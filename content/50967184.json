{"question_id": "50967184", "question_text": "普通本科，对机器学习感兴趣，老师丢给我几篇英文论文。内含很多数学公式，不太看得懂。接下去我该怎么做？看不懂硬看？ps. 我的机器学习水平处于仅仅只看完ng和台大的公开课，写过一些机器学习代码，但量不大。数学水平：线性代数 处于看完mit公开课水平。  概率和微积分一般。————————————谢谢各位。已找到了答案。@Takashi  说的很对，无非基础不够，及不够了解。还要继续努力！", "question_title": "看机器学习论文时，看不懂数学公式怎么办？", "question_commet": "​2 条评论", "answer_number": "18 个回答", "question_followers": "1,176", "brower_number": "78,742"}
{"answer_author": "赵紫川", "answer_id": 137902676, "answer_text": "不请自来。现在也在对机器学习方向进行研学，每天阅读大量的论文，同时也需要补充不少基础。一度面临过和题主相似的问题，斗胆来总结一下。||| 首先是基础知识方面：    1. 概率与数理统计 - 本质问题         我们基本可以认为当前机器学习的大部分根基都建立于概率与数理统计的理论之上，无论是NaiveBayes，HMM，概率决策树等PGM模型，抑或是支持向量机、神经网络等“现代方法”，其背后都是有庞大的概率体系作为支撑的。我们甚至可以用概率的方式去定义Generative model和Discriminative model的本质区别：    Generative Model 计算的目标是求解，而 Discriminiative Model的计算目标是求解       在概率统计中着重需要熟练运用的概念有：贝叶斯理论：重中之重，不必阐述贝叶斯理论在各类PGM中的重要性了，在神经网络的各种模型、方法、技巧中，也存在着大量的Bayes Approach & Explanations随机变量的各种特征、运算规则、分布等：其实应该和上面的放在一起说，同样的，不必说BayesNetwork以及MarkovNetwork这样显而易见的模型，在当前的深度学习中，由各类分布、Factor运算、以及相应的随机假设而推导出的方法、公式也是占了大量比例的（比如Softmax function、Hopfield Network的父模型MRF背后的Boltzmann/Gibbs分布等）。统计方法：应用领域也很多，最典型的是对于机器学习系统Performance的评判，以及一些上层改进方法（如Cross-validation等）。总和上述各个方面的似然方法：大量的机器学习问题，最后都可以归为概率-统计模型的似然求解问题，无论是问题本身的构建、求解，还是相应方法的优化，这一知识体系始终贯穿整个机器学习领域。2. 线性代数 -  模型建立线性代数在机器学习中的重要性，既非“线性”也非“代数”，更不在于很多人指出的“计算机对于矩阵运算有更高效的优化”，而在于现代机器学习系统的大量学习方法，都可以看做根据学习的目的，在为数据建立向量空间，并对这一向量空间进行映射变换，而达成直接求解或简化问题的目的（比如使得线性不可分的数据变得可分）。无论是Linear/Logistic Regression，还是神经网络（相关的解释可以参考Neural Networks, Manifolds, and Topology）。             相应地，当你把机器学习的各类问题转换为上面的视角去理解，那么在问题的建模、求解、优化中采用大量线性代数的知识，也不足为奇了。3. 高等数学 - 求解方法这一块具体怎么称呼众说纷纭，有人说要学好微积分，有人说会求导求梯度就好，有人说要把数分啃下来云云，其实在我的理解中，这些被广泛中国大学生概括为“高数”的东西，在机器学习里的主要以及重要应用就在于——近似的艺术。         为什么这么说？因为整个机器学习领域，从Statistical inference到Deep learning，几乎一路上全是各种NP-hardness，要做精确的计算，其所需计算资源随模型复杂度是指数级上升到。所以我们需要大量的方法对模型中的运算、求解（比如凸优化等），都需要大量的近似算法来进行，从Gradient Descent逼近（相应知识体系：梯度、极值），到Truncated Newton method（又称Hessian-Free Optimization，可以参考我之前写的知乎专栏，涉及到Hessian矩阵、级数展开等），以及在计算概率分布时使用的各种逼近算法（这一块基本就是各种微积分求解了），几乎都逃不出“高数”的手掌心。    除此之外，如果要走学术道路，这些内容的深化与扩展，包括但不限于：泛函分析、复分析、信息学、热力学等，对于后续的学习理解与研究启发，也是有深刻的帮助的。||| 接下来是学习方法方面：       这一方面我不做过于细致的展开，因为对于每个不同的个体而言，合适的学习方法千差万别，适合我自己的学习方法不一定适合这个答案的读者，所以在这一过程中，我只能蜻蜓点水般地说一说，大量展开难免夹带私货。学习路线：              我个人比较推荐的参考学习路线是，首先有一定的了解和基础（比如Coursera上AndrewNg的机器学习课程），这一步主要是知道机器学习做什么，以及一些基本的概念、方法。然后研学PGM，看一下PGM的基础教材，并了解一下各类概率模型在感兴趣的领域中的具体应用，各种Probablistic Graphical Models包含的知识体系，视野视角，对于后序的学习都有着很高的帮助。而后开始学神经网络，对于神经网络的学习，其实我个人觉得先从Hopfield Network学起（这一块是彻底彻底的私货，仅供参考），一个是模型简单、实现方便，另一方面可以大量借助之前PGM中学习的MRF知识进行辅助，然后又HopfieldNetwork的无向图推到有向模型，而后展开到分层神经网络，结合之前入门时的梯度下降方法手推一遍BackPropagation，在接下来就可以研学神经网络的各种变种、不同模型的结合等等。这一过程，推荐通过论文而非教材/教程进行学习。学习方式：              我比较推崇“深度优先学习法”，就是在学习的过程中，重视知识网的建立，遇到重要或有趣的内容，及时Dive in（但也要记得在走太远的时候及时终止）。比如在书、课程中遇到不熟悉/想更深了解的概念，记下来，开始进行搜索（可以从Wikipedia、Scholarpedia等进行入手，而后一并翻出各类资料来，对于重要的内容，还可以在arXiv.org等公开论文平台上获取一些有价值的论文），对于论文的研读过程，更可以在最后的Reference中寻找一些值得一看的论文。这种学习方法，除了能够对你的基础知识进行查漏补缺，对上层知识达到触类旁通，还有一个重要的作用：在寻本朔源的过程中，你会发现正在学的某个内容，和过去自己熟知的其他内容，本质上是同源的，很多无法理解的概念在这一瞬间，就恍然大悟了。我自己的一个例子是在学习MRF的时候，查阅MRF Factorization与Gibbs/Boltzmann分布的关系，并且（看着统计热力学资料）手推了一遍Gibbs/Boltzmann分布，而后突然明白Softmax分类函数、以及其作为分母的Partition Funtion的根本意义，以及后来在学到Hopfield Network时，更因为在推导Boltzmann分布的时候接触了一部分的统计力学、动力学知识，而后涉及到Ising模型、能量函数的本质时，也有了更自然的理解入口。             另当一提，对于初学来说，各类“水文”其实有着相当的参考价值（当然，不必精读），主要有以下两点： 初学者非常容易遇到的问题，就是“道理我都明白了，可是这玩意到底干嘛用的/怎么用的？”，而许多水文，文章不长，信息量稀疏，但却能很好地作为参考，来解答新手的这一问题为了保证水文看起来“不那么水”，大量的水文背后都有着非常值得一看的Reference，可以挑出其中有价值的部分当ReadingList了。。。。嗯。。。暂时就想到这，如果再想到什么也会更新上来，也欢迎同行补充完善以及指正 ~", "answer_votes": "366", "answer_comment": "​17 条评论"}
{"answer_author": "知乎用户", "answer_id": 138333577, "answer_text": "看不懂很正常，我现在也经常碰到看不懂的。没有办法，有些人就是喜欢在文章里写泛函、测度这些东西，虽然用向量、积分就能说明白……文章看不懂就不看了，审到看不懂的拒掉就好了。", "answer_votes": "37", "answer_comment": "​17 条评论"}
{"answer_author": "我爱机器学习", "answer_id": 123545501, "answer_text": "泻药，楼主的问题是一下子面临机器学习中比较复杂的公式但是又没人带入门，这种情况是不太好的。如果要比较高效的改变，建议：1. 导师或师兄带看paper和相关推导；2. 明确论文看不懂的部分缺的是哪块的数学知识，针对性补充。 长远来看，和课题或paper相关的数学知识需要系统补充，公开课和书都很好的，也可以看看我们网站的相关文章：数学 – 我爱机器学习，我们会持续更新。", "answer_votes": "24", "answer_comment": "​4 条评论"}
{"answer_author": "li Eta", "answer_id": 123575149, "answer_text": "看不懂的时候，先回顾一下以前学的数学基础，还看不懂，说明不是你的问题，要向导师和师兄师姐请教，此外，通过文章中公式上下文中引文的描述寻找公式的原始出处，可能会有更加清晰的解释。总之，不要害怕看公式。题外话：平心而论，我宁可看清晰的数学公式，而不是看含糊的文字表达。数学公式即使难懂，好歹也是清晰的，如果不清楚，基本上就说明写得有问题。但是文字写得模棱两可，就会导致有多种不同的理解。", "answer_votes": "31", "answer_comment": "​3 条评论"}
{"answer_author": "白杨", "answer_id": 123752406, "answer_text": "技能书要点对啊。给一个最快入门教科书类目吧。以周志华的书为例，在贝叶斯那章之前，需要的入门基础是微积分，线性代数，矩阵论。其中矩阵论建议用张贤达的那本贵的，其中矩阵求导，hesse阵，后面的矩阵分解是必知必会。看完了之后如果学有余力可以买一本boyd的凸优化，如果懒得看买一本应用最优化及matlab实现基本上最优化的基本应用可以过关。如果在这期间能阅读冯康的数值计算方法那是极好的。后面需要用到统计学方法的需要掌握的就是多元矩阵论（好像是这个名字？）茆师松的贝叶斯统计，李航的那本经典著作，基本上需要使用统计学的知识点暂时就点满了。偏微分可是个大坑，慎入，实函数要懂得测度，泛函要学会计算，如果实在想快速入门，老大中的变分法先看起来吧，看了基本上一般的小问题能够快速解决，再往后，我觉得需要先点解析几何，曲线与曲面，然后才能更好的理解关于pde求解中各种簇，锥之类的意义，一本通是数学物理方法2，全本都在讲pde。快速入门我觉得10本书足够了，要是想认真入门，路漫漫。。。", "answer_votes": "20", "answer_comment": "​5 条评论"}
{"answer_author": "Elina C", "answer_id": 138039960, "answer_text": "一般男票写程序需要用到高数的内容，基本都是甩给我，我帮他解。连特解和通解，微分了积分都分不清楚的数学渣，已经不能指望他什么了。当然现在会好好给他补课。我这个答案是抖机灵的，反正你们看不见。反正你们没有我这样的女朋友   ", "answer_votes": "116", "answer_comment": "​69 条评论"}
{"answer_author": "厂长", "answer_id": 123715013, "answer_text": "我大学没有选修数学课，高等数学基本自学。所以我有过题主一样的经历，我数学基本功也比较薄弱，体现在证明不够严谨，对算法的掌握依赖于直观思考和实现，而非数学推导。所以读数学成分大的论文（比如之前读量子机器学习算法的论文）也容易一头雾水。在寒窗苦读一段时间之后，也算是有了一些体会。其实读这些paper有一个小诀窍：就是把作者的推导步骤抄一遍。就是一行一行的抄，抄一步想一步。抄到哪个地方，觉得逻辑跟不上了，就记下来，方便之后找人请教。但是遇到断层，不要停，继续抄到结尾为止。大部分情况下，全部抄完，整个算法基本就能理解个差不多了。不要怕麻烦，这个方法比大量反复读论文要更有效率，而且会建立理解的信心。抄完之后，再快速读两遍论文，也会清晰爽快的多。假期如果有时间补理论，就推荐Bishop的Pattern Recogntion and Machine learning。是之前其他前辈推荐的。清晰易懂，数学不是特别难。时间紧的话，每章看前几节就好。实在看不懂的公式，就先背下来（没错。。就是先背下来），然后学到一定程度的时候，再反回来学习理解。公式也可以用抄写大法去学。这本书可以同时补充数学基本功和机器学习理论基本功，一箭双雕好东西。这是书：http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf再补充一个通用的学习方法，不限机器学习。就是不要一直高度精神集中学习一件事情，比如一两天全日死磕一遍论文。建议不同工作交叉进行，读读论文，然后写点其他的代码，有时间的话出去走走放松，或者睡一小觉。这是为了给大脑自动消化知识的时间，等断一段时间再回来学那篇论文，就会觉得简单的。有些难题，睡前想不懂，睡醒稍微想一想就想明白了，也是这个原理。", "answer_votes": "16", "answer_comment": "​2 条评论"}
{"answer_author": "知乎用户", "answer_id": 123631299, "answer_text": "不请自答。该问题中，「机器学习」其实可以换为其他的许多名词，比如「组合优化」「网络编码」等等。原因无非就是两个：1. 你的基础还不够。 2. 你对这个领域还不熟悉。建议的解决方法是，一边看优秀教材打基础，一边把论文多看几遍。这篇论文看不懂，就向前辈请教一些相对容易看懂的论文作引导。上学期我导师的同学，苏大的一位副教授来学院交流时，讲述了他进入「网络编码」这个研究领域的艰辛历程（现在他是网络编码领域多个国际期刊的审稿人，交流时非常谦虚），当时的说法就是一开始死活看不懂（那还是网络编码最早的几篇文献，看不懂就意味着可能很难进入这个领域了），但是仍然硬着头皮看，不断思考，不断理解，不知不觉地就看懂了，也不知不觉地，就进入了这个领域。言之于机器学习，大概也是适用的吧。共勉。", "answer_votes": "18", "answer_comment": "​4 条评论"}
{"answer_author": "蓦风星吟", "answer_id": 138300460, "answer_text": "这个还能怎么办呀，想要好好钻研，那么肯定追本溯源，一点一滴从基础看起，结合文章的引用与相关自己的推倒，当然还可以求助导师和你的同门，至于想要划水么，忽悠忽悠也就过去了。。。", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "Milo Sun", "answer_id": 143428799, "answer_text": "微积分，线性代数，概率论数理统计，这三门本科基础课的知识足够应付80%左右的机器学习算法，其他更复杂的就需要补数学了", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "一夜九卷的cxc", "answer_id": 127093227, "answer_text": "就本科平均水平来说，数学专业除外。应该是达不到机器学习入门所需的门槛的，除了最基本微积分，概率论数理统计，线性代数，还要有最优化计算方法和随机过程的基础。因为现在机器学习基本上都是从统计学的观点来进行研究的，所以概率论和数理统计这一块特别重要，还有就是最优化计算方法也是很重要的。比如牛顿法，Gradient descent method，凸优化等等都是学习器中非常常用的优化方法。而且很多东西本科就算学了也学不全，比如线性代数一般工科专业是不会涉及到矩阵求导，trace，还有奇异值分解这些东西的，所以如果不自己额外补的话，学习过程中会有困难的，感兴趣的话还是建议多多加强数学基础。新手入门可以看周志华的那本机器学习，比较通俗易懂，但是公式很多没有推导过程，可以配合Andrew Ng的视频看。等有一定的基础之后可以看看MLAPP吧", "answer_votes": "7", "answer_comment": "​4 条评论"}
{"answer_author": "陈司空", "answer_id": 138987249, "answer_text": "看不懂，就算了，知道怎么换数据集的代码，怎么调参数就可以撸起袖子加油干！干着干着就会了OR干着干着就感觉无所谓了！欢迎关注我的专栏，看更多精彩分享。", "answer_votes": "13", "answer_comment": "​5 条评论"}
{"answer_author": "匿名用户", "answer_id": 137951445, "answer_text": "会议论文由于页数限制的缘故一般不可能把公式在正文里写的那么详细。我建议开始阅读的时候主要关注思路和结论。详细的公式如果需要follow的话回过头来再看补充材料，一般会有比较详细的推导。", "answer_votes": "3", "answer_comment": "​添加评论"}
{"answer_author": "知乎用户", "answer_id": 138365441, "answer_text": "找本theory的书，比如A Probabilistic Theory of Pattern Recognition，把后面附录搞明白差不多了。矩阵微分和计算Mike Giles有个notes不错的或者看看理论计量的人写的习题集Matrix Algebra by Abadir & Magnus。数值优化看一看Nocedal&Wright前面几章就行，附录也是极好的参考。", "answer_votes": "1", "answer_comment": "​添加评论"}
{"answer_author": "西瓜圆滚滚", "answer_id": 144142255, "answer_text": "去补充下高数知识", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "章锐", "answer_id": 140475110, "answer_text": " 如果发现完全看不下去，建议跳回去补数学。微积分和概率论", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "蹭蹭", "answer_id": 138388349, "answer_text": "在国外读data science，跟你情况差不多，我手边放了本李航的《统计学习方法》，公式还是比较全的，基本上都有例题，不懂的顺着例题走一遍就懂了。", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "匿名用户", "answer_id": 138336916, "answer_text": "看来某科主攻数理基础还是很有道理的@陈炜铿 ", "answer_votes": "0", "answer_comment": "​1 条评论"}
