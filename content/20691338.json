{"question_id": "20691338", "question_text": "本人大学本科，对机器学习很感兴趣，想从事这方面的研究。在网上看到机器学习有一些经典书如Bishop的PRML， Tom Mitchell的machine learning，还有pattern classification，不知该如何入门？那本书比较容易理解？", "question_title": "机器学习该怎么入门？", "question_commet": "​11 条评论", "answer_number": "185 个回答", "question_followers": "21,518", "brower_number": "1,785,004"}
{"answer_author": "张松阳", "answer_id": 53910077, "answer_text": "好东西不敢独享，转载一发。正在学习林轩田的机器学习基石和吴恩达的机器学习，感觉讲的还不错，数学基础还是蛮重要的。机器学习入门资源不完全汇总感谢贡献者： tang_Kaka_back@新浪微博欢迎补充指正，转载请保留原作者和原文链接。 本文是 机器学习日报的一个专题合集，欢迎订阅：请给hao@memect.com发邮件，标题＂订阅机器学习日报＂。机器学习入门资源不完全汇总基本概念机器学习 机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。下面从微观到宏观试着梳理一下机器学习的范畴：一个具体的算法，领域进一步细分，实战应用场景，与其他领域的关系。图1: 机器学习的例子：NLTK监督学习的工作流程图 (source: http://www.nltk.org/book/ch06.html)图2: 机器学习概要图 by Yaser Abu-Mostafa (Caltech) (source: Map of Machine Learning (Abu-Mostafa))图3: 机器学习实战：在python scikit learn 中选择机器学习算法 by Nishant Chandra (source: In pursuit of happiness!: Picking the right Machine Learning Algorithm)图4: 机器学习和其他学科的关系： 数据科学的地铁图 by Swami Chandrasekaran (source: Becoming a Data Scientist)机器学习入门资源不完全汇总入门攻略大致分三类： 起步体悟，实战笔记，行家导读机器学习入门者学习指南 @果壳网 (2013) 作者 白马 -- [起步体悟] 研究生型入门者的亲身经历有没有做机器学习的哥们？能否介绍一下是如何起步的 @ourcoders -- [起步体悟] 研究生型入门者的亲身经历，尤其要看reyoung的建议tornadomeet 机器学习 笔记 (2013) -- [实战笔记] 学霸的学习笔记，看看小伙伴是怎样一步一步地掌握“机器学习”Machine Learning Roadmap: Your Self-Study Guide to Machine Learning (2014) Jason Brownlee -- [行家导读] 虽然是英文版，但非常容易读懂。对Beginner,Novice,Intermediate,Advanced读者都有覆盖。A Tour of Machine Learning Algorithms （2013） 这篇关于机器学习算法分类的文章也非常好Best Machine Learning Resources for Getting Started（2013） 这片有中文翻译 机器学习的最佳入门学习资源 @伯乐在线 译者 programmer_lin门主的几个建议既要有数学基础，也要编程实践别怕英文版，你不懂的大多是专业名词，将来不论写文章还是读文档都是英文为主[我是小广告][我是小广告]订阅机器学习日报，跟踪业内热点资料。机器学习入门资源不完全汇总更多攻略机器学习该怎么入门 @知乎 (2014)What's the easiest way to learn machine learning @quora (2013)What is the best way to study machine learning @quora (2012)Is there any roadmap for learning Machine Learning (ML) and its related courses at CMU Is there any roadmap for learning Machine Learning (ML) and its related courses at CMU(2014)机器学习入门资源不完全汇总课程资源Tom Mitchell 和 Andrew Ng 的课都很适合入门机器学习入门资源不完全汇总入门课程机器学习入门资源不完全汇总2011 Tom Mitchell(CMU)机器学习英文原版视频与课件PDF 他的《机器学习》在很多课程上被选做教材，有中文版。Decision TreesProbability and EstimationNaive BayesLogistic RegressionLinear RegressionPractical Issues: Feature selection，Overfitting ...Graphical models: Bayes networks, EM，Mixture of Gaussians clustering ...Computational Learning Theory: PAC Learning, Mistake bounds ...Semi-Supervised LearningHidden Markov ModelsNeural NetworksLearning Representations: PCA, Deep belief networks, ICA, CCA ...Kernel Methods and SVMActive LearningReinforcement Learning 以上为课程标题节选机器学习入门资源不完全汇总2014 Andrew Ng (Stanford)机器学习英文原版视频 这就是针对自学而设计的，免费还有修课认证。“老师讲的是深入浅出，不用太担心数学方面的东西。而且作业也非常适合入门者，都是设计好的程序框架，有作业指南，根据作业指南填写该完成的部分就行。”（参见白马同学的入门攻略）\"推荐报名，跟着上课，做课后习题和期末考试。(因为只看不干，啥都学不会)。\" (参见reyoung的建议）Introduction (Week 1)Linear Regression with One Variable (Week 1)Linear Algebra Review (Week 1, Optional)Linear Regression with Multiple Variables (Week 2)Octave Tutorial (Week 2)Logistic Regression (Week 3)Regularization (Week 3)Neural Networks: Representation (Week 4)Neural Networks: Learning (Week 5)Advice for Applying Machine Learning (Week 6)Machine Learning System Design (Week 6)Support Vector Machines (Week 7)Clustering (Week 8)Dimensionality Reduction (Week 8)Anomaly Detection (Week 9)Recommender Systems (Week 9)Large Scale Machine Learning (Week 10)Application Example: Photo OCRConclusion机器学习入门资源不完全汇总进阶课程2013年Yaser Abu-Mostafa (Caltech) Learning from Data -- 内容更适合进阶 课程视频,课件PDF@CaltechThe Learning ProblemIs Learning Feasible?The Linear Model IError and NoiseTraining versus TestingTheory of GeneralizationThe VC DimensionBias-Variance TradeoffThe Linear Model IINeural NetworksOverfittingRegularizationValidationSupport Vector MachinesKernel MethodsRadial Basis FunctionsThree Learning PrinciplesEpilogue2014年 林軒田(国立台湾大学) 機器學習基石 (Machine Learning Foundations) -- 内容更适合进阶，華文的教學講解 课程主页When Can Machines Learn? [何時可以使用機器學習] The Learning Problem [機器學習問題] -- Learning to Answer Yes/No [二元分類] -- Types of Learning [各式機器學習問題] -- Feasibility of Learning [機器學習的可行性]Why Can Machines Learn? [為什麼機器可以學習] -- Training versus Testing [訓練與測試] -- Theory of Generalization [舉一反三的一般化理論] -- The VC Dimension [VC 維度] -- Noise and Error [雜訊一錯誤]How Can Machines Learn? [機器可以怎麼樣學習] -- Linear Regression [線性迴歸] -- Linear `Soft' Classification [軟性的線性分類] -- Linear Classification beyond Yes/No [二元分類以外的分類問題] -- Nonlinear Transformation [非線性轉換]How Can Machines Learn Better? [機器可以怎麼樣學得更好] -- Hazard of Overfitting [過度訓練的危險] -- Preventing Overfitting I: Regularization [避免過度訓練一：控制調適] -- Preventing Overfitting II: Validation [避免過度訓練二：自我檢測] -- Three Learning Principles [三個機器學習的重要原則]机器学习入门资源不完全汇总更多选择2008年Andrew Ng CS229 机器学习 -- 这组视频有些年头了，主讲人这两年也高大上了.当然基本方法没有太大变化，所以课件PDF可下载是优点。 中文字幕视频@网易公开课 | 英文版视频@youtube |课件PDF@Stanford第1集.机器学习的动机与应用 第2集.监督学习应用.梯度下降 第3集.欠拟合与过拟合的概念 第4集.牛顿方法 第5集.生成学习算法 第6集.朴素贝叶斯算法 第7集.最优间隔分类器问题 第8集.顺序最小优化算法 第9集.经验风险最小化 第10集.特征选择 第11集.贝叶斯统计正则化 第12集.K-means算法 第13集.高斯混合模型 第14集.主成分分析法 第15集.奇异值分解 第16集.马尔可夫决策过程 第17集.离散与维数灾难 第18集.线性二次型调节控制 第19集.微分动态规划 第20集.策略搜索2012年余凯(百度)张潼(Rutgers) 机器学习公开课 -- 内容更适合进阶 课程主页@百度文库 ｜ 课件PDF@龙星计划第1节Introduction to ML and review of linear algebra, probability, statistics (kai) 第2节linear model (tong) 第3节overfitting and regularization(tong) 第4节linear classification (kai) 第5节basis expansion and kernelmethods (kai) 第6节model selection and evaluation(kai) 第7节model combination (tong) 第8节boosting and bagging (tong) 第9节overview of learning theory(tong) 第10节optimization in machinelearning (tong) 第11节online learning (tong) 第12节sparsity models (tong) 第13节introduction to graphicalmodels (kai) 第14节structured learning (kai) 第15节feature learning and deeplearning (kai) 第16节transfer learning and semi supervised learning (kai) 第17节matrix factorization and recommendations (kai) 第18节learning on images (kai) 第19节learning on the web (tong)机器学习入门资源不完全汇总论坛网站机器学习入门资源不完全汇总中文我爱机器学习 我爱机器学习http://www.mitbbs.com/bbsdoc/DataSciences.html MITBBS－ 电脑网络 - 数据科学版机器学习小组 果壳 > 机器学习小组http://cos.name/cn/forum/22 统计之都 » 统计学世界 » 数据挖掘和机器学习北邮人论坛-北邮人的温馨家园 北邮人论坛 >> 学术科技 >> 机器学习与数据挖掘机器学习入门资源不完全汇总英文josephmisiti/awesome-machine-learning · GitHub 机器学习资源大全Machine Learning Video Library Caltech 机器学习视频教程库，每个课题一个视频Analytics, Data Mining, and Data Science 数据挖掘名站http://www.datasciencecentral.com/ 数据科学中心网站机器学习入门资源不完全汇总东拉西扯一些好东西，入门前未必看得懂，要等学有小成时再看才能体会。机器学习与数据挖掘的区别机器学习关注从训练数据中学到已知属性进行预测数据挖掘侧重从数据中发现未知属性Dan Levin, What is the difference between statistics, machine learning, AI and data mining?If there are up to 3 variables, it is statistics.If the problem is NP-complete, it is machine learning.If the problem is PSPACE-complete, it is AI.If you don't know what is PSPACE-complete, it is data mining.几篇高屋建瓴的机器学习领域概论, 参见原文The Discipline of Machine LearningTom Mitchell 当年为在CMU建立机器学习系给校长写的东西。A Few Useful Things to Know about Machine Learning Pedro Domingos教授的大道理，也许入门时很多概念还不明白，上完公开课后一定要再读一遍。几本好书李航博士的《统计学习方法》一书前段也推荐过，给个豆瓣的链接", "answer_votes": "3.4K", "answer_comment": "​57 条评论"}
{"answer_author": "知乎用户", "answer_id": 90976508, "answer_text": "看到没有人提到Metacademy，推荐一发作为入门工具：Metacademy，以及我个人的一点粗浅看法。上面有很多答案说得太庞杂了，固然机器学习这个领域有很多的经典资料值得我们花大块时间去研读，但对于一个入门的新人来说如果在一开始就一头扎进这样深不见底的知识海洋之中，难免产生一些挫败感，这样的挫败感对深入学习是不利的，也是不必要的。事实上，在机器学习这个领域里，我们可以说出诸如“演化计算”，“统计关系学习”等上百个关键词，每一个关键词都代表着一个子领域，无论多么优秀的机器学习学家，也不敢说自己对每一个子领域都有相当的了解。如果对机器学习有兴趣，当拥有最基础的知识之后，就可以尝试对某个感兴趣的子领域展开一些研究，利用问题驱动自己，逐渐形成self-motivation。在解决问题的过程中不断提升自己的视野，提升自己对问题的洞察力和对研究的自信可能是更为重要的。但在这样的过程中，基础薄弱所带来的问题可能就会浮现：每每你读论文，会遇到许多闻所未闻的概念，这时为了弄清整个论文逻辑，你不得不跑回去先了解这些知识。这样你又一头扎进了知识海洋，在几十个搜出来的网页之间切来切去，尝试弄明白一个个预备知识的预备知识，却不知道这一块块拼图何时才能拼完你最初想读懂的论文。如果你有一个足够强大又足够耐心的导师，可能会很大程度地帮到你，但大部分的导师不会如此体贴入微——他们只会在大的方向上引导你。这时候我们需要的是一个知识结构上的贴心“导师”，告诉你为了看懂这个概念，哪些知识你需要学，为什么这些知识重要，怎样快速了解这些知识。我们需要一副清晰的知识图谱，以帮助我们最快速地解决我们需要解决的问题。这是Metacademy的建设初衷。Metacademy会把各个知识点联系起来，就像游戏里的技能树一样。每个知识点有个简介，而且会链接到那些优质的学习资源上，最重要的是，它会画出通向这个知识点的知识图谱。Metacademy的建设目标是“your package manager for knowledge”，但现在上面暂时只集成了一些机器学习和相关的数学知识。例如我们想了解CNN(convolutional neural nets)这个概念，直接在Metacademy上搜索它：&lt;img src=\"https://pic1.zhimg.com/50/4c8801f1addb21238b00c180263f8aea_hd.jpg\" data-rawwidth=\"847\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb\" width=\"847\" data-original=\"https://pic1.zhimg.com/4c8801f1addb21238b00c180263f8aea_r.jpg\"&gt;可以看到这个概念相关的介绍：&lt;img src=\"https://pic2.zhimg.com/50/be15a512fe6891ff0be1a073224d68b5_hd.jpg\" data-rawwidth=\"900\" data-rawheight=\"616\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic2.zhimg.com/be15a512fe6891ff0be1a073224d68b5_r.jpg\"&gt; 其中这门课Coursera: Neural Networks for Machine Learning 想必有很多前辈都会推荐，授课人是深度学习大师Geoffrey Hinton。我们还可以点击左上角的树状图标查看知识图谱：&lt;img src=\"https://pic1.zhimg.com/50/08706dbf82abde2ea3eaa5916643a447_hd.jpg\" data-rawwidth=\"507\" data-rawheight=\"724\" class=\"origin_image zh-lightbox-thumb\" width=\"507\" data-original=\"https://pic1.zhimg.com/08706dbf82abde2ea3eaa5916643a447_r.jpg\"&gt;一层一层知识间的关系变得清晰起来。再怎么新手，vectors，dot product也是知道的。这样虽然要学的知识量客观上没有改变，但不再是淹没在知识海洋里，而是面对知识的阶梯一步一步向上走。这样的感觉是截然不同的，而在研究过程中，感觉是非常重要的一环。当然这个Metacademy还很初步，我只是拿它做了个例子。总的来说，机器学习该怎么入门，怎么算入门，各家有各家的说法，我还没有评论的资格。我的想法是，在科技如此发达，知识如此丰富的现代，我们不应感到迷茫，而应换个角度看到道路更宽广，世界更多彩。也许可以把一些冗杂的既有知识暂且放下，多将精力放在那些更值得我们思考的问题上来，或许这样更能不断地在学习和研究中获得正向反馈。", "answer_votes": "650", "answer_comment": "​22 条评论"}
{"answer_author": "Leon", "answer_id": 102249162, "answer_text": "我看到有人在问，Andrew Ng的视频，还有代码这些的资料。再次整理一下：1、机器学习实战的书：《机器学习实战 (图灵程序设计丛书 72)》 [美]Peter Harrington, 李锐, 李鹏, 曲亚东, 王斌 书评 简介 电子书下载 Kindle电子书2、Andrew Ng老师的视频教程：Machine Learning:斯坦福大学机器学习个人笔记完整版（附所有视频和字幕） （现在Andrew Ng老师没开新课了，这是一个同学自己下载的所有视频和相关资料，大家可以自行下载）3、Andrew Ng老师早期的一个机器学习公开课：斯坦福大学公开课 ：机器学习课程4、Andrew Ng老师机器学习课的代码。Python版本：icrtiou/Coursera-ML-AndrewNg                                                            Matlab版本：vugsus/coursera-machine-learning另外，鉴于现在深度学习这么的火热，而且现在做机器学习也避免不了了解及应用深度学习，我这里也加入一些深度学习的内容。1、入门的数学和编程基础和机器学习的要求是一样的。2、入门读物还是推荐Andrew Ng老师组织的一个WIKI，UFLDL Tutorial - Ufldl ， 非常建议大家老老实实花两个星期的时间把这个wiki的内容和相关程序自己实现一次。而且，这个wiki是有中文版本的，在每个页面的最下面都可以点击查看中文版本。（PS：我还很荣幸的当时参与了当时的翻译工作，为内容的中文化做了一点点微小的工作。）。3、现在的深度学习应用最为广泛的就是卷积神经网络（Convolutional neural network， CNN），所以建议大家可以多看看这个方面的内容。正好这几天Fei Fei Li老师的CNN课程又开课了，大家有兴趣可以去看看。这个网站会同步更新，而且有中文翻译。【中文字幕】2017春季CS231n 斯坦福深度视觉识别课。4、做深度学习避免不了的要选择一个平台，Tensorflow，Caffe，Torch，MxNet等等都是选择。如果是新手，尤其是基于Windows平台的新手，我还是比较建议用Tensorflow。具体的内容可以参见这个莫烦系列教程 - Tensorflow教程。5、最后，就是勤联系、勤联系、勤联系啦。6、最后的最后，如果没有项目参与，那么最好的检验自己的学习成果的手段就是参加比赛啦。国外的Kaggle，KDD CUP，...。国内的天池大数据竞赛，...。https://www.kaggle.com/http://www.kdd.org/kdd-cuphttps://tianchi.shuju.aliyun.com/这几年，机器学习绝对是计算机领域最热门的话题和方向。笔者不属于专门研究机器学习，但是平时的工作会经常用到一些相关的算法。因此，对于机器学习也仅仅是入门的水平。但是我想也正是因为我只是一个入门汉，所以能够从我们入门者的角度来总结如何入门，希望对还在门外的同学有一些帮助。                                                          数   学很多人翻看任何一本机器学习的书，看到一推的数学公式就开始打退堂鼓了。开始搜索，提问“机器学习需要哪些数学知识？”然后得到的结果可能会是“矩阵分析，概率论，优化设计……”而且还会有大量的人推荐一些例如“All of Statistics”，“Convex Optimation”等等外文教材。至少我当时面对的情况就是这样的。这种情况很可能后面会朝以下画风发展。看到上述推荐的那些经典教材，你像看待圣经一样看待他们。抱着一种学会了那些课，我再看机器学习的书简直就会是探囊取物的想法，你下载了巨多相关材料。但是，慢慢你会发现，除了把他们下载了下来，你并没有任何的进步。你并没有完完整整的看完一本，你并没有在机器学习方面卓越超群。入门阶段真的需要这么多的数学储备吗？未必。入门阶段我感觉你只要有普通工科专业大一大二那几门基础数学课“线性代数”，“高数”，“概率论与数理统计”就可以让你入门了。所以，千万别被机器学习中的数学所吓倒而不知道该如何下手。只要有上述的几门课的基础，你完全可以看懂很大一部分机器学习算法。                                                             程序语言机器学习入门最佳的方法其实就是理论和代码一起学习。一边看相应的理论推导，一边看并且实践经典代码。所以，为了更快入门，我推荐你最好能够懂点MATLAB或者是Python语言。Matlab和Python说实话做高端的机器学习肯定是不推荐的，但是如果你想的是机器学习快速入门，那这两门语言绝对是绝佳选择。     第一步有了上述基础后，你可以开始看点机器学习的相关内容了。我看很多人推荐elements of machine learning。我想说，你想让一个基础为零的人去看这本书，真的合适吗？？？所以，我推荐的是Machine Learning in action，（这里面的完成语言为Python）这是英文版本的。当然如果你觉得英文对你是一个完全过不去的坎，（虽然我建议做技术的人都必须至少要看得懂英文）现在有中文版本，叫“机器学习实践”。这本书用尽量少的公式把机器学习的基本算法都过了一遍，而且还讲得很清楚，更为重要的是他将公式和代码结合了起来。因此，你的机器学习并没有那么的抽象了，你知道算法里的公式如何的转化为代码。所以，第一步，你可以耐着性子将这本书看完。反正我当时，把书中的代码自己敲了一次，虽然代码有的下载，你也可以选择只是把代码看懂完事。但我还是建议，自己敲一次，运行运行，这样你会得到不一样的体会。   第二步学习Coursera上面Andrew Ng老师的machine learning的课程。这门课造福了众多机器学习的入门者，不仅仅是因为课程全面，内容由浅入深。更加重要的是这门课程每次课都有课堂作业，作业不需要你写出来所有的代码，但是关键代码要你写出来，而且还会教你如何调试代码。初学者学这门课的时候很可能会买有耐心，又是英文的，又有进度要求，又有作业。没关系，你可以把视频下载下来（很多网盘里都有下载好的视频），然后慢慢的去啃。作业也是，可能你自己不能一口气写出来，没关系，在自己做了大量尝试后，去Github上面下载一些别人写好的代码看一看，找找自己的问题到底出在了哪里。总之，一定要耐着性子过一遍甚至是几面这个课程。                                                              第三步这时候你已经对机器学习很多简单的算法比较清楚了，但是可能还没有一种大的全局观。所以，我建议大家可以看看这两本中文教材。周志华老师的西瓜书《机器学习》和李航老师的《统计学习方法》，这两本书都是作者花了大量心思编写的，也是在中国众多科技书籍中难得的两本佳作。英文书籍，可以推荐《Patten Recognition and Machine Learning》，《Elementsof Statistical Learning》(但是这本书难度比较大，如果你有足够的耐心，可以慢慢啃，多次的啃。相信每次都会有不同的收获。我自己已经看了好几次，但是确实每次都没有完全看完，但是目前我遇到很多问题，我去翻这本书，还是能找到很多答案，尤其是我做稀疏相关的工作，里面的相关内容讲解非常清楚。）                                                             第四步这时候，机器学习你已经可以说大概入门了。后面的事情，就得根据你的需求来制定相关的学习路线。比如，做大数据分析的，得去学学spark，Hadoop等计算框架；另外，图模型，深度学习……等等内容，都是一些方向。自然语言处理、图像识别、语音识别等等也是一些应用方向，更有大量的领域知识需要结合。在前沿部分和第一到第三步的内容，如果你能按照这几步走下来，入门是肯定可以的。至于后面的机器学习精通部分，我也只能说：Good Luck and Have Fun广告时间：机器学习、未来智能、机器人相关话题，可关注公众号：工业大数据与PHM研究http://weixin.qq.com/r/A0wDG77E9uOJrfp49xkR (二维码自动识别)", "answer_votes": "922", "answer_comment": "​96 条评论"}
{"answer_author": "刘知远", "answer_id": 107537692, "answer_text": "原来写过一个段子：ML派坐落美利坚合众山中，百年来武学奇才辈出，隐然成江湖第一大名门正派，门内有三套入门武功，曰：图模型加圈，神经网加层，优化目标加正则。有童谣为证：熟练ML入门功，不会作文也会诌。供参考，哈哈。", "answer_votes": "315", "answer_comment": "​17 条评论"}
{"answer_author": "知乎用户", "answer_id": 155188118, "answer_text": "入门分两种：1. 应用的级别 2. 科研的级别。第一种门槛非常低，跟一门公开课，读一本书，用Python的SK-Learn解决一些问题。多做编程实现和练习，很快就能用机器学习的方法解决问题。第二种是research-level，入门比较难。当然，你把机器学习入门定义为在1.5流会议上灌水，其实倒也不难，比如刘知远写的那个段子。然而找到真正的前沿领域，能推进这个领域的发展，做一些微小的贡献，难度是很大的，而且很难在没有人指导的情况下做到。真正靠谱的方法只有一个：找个靠谱的导师。", "answer_votes": "117", "answer_comment": "​31 条评论"}
{"answer_author": "知乎用户", "answer_id": 47296825, "answer_text": "20161121更新： 如果你想看的Coursera课程没有了，推荐使用一款神奇的插件，可以批量下载课程，Github传送门：coursera-dl/coursera-dl使用说明在Readme上。------ 刚好是一名小菜正在入门，日学习时间>8h/d，与楼主共勉，基础课程学习完了之后，动手实践吧！2015/07/01： 根据自己上过的课程，更新课程列表1. 数学基础机器学习必要的数学基础主要包括：多元微积分，线性代数Calculus: Single Variable | Calculus One （可选）Multivariable CalculusLinear Algebra2. 统计基础Introduction to Statistics: Descriptive StatisticsProbabilistic Systems Analysis and Applied Probability | 概率 ( 可选)Introduction to Statistics: Inference3. 编程基础Programming for Everybody (Python)DataCamp: Learn R with R tutorials and coding challenges(R)Introduction to Computer Science:Build a Search Engine & a Social Network4. 机器学习Statistical Learning(R)Machine Learning机器学习基石机器学习技法下面是近期的给外行人读的泛数学科普书籍，由浅至深，作用除了感受数学之美之外，更重要的是可以作用每天学习的鸡血，因为这些书都比较好读……1.《数学之美》作者：吴军 2.《 Mathematician's Lament | 数学家的叹息》作者：by Paul Lockhart3.《 Think Stats: Probability and Statistics for Programmers | 统计思维：程序员数学之概率统计 》 作者：Allen B. Downey4.《 A History of Mathematics | 数学史 》作者：Carl B. Boyer5.《 Journeys Through Genius | 天才引导的历程：数学中的伟大定理 》作者：William Dunham6.《 The Mathematical Experience | 数学经验 》作者 Philip J.Davis、Reuben Hersh7.《 Proofs from the Book | 数学天书中的证明 》作者：Martin Aigner、Günter M. Ziegler8.《 Proofs and Refutations | 证明与反驳－数学发现的逻辑 》作者：Imre Lakatos本文源《我的数据挖掘学习图谱》：http://blog.bpteach.com/my-discovery-of-dataming", "answer_votes": "495", "answer_comment": "​28 条评论"}
{"answer_author": "LIU XIANGYU", "answer_id": 54653641, "answer_text": "机器学习基石机器学习技法Machine Learning (Andrew Ng)Linear Algebra (Gilbert Strang)統計學, 高等統計學 （陳鄰安）", "answer_votes": "638", "answer_comment": "​27 条评论"}
{"answer_author": "谢澎涛", "answer_id": 41951610, "answer_text": "机器学习用到的数学并不难，很多较难的数学（如抽象代数、微分几何）目前在ML问题上也没有用武之地。相比数学，我觉得更重要的一点是对问题和数据的insight。很多经典漂亮的模型，如HMM、CRF、LDA都是建立在良好的motivation和insight之上，数学并不是瓶颈。至于怎么培养insight 恐怕很难说，目前能做的就是多读、多想、多试。", "answer_votes": "86", "answer_comment": "​6 条评论"}
{"answer_author": "知乎用户", "answer_id": 27259370, "answer_text": "我也谈谈自己的经验。机器学习说简单就简单，说难就难，但如果一个人不够聪明的话，他大概很难知道机器学习哪里难。基本上要学习机器学习，先修课程是algebra, calculus, probability theory, linear regression。这几门科学好了再学Machine learning是事半功倍的。此外近代数学的东西也要懂， functional analysis啥的。其实不懂也行，只是现在文献总是喜欢引用里面的概念，懂一些读起来方便。（我就很讨厌manifold learning这个名字，把许多人都吓跑了）real analysis最好用心学，对序列或函数的收敛性的理解很能帮助你了解这些模型的精髓。Optimization theory (ref. Convex optimization by Boyd)也是重中之重，在前面几门课学好并有一定python基础的时候可以仔细读一读。其实机器学习需要看的书不多，必读的是elements of statistical learning。这本书涵盖范围很广，且深入浅出，习题也有一定难度，适合自学。你看过这本之后就知道其他什么书可以看什么书不需要看了。再下来就是练习，这个是重中之重。我觉得做kaggle的比赛最有效。可以仿照别人写写code，也可以自己想想办法，但最主要的是要能够迅速完成编程并给出结果。我见过许多人光讨论就可以几天，但真正动起手来就萎了。最后就是读source code并自己实现几个model from scratch。这个比较难，但是确是最锻炼人的。具体语言应该是越基础越好，比如C/C++什么的。等你自己写完了一两个model，再去用别人的package就会觉得得心应手许多了。我真心觉得这个比上coursera那些课强多了。上coursera最大的缺点就是容易变得似懂非懂纸上谈兵。我自己program过ensemble trees(C++)和deep learning solver(Python)，受益颇多。至于读source code，我觉得libsvm写得很好啊，不过算法对大一大二新生是难了点。此外，基于python的工具包scikit-learn的sourcecode很好读，建议大家多看看。我看回答中有提到Matlab，我觉的matlab处理字符很麻烦，现在很多dataset都需要处理字符，所以并不是好的选择。补充一点就是要学会发散思维，学会如何从data中找feature。关于这个的教程很缺，需要大量练习及一些天赋。说实话machine learning虽然门槛不高，但真心是聪明人的游戏。-------------------------------------------------------很久之前写的东西了，不过感觉文字打击了很多人的积极性。 -------------------------------------------------------[2017年2月7日]没想到直到今天还有人点赞。我发几页自己之前写的notes吧。看起来是笨鸟笨着飞的办法，但是效果真的很好。（再加上投行那几年把MS Word能力练得很强，写起来比Latex快多了）&lt;img data-rawwidth=\"750\" data-rawheight=\"1334\" src=\"https://pic3.zhimg.com/50/v2-3e8ccae347e85cb4960b8cff091bbfcb_hd.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"750\" data-original=\"https://pic3.zhimg.com/v2-3e8ccae347e85cb4960b8cff091bbfcb_r.jpg\"&gt;&lt;img data-rawwidth=\"750\" data-rawheight=\"1334\" src=\"https://pic2.zhimg.com/50/v2-c00755cbff9950dc9677915e16109495_hd.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"750\" data-original=\"https://pic2.zhimg.com/v2-c00755cbff9950dc9677915e16109495_r.jpg\"&gt;&lt;img data-rawwidth=\"750\" data-rawheight=\"1334\" src=\"https://pic1.zhimg.com/50/v2-d388bb933386c4d7b358e63ac453256b_hd.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"750\" data-original=\"https://pic1.zhimg.com/v2-d388bb933386c4d7b358e63ac453256b_r.jpg\"&gt;", "answer_votes": "699", "answer_comment": "​54 条评论"}
{"answer_author": "知乎用户", "answer_id": 22469618, "answer_text": "2014/10/23更新：这两天看到李航老师的《统计学习方法》，感觉写的非常好，适合入门，机器学习的基本概念都有，但是不太深入，中文书写，所有专业名词给出英文翻译。适合给初学者建立概念，可以系统的了解机器学习。原答案：强烈推荐这个UFLDL教程 - Ufldl。这是Andrew Ng写的关于非监督特征学习与深度学习的教程，关键是有一批无私且专业的网友，将其翻译成中文，并有中英文对照，与Andrew Ng商量后贴在了原网址上。非常感谢这些人啊。对于一个初学者，如果单纯从英文教材（视频）入手的话，会比较吃力，很多概念都没建立起来，很多术语都没有掌握，而这个教程设计机器学习很多的基本概念，并附有matlab习题，通过循序渐进的练习，可以更快掌握基本概念。另外这个的好处是不像一般教材，面面俱到，很多追究的太深，不利于初学者建立概念！有了这个的基础之后，再去看相关著作或者论文，肯定得心应手。", "answer_votes": "89", "answer_comment": "​23 条评论"}
{"answer_author": "知乎用户", "answer_id": 22465357, "answer_text": "我要翻译一把quora了，再加点我的理解，我相信会是一个好答案，链接我都放到一起了，没插入到正文中，要求其实比较高了，我觉得我自己都差很远很远~~~我尽量持续更新翻译质量以及自己理解1. Python/C++/R/Java - you will probably want to learn all of these languages at some point if you want a job in machine-learning. Python's Numpy and Scipy libraries [2] are awesome because they have similar functionality to MATLAB, but can be easily integrated into a web service and also used in Hadoop (see below). C++ will be needed to speed code up. R [3] is great for statistics and plots, and Hadoop [4] is written in Java, so you may need to implement mappers and reducers in Java (although you could use a scripting language via Hadoop streaming [5])首先，你要熟悉这四种语言。Python因为开源的库比较多，可以看看Numpy和Scipy这两个库，这两个都可以很好的融入网站开发以及Hadoop。C++可以让你的代码跑的更快，R则是一个很好地统计工具。而你想很好地使用Hadoop你也必须懂得java，以及如何实现map reduce2. Probability and Statistics: A good portion of learning algorithms are based on this theory. Naive Bayes [6], Gaussian Mixture Models [7], Hidden Markov Models [8], to name a few. You need to have a firm understanding of Probability and Stats to understand these models. Go nuts and study measure theory [9]. Use statistics as an model evaluation metric: confusion matrices, receiver-operator curves, p-values, etc.我推荐统计学习方法 李航写的，这算的上我mentor的mentor了。理解一些概率的理论，比如贝叶斯，SVM，CRF，HMM，决策树，AdaBoost，逻辑斯蒂回归，然后再稍微看看怎么做evaluation 比如P R F。也可以再看看假设检验的一些东西。3. Applied Math + Algorithms: For discriminate models like SVMs [10], you need to have a firm understanding of algorithm theory. Even though you will probably never need to implement an SVM from scratch, it helps to understand how the algorithm works. You will need to understand subjects like convex optimization [11], gradient decent [12], quadratic programming [13], lagrange [14], partial differential equations [15], etc. Get used to looking at summations [16].机器学习毕竟是需要极强极强数学基础的。我希望开始可以深入的了解一些算法的本质，SVM是个很好的下手点。可以从此入手，看看拉格朗日，凸优化都是些什么4. Distributed Computing: Most machine learning jobs require working with large data sets these days (see Data Science) [17]. You cannot process this data on a single machine, you will have to distribute it across an entire cluster. Projects like Apache Hadoop [4] and cloud services like Amazon's EC2 [18] makes this very easy and cost-effective. Although Hadoop abstracts away a lot of the hard-core, distributed computing problems, you still need to have a firm understanding of map-reduce [22], distribute-file systems [19], etc. You will most likely want to check out Apache Mahout [20] and Apache Whirr [21].熟悉分布计算，机器学习当今必须是多台机器跑大数据，要不然没啥意义。请熟悉Hadoop，这对找工作有很大很大的意义。百度等公司都需要hadoop基础。5. Expertise in Unix Tools: Unless you are very fortunate, you are going to need to modify the format of your data sets so they can be loaded into R,Hadoop,HBase [23],etc. You can use a scripting language like python (using re) to do this but the best approach is probably just master all of the awesome unix tools that were designed for this: cat [24], grep [25], find [26], awk [27], sed [28], sort [29], cut [30], tr [31], and many more. Since all of the processing will most likely be on linux-based machine (Hadoop doesnt run on Window I believe), you will have access to these tools. You should learn to love them and use them as much as possible. They certainly have made my life a lot easier. A great example can be found here [1].熟悉Unix的Tool以及命令。百度等公司都是依靠Linux工作的，可能现在依靠Windows的Service公司已经比较少了。所以怎么也要熟悉Unix操作系统的这些指令吧。我记得有个百度的面试题就是问文件复制的事情。6. Become familiar with the Hadoop sub-projects: HBase, Zookeeper [32], Hive [33], Mahout, etc. These projects can help you store/access your data, and they scale.机器学习终究和大数据息息相关，所以Hadoop的子项目要关注，比如HBase Zookeeper Hive等等7. Learn about advanced signal processing techniques: feature extraction is one of the most important parts of machine-learning. If your features suck, no matter which algorithm you choose, your going to see horrible performance. Depending on the type of problem you are trying to solve, you may be able to utilize really cool advance signal processing algorithms like: wavelets [42], shearlets [43], curvelets [44], contourlets [45], bandlets [46]. Learn about time-frequency analysis [47], and try to apply it to your problems. If you have not read about Fourier Analysis[48] and Convolution[49], you will need to learn about this stuff too. The ladder is signal processing 101 stuff though.这里主要是在讲特征的提取问题。无论是分类（classification）还是回归（regression）问题，都要解决特征选择和抽取（extraction）的问题。他给出了一些基础的特征抽取的工具如小波等，同时说需要掌握傅里叶分析和卷积等等。这部分我不大了解，大概就是说信号处理你要懂，比如傅里叶这些。。。Finally, practice and read as much as you can. In your free time, read papers like Google Map-Reduce [34], Google File System [35], Google Big Table [36], The Unreasonable Effectiveness of Data [37],etc There are great free machine learning books online and you should read those also. [38][39][40]. Here is an awesome course I found and re-posted on github [41]. Instead of using open source packages, code up your own, and compare the results. If you can code an SVM from scratch, you will understand the concept of support vectors, gamma, cost, hyperplanes, etc. It's easy to just load some data up and start training, the hard part is making sense of it all.总之机器学习如果想要入门分为两方面：一方面是去看算法，需要极强的数理基础（真的是极强的），从SVM入手，一点点理解。另一方面是学工具，比如分布式的一些工具以及Unix~Good luck.祝好[1] http://radar.oreilly.com/2011/04...[2] NumPy — Numpy[3] The R Project for Statistical Computing[4] Welcome to Apache™ Hadoop®![5] http://hadoop.apache.org/common/...[6] http://en.wikipedia.org/wiki/Nai...[7] http://en.wikipedia.org/wiki/Mix...[8] http://en.wikipedia.org/wiki/Hid...[9] http://en.wikipedia.org/wiki/Mea...[10] http://en.wikipedia.org/wiki/Sup...[11] http://en.wikipedia.org/wiki/Con...[12] http://en.wikipedia.org/wiki/Gra...[13] http://en.wikipedia.org/wiki/Qua...[14] http://en.wikipedia.org/wiki/Lag...[15] http://en.wikipedia.org/wiki/Par...[16] http://en.wikipedia.org/wiki/Sum...[17] http://radar.oreilly.com/2010/06...[18] AWS | Amazon Elastic Compute Cloud (EC2)[19] http://en.wikipedia.org/wiki/Goo...[20] Apache Mahout: Scalable machine learning and data mining[21] http://incubator.apache.org/whirr/[22] http://en.wikipedia.org/wiki/Map...[23] HBase - \n    Apache HBase Home[24] http://en.wikipedia.org/wiki/Cat...[25] grep[26] http://en.wikipedia.org/wiki/Find[27] AWK[28] sed[29] http://en.wikipedia.org/wiki/Sor...[30] http://en.wikipedia.org/wiki/Cut...[31] http://en.wikipedia.org/wiki/Tr_...[32] Apache ZooKeeper[33] Apache Hive TM[34] http://static.googleusercontent....[35]http://static.googleusercontent....[36]http://static.googleusercontent....[37]http://static.googleusercontent....[38] http://www.ics.uci.edu/~welling/...[39] http://www.stanford.edu/~hastie/...[40] http://infolab.stanford.edu/~ull...[41] https://github.com/josephmisiti/...[42] http://en.wikipedia.org/wiki/Wav...[43] http://www.shearlet.uni-osnabrue...[44] http://math.mit.edu/icg/papers/F...[45] http://www.ifp.illinois.edu/~min...[46] http://www.cmap.polytechnique.fr...[47 ]http://en.wikipedia.org/wiki/Tim...[48] http://en.wikipedia.org/wiki/Fou...[49 ]http://en.wikipedia.org/wiki/Con...", "answer_votes": "1.1K", "answer_comment": "​39 条评论"}
{"answer_author": "王丰", "answer_id": 25385865, "answer_text": "不同意第一名的答案。知乎一直这样，精英主义太严重，好像不表现得专业点、不长点就不是好答案。说白了就是装b。知乎不是wikipedia（wikipedia适合查资料，不适合从零开始学习）。题主的问题是这样的：本人大学本科，对机器学习很感兴趣，想从事这方面的研究。在网上看到机器学习有一些经典书如Bishop的PRML， Tom Mitchell的machine learning，还有pattern classification，不知该如何入门？那本书比较容易理解？注意题主是本科，现在感兴趣，希望能入门。让一个想要入门机器学习的本科生上来就学Hadoop，这靠谱吗？估计等题主熟练掌握了Hadoop、MapReduce、HBase，本科也快结束了。这种问题天生就不适合长答案。对一个初学者，无重点地给出很多资料，除了能打击学习兴趣、扰乱学习目标之外没有任何作用。同意 @Darkscope@苗忆南 等人的答案。题主既然是初学者，就要从简单入手。而大学本科的概率论线性代数对于基本的入手已经足够了。Andrew Ng的课很适合入门，值得看一看，网上的相关资料也很多，例如这个：Machine Learning，写得很详细。如果题主英文水平有限，那可以看一些中文书籍入门。入门之后，对常用算法有了基本了解之后，就可以多学一些原理性知识了，比如统计理论、矩阵理论、信号处理、分布式计算等等。这时排名第一的答案才比较有用。", "answer_votes": "341", "answer_comment": "​16 条评论"}
{"answer_author": "许靖", "answer_id": 27301128, "answer_text": "最近在学teradata的aster数据挖掘工具，果然商业的框架跟hadoop的易学性易用性可拓展性都有天壤之别啊。建议有兴趣的同学自查资料，软件贵的惊人，但是对于自身维护团队水平一般的企业还是值得买的-----------不邀自来，结合我现在的工作以及当年机器学习的经验来讲一下自己的一些感受。首先从机器学习的全流程说起。输入：机器学习按输入数据分可以分结构化数据(表)，半结构化数据(文本，日志等)，非结构化数据(图片，录像)，后两者对应的分支中比较出名分别是文本挖掘和图像挖掘，其实就是通过提取特征的方式 把半结构化数据 非结构化数据转化为结构化数据，然后进行机器学习。按输入数据是否预测状态分，可以分为有监督学习数据及无监督学习数据，直接决定后续模型是使用分类模型还是聚类模型。同时如果数据量到达了T级，就要考虑时候hadoop框架了，这里要说明的是，hadoop框架只是解决大数据处理效率瓶颈的工具，除非你志向是做架构师，不然不用深究，掌握hadoop家族的sql处理工具hive和机器学习工具mahout就可以了，需要掌握java和sql，这是基础。下一步，数据清洗和数据降维，在数据清洗方面不是学术界研究的重点，清洗方法有很多，主要通过描述性统计量填补缺失值和极端值，数据降维方面有较多比较出名的算法，如主成分分析，lasso，LDA线性判别分析，变量聚类等，数据降维是重点，因为维度过大容易产生维度灾难和过度拟合问题。然后是数据分区(有监督学习才需要做)，分成训练集，验证集，测试集，分别用于训练模型，模型内修正，多模型效果对比用。不展开讨论。接着建模，分为分类算法，聚类算法，规则关联算法，分类算法是大头，建议分别拜读支持向量机，概率图模型，神经网络(虽然我不喜欢但是google的深度学习就是用的神经网络)，决策树(C4.5)，逻辑回归(吐槽：线性回归什么的看不看得看个人水平)，混合高斯模型等，聚类算法有KNN，LDA潜在迪力克雷分析(做文本挖掘效果一流)，聚类算法研究不多，大多机器学习算法都是基于有监督学习的，即分类算法。规则关联算法有最简单的规则关联，路径关联分析，及协同过滤(推荐系统首选，输入数据量太大数据太稀疏跑数效率很低一般需要hadoop支持)，模型是机器学习的核心，还有一些优化模型，如EM模型等，建议阅读增加知识广度，要求学习人员要懂以下课程：概率论，高数，线性优化，线性代数还有英文，也可以边看论文边学。书籍的话推荐数据挖掘十大算法作为入门索引，然后根据每章节的参考文献找原文阅读，记得把公式推导一遍。结果评估：本来不应该是重点，但是从个人学习和工作经历发现，有很多人不是很会看模型结果，甚至包括一些专业人士。所以如果有志做机器学习的千万要学会看结果，不然就丢人丢大了。最直接的两个指标准确度percision和召回度recall，分别描述模型的精度和泛化性的，模型结果应在两者取得均衡。最小平方误差也是描述准确度的，算法不一样，大家更喜欢用这个评估模型精度。还有一些K-S值，基尼值，ROC值也是描述准确度和拟合度的，不同的软件会使用不同的指标，注意一下。还有就是提升度，事件捕获率这些就是描述分类预测下前百分之几数据的预测准确性情况的，不展开讨论。最直接的学法就是认真读论文的实验部分，看看它的指标评价量。最后是工具和语言，按现在数据挖掘与机器学习的趋势，必须掌握java，python，原因是hadoop是处理大数据的框架，已成趋势，hadoop是java写的，挖掘工具mahout是java写的。python的好处在于底层基于C，语法简单，效率高，而且有很多开源的算法可以直接用，支持mapreduce。可以选择掌握R，同python，但是R效率木有python高，如果是针对商业分析建议学习SAS，因为它集成了一套专业的数据可视化及数据分析方案，大大方便了数据展示功能，这是作为商业分析所必须的。最后补充一点，很多做数据挖掘和机器学习的人最后都走火入魔执着技术忽略了业务的重要性，忽略了模型可解释性的重要性，埋头苦干做出业务人员不能理解的黑箱模型，无法说服业务使用，最终沦为鸡肋的存在，所以在学习过程中要时刻设想技术适应的业务场景，在算法效果接近时选择高可解释性算法，做好结果的图形化展示，让业务理解，这才是王道。补充，andrew ng的公开课不错，但还是建议先看论文。", "answer_votes": "126", "answer_comment": "​24 条评论"}
{"answer_author": "军师", "answer_id": 215117866, "answer_text": "资源一个比一个多，反而连点开的欲望都没有了。就怕存了那么多资源，依旧学不完一个。（有的还有大量拾人牙慧的二手垃圾，还有人让看csapp和计算机网络的，和机器学习有什么关系。。莫名几百赞。。。不是你写的长就有道理啊老哥。。。知乎变成骗乎了要。。。。黑人问号）入门的难度就被你们这些低信噪比的信息引导到难于上青天了，拜托，只是想入个门而已。。。我提供一个新的角度：乱拳打死老师傅。直接就操练起来，缺啥补啥。后面算法不行补算法，数学不行补数学，Python不熟补Python。语言首选Python（这个原因就不用多说了），直接操练起来一些实际的项目。这块不熟的话可以看一本三百到五百页的Python语法书，比如《Python基础教程 第二版》《Python Cookbook》之类的。《机器学习实战》这门书恰好能给你一个笼统入门的概念（如果算法像我一样稀烂的话）。然后就找个合手的库写具体的项目吧。要被吹上天的西瓜书反正我看起来挺有难度的，数学忘得一干二净。<img src=\"https://pic4.zhimg.com/50/v2-2d30944d8a4a6d1839b06becf573c96c_hd.jpg\" data-rawwidth=\"4267\" data-rawheight=\"267\" class=\"origin_image zh-lightbox-thumb\" width=\"4267\" data-original=\"https://pic4.zhimg.com/v2-2d30944d8a4a6d1839b06becf573c96c_r.jpg\">想找个课程逼着自己操练做个入门的话，可以来景略集智（https://jizhi.im）（简称集智）看看这门课：深度学习之Hello World - 集智课堂 。当然这个是深度学习的，跟机器学习还是有一些区别，不过道理相通，写着写着你就发现，还是得对着某些库的官方文档撸课程里的代码（项目框架和官方doc的互补）。如果本身基础不错的话，深度学习的理论基础 - 集智课堂 这个看过了都说好，而且信息密度比较大。社区还有一些免费的资源（入门指南、数据集之类的）：深度学习资源帖 - 集智社区。有问题还可以发帖提问。<img src=\"https://pic4.zhimg.com/50/v2-2d30944d8a4a6d1839b06becf573c96c_hd.jpg\" data-rawwidth=\"4267\" data-rawheight=\"267\" class=\"origin_image zh-lightbox-thumb\" width=\"4267\" data-original=\"https://pic4.zhimg.com/v2-2d30944d8a4a6d1839b06becf573c96c_r.jpg\">行了，行动吧。", "answer_votes": "119", "answer_comment": "​18 条评论"}
{"answer_author": "知乎用户", "answer_id": 16926630, "answer_text": "coursera上的andrew ng教授的公开课，妥妥的，绝对靠谱 https://class.coursera.org/ml/class/index", "answer_votes": "117", "answer_comment": "​29 条评论"}
{"answer_author": "张戎", "answer_id": 191457222, "answer_text": "之前写过一篇转行的文章，希望对楼主有帮助~转行数据挖掘和机器学习 - 知乎专栏原文来自微信公众号“数学人生”，链接是：转行到数据挖掘与机器学习（三）回头看一下，目前已经从纯数学专业转行到数据挖掘和机器学习领域有一年半了，又到了该总结转行经验的时候。还是那句老话，大牛们请主动忽视以下内容，初学者可以用作参考。［1］编程语言目前工业界的机器学习编程语言很多，基于个人的一些浅显的工作经验，发现目前比较常用的编程语言是 Python 和 HIVE。通常来说，HIVE 是为了从数据库中提取数据，然后进行必要的数据过滤，数据分析，数据提取。对于 HIVE，需要掌握的内容有以下几点：聚合函数，数学函数，字符串函数，表格的连接函数，条件语句等。HIVE 的经典教材有两本，分别是：《HIVE编程指南》，作者 Edward Capriolo《SQL基础教程》，作者 MickPS：个人特别喜欢《SQL基础教程》，极易上手，易学易通。之前写过一篇文章总结 HIVE 的使用细节，提供给大家做参考：《HIVE基础介绍》对于编程语言 Python 来说，目前深度学习的框架 Tensorflow 等，都可以使用 Python 进行编程。除此之外，Python 还有各种各样的数值计算库和机器学习库等着大家去使用，例如 Numpy，Scipy，ScikitLearn，matplotlib 等。其中，Scikitlearn 的文档是非常详细的，特别适合初学者入门学习。至于 Python 教材的话，其实有很多，例如：《Python基础教程》，作者是 Magnus Lie Hetland，这本书特别适合初学者看。如果是网络教材的话，推荐参考 廖雪峰 的官方网站，地址是：Home - 廖雪峰的官方网站至于开发环境的话，一般来说公司都会使用Linux，有一本书可以提供给大家做参考：《Linux命令行与Shell脚本编程大全》，作者 Richard Blum／ Christine Bresnahan既然是处理大数据，那么 MapReduce，Hadoop，Spark 等内容需要了解。参考文章：《一文看懂大数据的生态技术圈，Hadoop，Hive，Spark都有了》［2］机器学习既然是做数据挖掘和机器学习的工作，那每个人都需要了解这方面的内容。在这里笔者推荐教材《机器学习实战》，作者是 Peter Harrington。阅读这本书需要读者掌握 Python 语言，加上 Numpy，Scipy，matplotlib 函数库的一些基础内容。源代码的话可以在网上找到，然后根据书本的章节逐步学习即可。除了《机器学习实战》之外，周志华老师所写的《机器学习》西瓜书也是不错的选择。建议初学者结合这两本书一起学习，周志华老师的《机器学习》介绍了多种机器学习算法，并有简单的例子和数学原理进行描述。既然提到了机器学习，那就简单地总结一下里面的一些算法吧。如果是做推荐业务的团队，那么使用地最多的还是逻辑回归算法（Logistic Regression），ItemCF 和 UserCF，物质扩散和热传导算法（Heat Spreading） 算法。由于 LR 是使用线性的方法来处理非线性的问题，并且实际的环境中会有物品的特征和用户的特征，因此会导致特征工程比较复杂，交叉项多（二维或者三维的交叉）。因此，在实际的工作中，特征工程的作用就显得十分重要。工程师和业务人员要根据物品和用户进行必要的特征构造，形成物品特征，用户特征，交叉特征等。之前也写过一篇文章《特征工程简介》，供大家参考。除此之外，涉及到在线优化的问题，Google 在几年前提出了一个 FTRL 算法。论文是 Ad Click Prediction a View from the Trenches，里面会涉及 SGD 算法，Truncated Gradient 算法，RDA 算法，FOBOS 算法，以及最终的 FTRL 算法等。比逻辑回归算法还要简单的那就是线性回归算法了，目的都是针对连续型的数据进行预测，结果都十分容易解释。除了直接的线性回归之外，还有局部加权线性回归，岭回归，Lasso 和前向逐步线性回归等算法。这些细节可以参考文章《线性回归》。如果是针对转行的同学的话，那么大家肯定关心的是如何把之前的技能平滑地切入到新的领域中。如果学过数理统计的话，那么《最大似然估计》就是一个不错的切入点。除了上面所说的算法，支持向量机算法（Support Vector Machine），GBDT 算法，随机森林算法，XgBoost 算法都是在工业界比较常见的算法。目前个人还没有对这类算法进行过总结，不过还是强烈建议大家去学习一下。2017年笔者应该会对这些算法进行一些个人的总结。无监督学习算法也是整个机器学习领域的一大方向。提到无监督学习算法，就不得不提到聚类算法，其中最经典的还是 Kmeans 算法。这个可以参见文章《聚类算法（一）》。聚类算法的反面就是异常点检测算法，之前在异常点检测算法上面研究过一阵，也写过不少的文章。例如：《异常点检测算法（一）》，《异常点检测算法（二）》，《异常点检测算法（三）》，《异常点检测算法综述》。除此之外，强化学习也是机器学习的一个研究方向。随着 DeepMind 公司的 AlphaGo 打败围棋顶尖选手，能够自动玩游戏的智能 AI，强化学习已经成为了一个比较热门的研究方向。之前写过一篇关于强化学习和泛函分析的小文章《当强化学习遇见泛函分析》，供大家参考。目前深度学习已经成为了机器学习的热门研究方向，无论是卷积神经网络 CNN 还是循环神经网络 RNN，都是研究的主流。之前在学习反向传播算法的时候，写过一篇如何基于 BP 算法训练 RNN 网络的文章《循环神经网络－Reccurent Neural Networks》。［3］数理统计数理统计方面还是有一些东西是蛮常用的。例如时间序列模型 ARMA 模型等。一些数据的指标，例如均值，方差，标准差，变异系数，相关系数，ROC曲线和AUC，召回率和正确率，交叉验证等。［4］业务场景在实际的工作中，最重要的一个因素就是理解业务，只有理解了业务的需求，才能够更好的完成领导所布置的任务。在做事情的时候，一定要形成闭环。那就是：了解业务需求－》调研业界方案－》查看是否适用－》上线效果。通过最终的效果和我们要做成的目标，来反推当前需要做的事情。一些学生时代的思维方式需要逐渐抛弃，参考文章：《开公众号之后的一些感想》。", "answer_votes": "49", "answer_comment": "​2 条评论"}
{"answer_author": "酸性沼泽软泥怪", "answer_id": 24476904, "answer_text": "强烈推荐台大的这门《机器学习基石》。我感觉这门比Andrew Ng的讲得更深入更透彻更直观，而且作业题也需要更多的思考。给个coursera的链接：https://class.coursera.org/ntumlone-001", "answer_votes": "35", "answer_comment": "​3 条评论"}
{"answer_author": "知乎用户", "answer_id": 24983690, "answer_text": "我怎么觉得《统计学习方法》不适合入门呢？有点像中国的教科书，一上来就列很多公式，然后开始一通推导，有些还不如PRML讲得通俗。如果是工程师的话，我觉得Logistic Regression是一个比较适合入门的东西，通过它可以搞懂：1、分类和回归，在这一个算法中都得到了体现；2、正则，从贝叶斯观点理解最大似然和最大后验的区别；3、最优化，最好搞懂如何通过梯度下降或者随机梯度下降得到LR模型参数；4、特征选择，特征转换等特征工程；5、模型评价。从它入手，可以继续深入指数族；通过SGD,可以对不同损失函数去尝试一下优化过程；另外，LR模型应用很广，广告系统和推荐系统都喜欢用这玩意儿。", "answer_votes": "29", "answer_comment": "​3 条评论"}
{"answer_author": "知乎用户", "answer_id": 20919122, "answer_text": "分听课和看书两个部分来说：入门：视频可以看coursera上Andrew Ng的machine learning课书国内的可以看李航的统计学习方法，综合了老外的基本ML经典，写得浅显易懂，书也比较薄，好读，学习曲线不会太陡。国外的建议先看pattern classification，较其他的简单一些。进阶：视频的话可以看看coursera上的一些数值计算和最优化课程书老外的大部头多了，经典的比如PRML（patten recognition and machine learning），elements fo statistical learning（此书虽名叫基础，实则十分艰深难读，不推荐初学者学习）。这两本都能读完且读懂了，那是看最前沿的ml的paper也不会发怵了", "answer_votes": "17", "answer_comment": "​3 条评论"}
{"answer_author": "史博", "answer_id": 278717270, "answer_text": "我觉得结合你具体的目的才能决定你入门的好路子。  如果你学习机器学习是为了进入数据处理的行业。 那么我觉得宏观上对各种模型的一个了解会让你有一个概念了解。 然后再细化学习每个部分。 一般数据处理的流程如下：<img src=\"https://pic4.zhimg.com/50/v2-da3947c3a30b1aa620e3c45b22134f75_hd.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"926\" data-rawheight=\"488\" class=\"origin_image zh-lightbox-thumb\" width=\"926\" data-original=\"https://pic4.zhimg.com/v2-da3947c3a30b1aa620e3c45b22134f75_r.jpg\">但是花的时间少，不代表要求低， 只是要求能够熟练高效的应用。  这里给出部分模型对比的思考， 抛砖引玉， 帮助大家熟练高效， 祝各位能在10%的时间显示出90%的实力。 常见学习模型对比和选择有监督还是无监督  Supervised VS Unsupervised这个对比很明显， 但是目前强化学习（reinforcement learning）的横空出世， 或许有一天这些都不对了。 <img src=\"https://pic4.zhimg.com/50/v2-2c4a9cebf7b368509c901162917c672b_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"960\" data-rawheight=\"659\" class=\"origin_image zh-lightbox-thumb\" width=\"960\" data-original=\"https://pic4.zhimg.com/v2-2c4a9cebf7b368509c901162917c672b_r.jpg\">线性还是非线性 Linear VS Non-Linear如何把未知问题转化成已知问题， 如何把非线性转化成线性， 永远是很很需要的。 <img src=\"https://pic4.zhimg.com/50/v2-af851a7114ee79167483964e980f29f8_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"956\" data-rawheight=\"605\" class=\"origin_image zh-lightbox-thumb\" width=\"956\" data-original=\"https://pic4.zhimg.com/v2-af851a7114ee79167483964e980f29f8_r.jpg\">有没有先验 With VS Without Prior对于先验到底有没有决定性作用， 贝叶斯派和非贝叶斯派还没有完全说服对方， 譬如深度学习的Hinton就说自己扬弃了先验（参考 攒说 Geoff Hinton ）。<img src=\"https://pic4.zhimg.com/50/v2-bea734b01da752bb091fb75051b1baad_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"941\" data-rawheight=\"618\" class=\"origin_image zh-lightbox-thumb\" width=\"941\" data-original=\"https://pic4.zhimg.com/v2-bea734b01da752bb091fb75051b1baad_r.jpg\">是不是非参模型 Parametric VS Non-Parametric有些人要傻傻的不知道背后搞什么的编辑器（Word），有些人要可以控制一切的编辑器（Latex）， 所以参不参看需求了， 或许跟视窗系统（Windows）横行一样， 非专业人士更喜欢非参吧。 <img src=\"https://pic4.zhimg.com/50/v2-6049a9b7be9b440dffc823e2a30cdfea_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"942\" data-rawheight=\"592\" class=\"origin_image zh-lightbox-thumb\" width=\"942\" data-original=\"https://pic4.zhimg.com/v2-6049a9b7be9b440dffc823e2a30cdfea_r.jpg\">有没有集成学习 Single VS Ensemble引领一个10年的机器学习的突破，依然宝刀未老的集成学习，尤其对于表数据分析。  <img src=\"https://pic4.zhimg.com/50/v2-65e72ed38b29f57decdace75b147668b_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"939\" data-rawheight=\"518\" class=\"origin_image zh-lightbox-thumb\" width=\"939\" data-original=\"https://pic4.zhimg.com/v2-65e72ed38b29f57decdace75b147668b_r.jpg\">深浅学习 Shallow VS Deep有个文章叫“THE NEURAL NETWORK ZOO” （http://www.asimovinstitute.org/neural-network-zoo/?_utm_source=1-2-2）， 去动物园看看，蚯蚓和蛇一样很重要， 但是蛇更吓人。  <img src=\"https://pic4.zhimg.com/50/v2-a28e3581240a8612281c61fe33389523_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"946\" data-rawheight=\"637\" class=\"origin_image zh-lightbox-thumb\" width=\"946\" data-original=\"https://pic4.zhimg.com/v2-a28e3581240a8612281c61fe33389523_r.jpg\">在不在线 Online VS Offline分工越来越细， 在线学习的发展， 离不开 H. Brendan McMahan 博士（CMU毕业，Google工作， 户外运动达人）在这个领域的坚持。 <img src=\"https://pic3.zhimg.com/50/v2-c148583683d901a6da41a72cfeac3977_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"951\" data-rawheight=\"590\" class=\"origin_image zh-lightbox-thumb\" width=\"951\" data-original=\"https://pic3.zhimg.com/v2-c148583683d901a6da41a72cfeac3977_r.jpg\">大数据还是大计算 Huge Quantity VS Heavy Computation求各种大数据小计算， 小数据大计算的经典案例。 <img src=\"https://pic2.zhimg.com/50/v2-5fea9fd9dee5bceb770c35457b5cd82a_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"755\" data-rawheight=\"643\" class=\"origin_image zh-lightbox-thumb\" width=\"755\" data-original=\"https://pic2.zhimg.com/v2-5fea9fd9dee5bceb770c35457b5cd82a_r.jpg\">并行，分布和异步 Parallel VS Distributed VS Asynchronous学分布式的都发达了， 可惜我去学Service了， 哭的一塌糊涂。 <img src=\"https://pic1.zhimg.com/50/v2-bdc36768df0e5c3974385dfec9fca6bc_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"866\" data-rawheight=\"550\" class=\"origin_image zh-lightbox-thumb\" width=\"866\" data-original=\"https://pic1.zhimg.com/v2-bdc36768df0e5c3974385dfec9fca6bc_r.jpg\">如何选择一个学习模型？在这些模型认识的基础上， 然后就要思考如何选择了，做好一个选择， 需要对数据有认识（Data）， 但这还是不够的， 还需要对需求有把握（Quality of service， QoS）， 但这也是不够的， 还需要对应用人员的知识有掌握（Knowledge）。 <img src=\"https://pic4.zhimg.com/50/v2-1ad386c9a1a1ac3c17c4b45bd9f7b5ed_hd.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"946\" data-rawheight=\"552\" class=\"origin_image zh-lightbox-thumb\" width=\"946\" data-original=\"https://pic4.zhimg.com/v2-1ad386c9a1a1ac3c17c4b45bd9f7b5ed_r.jpg\">如果所有问题都能很清晰的回答， 再回到前面模型的对比中进行选择， 或许会有所收获。 当然这里所有的说法， 都是技术出发， 但是我们知道好的业务数据分析是要从业务本身需求出发， 别忘记了服务于业务本身！", "answer_votes": "82", "answer_comment": "​5 条评论"}
{"answer_author": "路人甲", "answer_id": 98172388, "answer_text": "分享机器学习学习资料（需要的自己拿去）：&lt;img data-rawheight=\"198\" data-rawwidth=\"655\" src=\"https://pic2.zhimg.com/50/be6727a4bfbe267b9a3047968746b144_hd.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"655\" data-original=\"https://pic2.zhimg.com/be6727a4bfbe267b9a3047968746b144_r.jpg\"&gt;链接: http://pan.baidu.com/s/1c2iCrM4 密码: f3fa&lt;img data-rawheight=\"229\" data-rawwidth=\"688\" src=\"https://pic1.zhimg.com/50/f3b8dfbb3856ee1d62cda32dee6674e8_hd.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"688\" data-original=\"https://pic1.zhimg.com/f3b8dfbb3856ee1d62cda32dee6674e8_r.jpg\"&gt;链接: http://pan.baidu.com/s/1c1TdmSg 密码: 4rb4&lt;img data-rawheight=\"383\" data-rawwidth=\"286\" src=\"https://pic3.zhimg.com/50/594d8959553e709da290aef9d85fe647_hd.jpg\" class=\"content_image\" width=\"286\"&gt;链接: http://pan.baidu.com/s/1kVjJVaZ 密码: 47dc以上所有文件解压密码：链接: http://pan.baidu.com/s/1o8MT194 密码: tya2需要更多其它学习资料可以私信我，有空就回。欢迎关注我，别光顾着收藏。欢迎关注我的专栏：https://zhuanlan.zhihu.com/passer", "answer_votes": "68", "answer_comment": "​26 条评论"}
{"answer_author": "夕小瑶Elsa", "answer_id": 145940108, "answer_text": "-----2月20日更新------阶段三也发布啦，直接贴链接了～http://mp.weixin.qq.com/s/yNLH0YSIw2pFxBPDOPwpGQ觉得有用记得帮小夕点赞哦-----情人节更新-----下阶段内容已经在订阅号更新了，急需的朋友可以去小夕的订阅号查看哦。ps：重新排版好麻烦QAQ小夕这几天忙哭了呜呜，过几天再给大家同步到这里哦。-----原回答-----不知道现在回答还有没有人看呢。。。最佳阅读体验见原文链接《史上最萌最认真的机器学习/深度学习/模式识别入门指导手册(一)》；《史上最萌最认真的机器学习/深度学习/模式识别入门指导手册(二)》。小夕的车辙小夕从大二开始做人脸识别，后来发现很快遇到了瓶颈。于是开始学机器学习理论，又很快遇到了瓶颈，于是又开始补数学。补完数学又钻模式识别，又被虐了，但还是辛苦的啃完了《模式分类》。后来学深度学习。再后来不停的论文论文论文、代码代码代码...由于小夕是从工程出发然后到理论，再回工程的道路，小夕觉得这样走的弯路挺大的。而且前期做工程的时候真的很懵逼，各种看不懂然后跳过。所以小夕这里分享给大家的道路是从理论到工程的平坦上升的道路。当然啦，理论中肯定会穿插代码实践。小夕希望这是一条靠谱的、没有知识断层的深度学习/机器学习的入门之路，希望能在真正意义上帮到大家。前言本指导适合于真正有志于钻研机器学习（含深度学习）、模式识别及其相关应用领域的人。对于那种“1个月入门机器学习”的大忽悠学习模式，小夕这里没有噢~理论上说，完全小夕的整个入门指导后，应对整个机器学习大框架、理论细节、工程能力都有了比较好的积累。在此之后可以偏向工程，轻松玩TensorFlow、Caffe等DL框架，转CV、NLP等应用性更强的方向；也可以偏向理论，比较轻松的看看最新的paper，跟上学术界的最前沿。但是工程与理论不是绝对割裂的哦，偏工程也要看论文、补数学，偏理论也要敲代码、了解优秀框架哦。首先，在开始之前，要确保有以下的理论基础：语文能力最少达到初中水平。英语能力最少要达到高中优秀水平，尽量在大学四级水平之上。数学最少达到高中水平，微积分一定得学过。尽量有以下的工程基础（这样可以边学边练，体会更深的喵，但是不会也没有关系的）面向过程编程范式常见数据结构常见算法思想及算法分析能力然后小夕为了避免文章过长，将计划截成了四五个阶段。本文为第一阶段。阶段一 线性代数前置课程中学代数主参考资料《线性代数应该这样学》(英文叫《Linear Algebra done right》)辅助参考资料（有先后顺序）《Deep Learning》Bengio等，第二章（中译本勉强能看，链接https://github.com/exacity/deeplearningbook-chinese 呜呜好想赶紧开通原创功能插超链接）；Wiki百科（翻墙不用教吧...）；《矩阵分析与应用》张贤达重点内容（无先后顺序）：向量及向量空间内积与范数线性映射矩阵    张成、线性相关、线性无关特征值与特征向量特征分解高级内容（最起码要了解）：谱定理奇异值分解（SVD）矩阵的迹行列式学习方法适当参考小夕总结的重点内容，细细的品味《线性代数应该这样学》（这本书真的棒呆了）。对于书中依然理解不了的部分，参考其他辅助资料哦。另外如果大家有哪方面难以理解，可以告诉小夕，小夕会尽量解答，若有必要的话直接写一篇小文章帮助大家理解哦。主要意义线性代数是机器学习的不能更基础的数学基础。不仅仅是因为矩阵是机器学习中运算的基本单位，而且一些线性代数中的高级理论也被借鉴吸收到了机器学习算法中，比如用SVD（奇异值分解）来对特征降维，迹运算可以加深对PCA及某些聚类算法本质的理解等。Matlab前置课程线性代数面向过程编程范式主参考资料：Coursera平台斯坦福大学Andrew Ng的“机器学习”课程的Matlab章节的视频及补充资料Matlab内嵌帮助文档辅助参考资料GoogleCSDNStackOverFlow重点内容：Matlab基本语法矩阵运算常用的内置API（即用户编程接口/函数接口）学习方法参考Coursera平台“机器学习”课程的Matlab教学视频及阅读材料来掌握Matlab基础知识。养成使用Matlab内嵌帮助文档来学习新API的方法的习惯。例如在解释器中可以用“help +命令”或“doc +命令”快速掌握某API的用法等。多多总结积累常用的矩阵运算API。主要意义利用Matlab入门和理解机器学习算法，可以很大限度的忽略编程语言语法特性对算法实现的影响，也就是说语法对数学表示的还原度很高~这样可以很轻松的打通数学到计算机算法的桥梁，对于以后深入学习机器学习的理论和代码实现都大有裨益。机器学习-上前置课程线性代数微积分Matlab主参考资料：Coursera平台斯坦福大学Andrew Ng的“机器学习”课程《数据挖掘导论》重点内容：机器学习基本概念及应用领域回归与分类的概念线性回归模型(Linear regression model)逻辑回归模型(Logistic regression model)浅层神经网络(Neural Network)支持向量机（Support Vector Machine）交叉验证思想及用途(Cross Validation)聚类的概念K-Means模型学习方法乖乖的跟着Coursera课程计划来就好，要认真完成课后习题和编程题哦。若课程中的有些内容实在没有理解透，强烈建议参考《数据挖掘导论》中的相关章节呐（这本书对于机器学习部分的讲解很好喵）。小夕注： Matlab代码实现中多多体会和建立“用矩阵运算”解决问题的思想，努力摆脱“循环套循环”的low做法。Coursera结束后，仔细阅读《数据挖掘导论》中的第4、5章。先跳过其中的决策树和贝叶斯分类器那一节（以后的计划中会安排的哦），另外第五章的组合方法能看懂就看，看不懂也没关系，放在以后还会深入学。主要意义Coursera上的“机器学习”课程中几乎没有涉及到概率统计的知识，自然也没有贝叶斯分类器这个经典统计模型。同时也没有深入讲解最优化的知识。不过这样极大的降低了课程的难度，非常适合拿来快速接触机器学习又不会受很大打击。对于提升兴趣，以及后续理论深入的学习真的很有帮助呀，小夕当年就是看了这个视频然后爱上了可爱的Andrew Ng，然后爱上了这一领域\\(//∇//)\\。而《数据挖掘导论》也非常适合新手入门，讲解的十分浅显易懂，在Coursera课程结束后再根据这个复习一遍，效果会非常好的。下阶段预告概率论与数理统计最优化算法-上机器学习-下注：版权归微信订阅号【夕小瑶的卖萌屋】所有，未经许可禁止转载。推荐阅读：《请某些人不要再冒充内行 过分夸大深度学习了好不好喵》", "answer_votes": "121", "answer_comment": "​11 条评论"}
{"answer_author": "Frank Chu", "answer_id": 126901054, "answer_text": "推荐一些ML方面的书籍，下面是我之前的一个回答：作者：Frank Chu链接：机器学习书籍选择? - Frank Chu 的回答来源：知乎著作权归作者所有，转载请联系作者获得授权。机器学习 机器学习 by 周志华: 周志华老师的这本书非常适合作为机器学习入门的书籍，书中的例子十分形象且简单易懂。统计机器学习 by 李航：李航老师的这本书偏优化和推倒，推倒相应算法的时候可以参考这本书。PRML by Christopher Bishop: PRML这本书有点偏Bayesian了，初学者看起来可能有些困难，可以和前两本结合起来看。GPCA by Yi Ma: 这本书由马毅老师耗时十年精心打造，推荐阅读。Machine Learning A Probabilistic Perspective Learning by Kevin P. Murphy: MLAPP这本书也是一本比较经典的机器学习书，可以和PRML互相补充着来看。自然语言处理数学之美 by 吴军：吴军老师的这本书适合作为入门自然语言处理的科普读物。统计自然语言处理 by 宗成庆：中文版的自然语言处理图书是比较少的，这本书由中科院宗成庆老师所写，推荐初学者先阅读此书。Foundations of Statistical Natural Language Processing by Christopher D. Manning: 本书由Manning大神所写，在1999年出版，最近比较火的Deep Learning for NLP没有涉及，不过可以参考他的学生Socher开的这门课 CS 224N / Ling 284。Speech and Language Processing by Dan Jurafsky: 这本书第三版已经更新一部分章节了，书中介绍了deep learning for nlp方面的技术，推荐阅读。", "answer_votes": "13", "answer_comment": "​添加评论"}
{"answer_author": "ApacheCN", "answer_id": 248678328, "answer_text": "提问者，你好，如果你不是科班出身，首先我不建议你去听一些非常理论的课程，例如：Andrew Ng的machine learning课，不是说他不好，是的确不太适合 Coding 出生的入门者。我收藏过很多套视频，但是没一套适合Coding小白！以下是我的学习路程：首先说一本书：《机器学习实战》经典的不能再经典的书！！！适合喜欢Coding的小伙伴，从代码的角度讲述，机器学习要学习的东西和项目，并且使用的是Python，非常简单。【当然你的懂一些Python语法】，完整录制了2期视频《机器学习实战-讨论版》和《机器学习实战-教学版》，GitHub地址：apachecn/MachineLearning 【现在已经 300 颗 star】，不怕你笑话，在录制课程的时候，我们就是几个小白聚集在一起。视频在：优酷、A站、B站 都是在线观看的，而且就是今年从0录制的，在Github上搜索：MachineLearning 排名在第一页，教程目录我觉得非常有套路。【注意：我们是几个热心的开源贡献者一起参与录制的】1. 循序渐进大体介绍： 机器学习初学者建议 | ApacheCN 2. 干货内容实际操作：MachineLearning(机器学习) 学习路线图 以下为 2 学习路线图 中的目录结构：第一部分 分类1.) 机器学习基础2.) k-近邻算法3.) 决策树4.) 基于概率论的分类方法：朴素贝叶斯5.) Logistic回归6.) 支持向量机7.) 集成方法-随机森林和AdaBoost第二部分 利用回归预测数值型数据8.) 预测数值型数据：回归9.) 树回归第三部分 无监督学习10.) 使用K-均值聚类算法对未标注数据分组:k-means聚类11.) 使用Apriori算法进行关联分析12.) 使用FP-growth算法来高效发现频繁项集第四部分 其他工具13.) 利用PCA来简化数据14.) 利用SVD简化数据15.) 大数据与MapReduce看完目录，你觉得还是有难度，没事：我们整合已经在 Github: apachecn/MachineLearning   好了 “文档+代码+数据+视频” 【为此，还申请了知乎专栏：机器学习实战，内容和GitHub 保持着同步，有兴趣也可以关注这里】，如果看完你还说“机器没法入门”， 那我就承认我输。--- 不好意思，可能录制的视频标题不是那么高大上，但是你可以看懂：<img src=\"https://pic4.zhimg.com/50/v2-95c78cbb52dfd16dbfd8d9e4ce3fc6ff_hd.jpg\" data-caption=\"\" data-rawwidth=\"911\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb\" width=\"911\" data-original=\"https://pic4.zhimg.com/v2-95c78cbb52dfd16dbfd8d9e4ce3fc6ff_r.jpg\">当然也有不好的地方，我相信在后期我们一起学习的过程中会迭代维护得更好。--- 还是想吐槽一下，这个现象：（算术入门简单吧？那么例题呢？试试看，然后一把梭的公式就来了）<img src=\"https://pic1.zhimg.com/50/v2-c3f9746dc056c99225d00163426d8ca8_hd.jpg\" data-caption=\"\" data-rawwidth=\"600\" data-rawheight=\"734\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic1.zhimg.com/v2-c3f9746dc056c99225d00163426d8ca8_r.jpg\">华丽的分割线  -------------------------------------------------------------------“机器学习” 我们下一个计划看到这里，如果你还敢兴趣，对我们。那么补充我再话痨一下，关于“机器学习” 我们下一个计划。现在我们正在做的事情：翻译：scikit-learn（sklearn）0.19 中文文档的翻译计划，邀请你的加入 | ApacheCN 校验：scikit-learn（sklearn） 0.19 中文文档的校验活动，邀请你的加入 | ApacheCN我们不是最牛逼的人，但是我们是愿意为机器学习的开源社区作出贡献的一份力量。组织翻译过的文档TensorFlow R1.2 中文文档: http://cwiki.apachecn.org/pages/viewpage.action?pageId=10030122Sklearn 0.19 中文文档: http://sklearn.apachecn.org/cn/0.19.0/Sklearn 0.18 中文文档: http://cwiki.apachecn.org/pages/viewpage.action?pageId=10030181Apache Beam 中文文档: http://beam.apachecn.org/Apache Spark 2.2.0 中文文档: http://spark.apachecn.org/docs/cn/2.2.0/Apache Spark 2.0.2 中文文档: http://cwiki.apachecn.org/pages/viewpage.action?pageId=2883613Apache Storm 1.1.0 中文文档: http://storm.apachecn.org/releases/cn/1.1.0/Apache Kudu 1.4.0 中文文档: http://cwiki.apachecn.org/pages/viewpage.action?pageId=10813594Apache Zeppelin 0.7.2 中文文档: http://cwiki.apachecn.org/pages/viewpage.action?pageId=10030467Elastic Elasticsearch 5.4 中文文档: http://cwiki.apachecn.org/pages/viewpage.action?pageId=4260364Elastic Kibana 5.2 中文文档: http://cwiki.apachecn.org/pages/viewpage.action?pageId=8159377如果你愿意，欢迎你的加入，一起来参与和完善 机器学习之路。。如果你非要捐赠我们的，那么可以多点一颗 star，多帮忙分享一下好的内容给朋友。另外，如果对微博感兴趣的，也可以关注我们 ApacheCN 官方微博  Thanks !!!", "answer_votes": "448", "answer_comment": "​50 条评论"}
{"answer_author": "米老虎", "answer_id": 154998685, "answer_text": "看这么多吓人的故事，我讲个励志故事。前公司一大叔，技术主管，数学渣，机器学习更是0基础，但是十年coding经验。去年听说深度学习很火热，于是1个月时间学完NG课程，1个多月把Deep Learning看完，就屁颠屁颠去调模型了。我问他DL书里的数学怎么处理的，他说看不懂的直接跳过，不记得跳了多少东西，反正没觉得因此在工作中遇到多少障碍。现在他组里招了两个博士生，帮他做项目。其实学习也有个80/20定理，你80%的时间都在啃20%的内容，而这20%的内容并可能不是重点，只是出于强迫症的需要，你觉得一定要搞定才敢去搞其他的，或者觉得“才有资格”去搞其他的。而在他们心中一定是看不起那些跳着搞的。但是在这个知识爆炸的年代，摒弃严谨也是一种重要的能力。嗯，是能力。比如，啃书的时候，看到一个知识点不懂，能不能放过他，硬着头皮继续啃剩下的内容？很多人做不到，包括我。尤其是看到剩下的部分中冷不丁地又提到前面你没看懂的东西，你那种内心的焦虑和狂躁感，或者说自尊心的屈辱感，总是在诱惑你去把那部分彻底搞明白，是不是？这叫学霸病，是病，得治！一提到流形，你就想去学泛函，一看泛函，怎么那么多实变的东西，于是又买本实变，实变函数学十遍啊！啊，还是头痛，于是去搞本苏联人的数学分析，你看，掉坑里出不来了把。这何止是80/20，简直是80000/20000！（你看，你又要跟我计较80000/20000=80/20，顺便喷我一句数学老师是体育课教的才开心，明白我要表达啥意思就行了呗）但如果能抵制住这种诱惑，你就能顺利地从沼泽里跳出来，20%时间掌握了80%的内容，而且很可能你并不那么需要剩下的20%。所以，路线我已经告诉你了，先上ng的课，再粗粗啃一遍dl（或其他你需要的方向的一本书）。嗯，可以了，干活去吧。啊，什么，你不会写程序。。。。好吧。", "answer_votes": "224", "answer_comment": "​38 条评论"}
{"answer_author": "蜗牛学院", "answer_id": 260577298, "answer_text": "写这篇文章的初衷是大部分私信我的朋友都想了解如何入门/转行机器学习，搭上人工智能这列二十一世纪的快车。再加上这个问题每隔一阵子就会在知乎时间线上出现一次，因此想写一篇文章来“一劳永逸”的分享我的观点。原作者： @阿萨姆原链接：https://zhuanlan.zhihu.com/p/29704017 原出处：知乎文章的宗旨是：指出一些自学的误区 不过多的推荐资料 提供客观可行的学习表 给出进阶学习的建议这篇文章的目标读者是计划零基础自学的朋友，对数学/统计基础要求不高，比如：在读的学生朋友非计算机行业的读者已经工作但想将机器学习/数据分析和自己的本职工作相结合的朋友因此，这篇文章对于已经身处机器学习领域可能帮助不大。同时再次声明这只是我的个人看法，请大家有选择的性阅读，探索适合自己的学习方法。<img src=\"https://pic4.zhimg.com/50/v2-1cdfe6b526289c21ca209eedefedcc02_hd.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"361\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic4.zhimg.com/v2-1cdfe6b526289c21ca209eedefedcc02_r.jpg\">1. 自学机器学习的误区和陷阱1.1. 不要试图掌握所有的相关数学知识再开始学习在很多相关的回答中，我都一再强调不要试图补足数学知识再开始学习机器学习。一般来说，大部分机器学习课程/书籍都要求：线性代数：矩阵/张量乘法、求逆，奇异值分解/特征值分解，行列式，范数等统计与概率：概率分布，独立性与贝叶斯，最大似然(MLE)和最大后验估计(MAP)等优化：线性优化，非线性优化(凸优化/非凸优化)以及其衍生的求解方法如梯度下降、牛顿法、基因算法和模拟退火等微积分：偏微分，链式法则，矩阵求导等信息论、数值理论等一般人如果想要把这些知识都补全再开始机器学习往往需要很长时间，容易半途而废。而且这些知识是工具不是目的，我们的目标又不是成为运筹学大师。建议在机器学习的过程中哪里不会补哪里，这样更有目的性且耗时更低。1.2. 不要把深度学习作为入门的第一门课虽然很多人都是冲着深度学习来的，但把深度学习作为机器学习第一课不是个好主意。原因如下：深度学习的黑箱性更加明显，很容易学得囫囵吞枣深度学习的理论/模型架构/技巧还在一直变化当中，并未尘埃落定深度学习实验对硬件要求高，不太适合自学或者使用个人电脑进行学习更多讨论可以看我的回答：阿萨姆：深度学习的教学和课程，与传统 CS 的教学和课程有什么区别？1.3. 不要收集过多的资料 & 分辨资料的时效性机器学习的资料很多，动辄就有几个G的材料可以下载或者观看。而很多朋友都有“收集癖”，一下子购买十几本书的人我也常常能够看到。机器学习的发展和变化速度很快。在入门期间，建议“小而精”的选择资料，选择近期出版的且口碑良好的书籍。我不止一次的提到这个例子：在很多深度学习的教科书中，尤其是10年以前的教科书中都还依然把Sigmoid当作默认的激活函数。但事实上，整流函数(ReLu)以及其拓展变形函数，如Leaky ReLu早就成为了主流的深度学习激活函数。但因为知识的滞后性，很多课程/书籍甚至都没有介绍ReLu的章节。一般来说，我比较推荐近5年内出版的书籍，或者10年以后出版的书籍。有些书籍虽然是经典，比如Tom Mitchell的《机器学习》，但因为其出版已经超过20年，还是不建议大家购买。在这篇文章中我所推荐的书籍和课程都相对比较经典，同时属于紧跟时代潮流的。入门阶段我推荐了1门课程和2本书，进阶阶段推荐了1本书，深度学习推荐了1门课程一本书，高级阶段推荐了2本额外书籍。2. 机器学习的一些前期准备2.1. 硬件选择另一个大家常问的问题是：是否可以用自己的笔记本电脑进行机器学习。答案是肯定的，大部分市面上的数据集都可以放到你的内存中运行。在入门阶段，我们很少会用到非常大的数据集，一般最大也就是MNIST，完全可以使用个人笔记本电脑进行运行。请不要打着学习的名义重新购买机器...2.2. 软件选择如果要做深度学习，Linux还是首选，因为其对很多学习模型支持比较好（主要是深度学习的Library）。但即使你使用的是Windows系统，也可以用虚拟机装Ubuntu来进行学习。小型的深度学习模型足够了，大型的深度学习我们很少在本地/个人计算机上运行。至于编程语言，首推Python，因为其良好的拓展支持性，主流的工具包都有Python版本。在特定情况下，选择R作为编程语言也是可以的。其他可能的语言还包括C++、Java和Matlab，但我个人不大推荐。此处也想额外提一句，因为编程属于机器学习基本要求之一，所以推荐大家可以自学一些基础编程的知识(如Python)，在文中不再赘述。2.3. 语言能力学好英语，至少打下阅读和听力的基础。虽然人工智能领域中国现在已经做得很不错，但主流的书籍、期刊和会议，资料都是英文的。我们可以接受翻译版，但最好的方法还是自己有能力直接阅读。即使你将来不做机器学习，英文阅读能力还是会有很大的帮助。3. 机器学习课程表3.1. 第一阶段：基础入门(3-6个月)入门的第一步是学习一些经典课程并配套经典书籍，一般来说这个过程在半年之内比较合适。在这个部分我介绍的课程和书籍都属于难度非常低的，对数学和编程都没什么太大的要求。3.1.1. 吴恩达Cousera机器学习课程Andrew Ng的机器学习课程（Machine Learning | Coursera）是很多人的启蒙课程，难度适中且完全免费。Coursera上总共有49285个人给出了评分，平均得分4.9分，满分5分。据我个人观察，大部分Coursera上的课程评分处于4-4.5分之间，能做到4.9分的课程寥寥无几。另一个值得关注的是，这门课有接近五万人给出评分，统计学知识告诉我们这个样本较大所以评分应该趋近于其真实值，比较可信。根据Freecodecamp的统计，这门课是所有在线Machine Learning课程中最受到大家好评的课程。另一个比较直接的观察是如果大家在知乎上搜索“机器学习如何入门？”，大部分答案都提到了Andrew的这门入门课程，所以这是一门绝对的口碑课程。3.1.2. Python机器学习 & Introduction to Statistical Learning with R在学习吴恩达的在线课程时，推荐同时阅读相关的机器学习书籍补充理论知识。我再次推荐这两本非常好的入门书籍，在我的专栏也有对于这两本书的介绍。Python机器学习：这本书出版于2015年并多次再版，在亚马逊中国上我们可以找到影印版和翻译版。这本书去掉了大量的数学推导的部分，仅保留了机器学习的核心应用。阅读本书可以快速对如何使用Python机器学习框架Sklearn有一个基本的了解，可以很快上手开始工作。本书涉及的内容很广泛，虽然只有400多页，但内容涉及了数据预处理(Data Preprocessing), 维度压缩和核函数(Dimension Reduction & Kernel)，评估方法如交叉验证，集成学习，情感分析，聚类，甚至还包括了神经网络和Theano。更多介绍：带你读机器学习经典(三): Python机器学习(Chapter 1&2)Introduction to Statistical Learning with R（ISL）：相信正在机器学习苦海中遨游的朋友们肯定都听过大名鼎鼎的The Element of Statistical Learning, 这本频率学派的统计学习“圣经”被大家叫做ESL。而ISL正是基于满足更广大阅读人群的目的而推出的；ISL是ESL的入门版，不仅大量的去除了繁复的数学推导，还加入了R编程的部分，方便大家可以尽快上手。这本书是我推荐书单第一名：ISL的电子版是免费的：点击下载。更多介绍：带你读机器学习经典(一): An Introduction to Statistical Learning (Chapter 1&2)3.1.3. 周志华《机器学习》周志华老师的《机器学习》也被大家亲切的叫做“西瓜书”。虽然只有几百页，但内容涵盖比较广泛。然而和其他人的看法不同，我建议把西瓜书作为参考书而不是主力阅读书。西瓜书因为篇幅的限制，涵盖了很多的内容但无法详细的展看来讲，对于初学者自学来说实际阅读很大。这本书更适合作为学校的教材或者中阶读者自学使用，入门时学习这本书籍难度稍微偏高了一些。我个人建议的用法是在学习网课和阅读ISL遇到疑惑时可以参考西瓜书的相关章节，但入门阶段没有必要一章一章的阅读，建议在这个阶段只阅读前十章即可。3.2. 第二阶段：进阶学习(3-6个月)在这个阶段，你已经对机器学习有了基本的了解。如果你认真的阅读了ISL并上完了吴恩达的课程，我相信你已经在理论上明白了什么是线性回归，什么是数据压缩，对特征工程以及简单的回归/预测问题有了理论上的基础。这个时候最重要的就是进行实践！3.2.1. Kaggle挑战赛/练习Kaggle（Your Home for Data Science）在数据分析领域早已大名鼎鼎，甚至可以说是数据分析第一社区，前一阵子刚刚被谷歌收购。Kaggle上有很多很好的数据集和挑战赛，你可以尝试这些挑战取得名次，甚至拿到奖金，对于将来找工作也非常有帮助。而且Kaggle的另一大优势是网友会分享他们的经验和看法，你也可以提出问题让大家来帮你提出一些修正方法。国内也有类似的平台，比如天池大数据竞赛，其他类似的平台还包括DataCastle。使用Kaggle的目的主要是将技能落在实处，防止练就一身屠龙之技。机器学习最大的幻觉就是觉得自己什么都懂了，但等到真的使用时发现并不奏效，而Kaggle是一个低成本的应用机器学习的机会。3.2.2. Sklearn文档学习Sklearn(scikit-learn: machine learning in Python)是Python上最流行的机器学习/数据科学工具包，上文介绍的Python Machine Learning书中就大量使用Sklearn的API。和使用Kaggle的目的一致，学习的Sklearn的文档也是一种实践过程。比较推荐的方法是把主流机器学习模型Sklearn中的例子都看一遍。Sklearn的文档是少数写的跟教程一样的技术文档，很具有阅读价值。举个简单的例子，假设你想学习Python中使用逻辑回归，就可以参考: Logistic Regression 3-class Classifier<img src=\"https://pic4.zhimg.com/50/v2-a22ac489e184ca02342f622673380bb6_hd.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"300\" class=\"content_image\" width=\"400\">Sklearn的文档不仅提供了练习数据、sklearn的相关代码实例，还提供了可视化图。3.2.2. 周志华机器学习再次提到周老师是因为西瓜书是值得常常翻看的一本书，在kaggle挑战和阅读Sklearn文档的过程中你还会时不时的遇到一些新的名词，比如流形学习(manifold learning)等。这个时候你会发现西瓜书真的是一本中级阶段大而全的书籍:)3.3. 第三阶段(可选*)：深度学习(3-6个月) 因为深度学习是当下的热点，很多公司都在寻找深度学习人才。虽然深度学习只是机器学习的一个子集，但有兴趣朝这个方向发展的朋友可以在完成以上学习后单独学习一下深度学习。3.3.1. 吴恩达深度学习课程吴恩达在八月份的时候通过Deeplearning.ai和Coursera平台推出了最新系列的五门深度学习课程(deeplearning.ai)。有条件的朋友可以通过Coursera学习获得证书，最近网易云课堂也上线了这门课的翻译版。如果想要上其中的课程，需要先注册报名「深度学习工程师微专业」 深度学习工程师微专业 - 一线人工智能大师吴恩达亲研-网易云课堂 - 网易云课堂，之后就可以分别点开每门课单独进行学习。和Coursera上的DL同步，现在云课堂也上线了五门中的前三门课程，而卷积网络(CNN)和循环网络(RNN)还未开放。更多关于网易云课堂上深度学习课程的介绍可以看：阿萨姆：如何评价网易云课堂上线的吴恩达Deep Learning课程？3.3.2. Deep Learning -  by IanGoodFellow深度学习这本书是由当下深度学习领域的几位领军人物所著，包含三大巨头之一的Bengio，还有教父Hinton来作序推荐。这本书的中文本翻译由张志华教授团队负责，在github上免费放出了翻译版本，印刷版也可以从亚马逊中国上买到。英文版：Deep Learning中文版：exacity/deeplearningbook-chinese这本书的阅读建议：为了补充基础可以阅读第1-5章其中也包含了一些数学知识只关注主流神经网络知识可以阅读6-10章，介绍了DNN/CNN/RNN需要进一步了解一些调参和应用技巧，推荐阅读11和12章第13-20章为进阶章节，在入门阶段没有必要阅读。其实比较实际的做法是吴恩达的课程讲到什么概念，你到这本书里面可以阅读一些深入的理论进行概念加深，按章节阅读还是比较耗时耗力的。3.4. 第四阶段：深入研究恭喜你！如果你已经完成了上面的计划表，代表你已经有了相当的机器学习能力。这个阶段，最重要的就是不要贪多嚼不烂。如果你浏览知乎，会发现大家都说你必须读Elements of Statistical Learning， MLAPP之类的大部头。我承认阅读这样的书会有帮助，但在你有了一定的基础知识后，相信你已经知道自己需要接着做什么了也有了志同道合的朋友，我希望把选择权交还给你，而不是继续推荐成堆的课程和书籍。当然，如果你希望继续深入的话，中文可以继续阅读周志华老师的《机器学习》和李航老师的《统计学习基础》，英文可以入手《Elements of Statistical Learning》。在这个阶段，重点要形成成体系的知识脉络，切记贪多嚼不烂，切记！从阅读论文角度来说，订阅Arxiv，关注机器学习的顶级会议，如ICML/NIPS等，相关的方法在知乎上可以很容易搜索到，不在此赘述。4. 实践经验4.1. 研究经历如果你还是学生，尝试尽早接触科研，进实验室。一般来说，大三的时候你应该已经有了基本的机器学习知识，尽管还比较浅。这个时候可以向老师/学长/学姐毛遂自荐进实验室，即使是无偿劳动和做基本的苦力活。进实验室有两个明显的好处：对某个小方向会有比较深入的了解。一般实验室做纯理论的不大需要本科生，做机器视觉或者自然语言处理(NLP)等小方向的比较需要本科生，所以这是很好的深入了解一个方向的机会。补充了研究经历也可以明白自己是否适合这个领域。如果运气好的话，你也有可能成为论文的作者之一，甚至可以去开会(公款旅游顺道见一下业内大佬)。这对于继续深造和去国外继续学习都很有帮助，有科研经历和论文是很大的筹码，对于找工作来说也绝对有利无害。4.2. 企业实习上文提到过，机器学习光说不练假把式，最好的方法还是要实践。因此，应该先试着做科研，再尝试工业界实习。对待科研机会，有则就上，没有也不是太大的遗憾。我建议大部分做机器学习的朋友尽早实习，主要出于以下几个考量：打破幻想，了解工业界的主流模型。在其他很多答案中我都提到过，其实工业界用的大部分技术并不酷炫，你很少能看到深度强化学习那种AlphaGo一样酷炫的模型。不夸张的说，广义线性模型(generalized linear models)还是占据了大壁江山，这要归功于其良好的解释能力。从神经网络角度出发，一般也逃不过普通任务深度网络、视觉任务卷积网络CNN、语音和文字任务LSTM的套路。补上学术界忽视的内容，比如可视化和数据清洗。工业界的最终目的是输出商业价值，而获得商业洞见的过程其实是非常痛苦的，比如第一步就是令人深恶痛绝的数据清洗。毫不夸张的说，工业界百分之六十的时间都在清理数据，这和学术界干净且规则化的现成数据完全不同。没有在工业界体验过的人，无法真的了解原来机器学习从头到尾有那么多陷阱，泛化能力只是终极目标，而往往我们连规整的数据都无法得到。了解技术商业化中的取舍，培养大局观。做技术的人往往一头扎进技术里面，而忽视了从全局思考。举个例子，模型A的准确率95.5%，每次训练时间是3天，需要6台有GPU的服务器。而模型B的准确率是百分之95.2%，但只需要一台普通的macbook训练4个小时就可以了。从学术角度出发我们往往追求更好的模型结果选A，而工业界还要考虑到训练开销、模型可解释性、模型稳定度等。到工业界实习不仅可以培养大家的宏观掌控能力，对将来自己带学生控制开销或者选题也大有帮助4.3. 在本职工作中使用机器学习对于大部分已经工作的朋友来说，重新回到学校攻读学位并不现实，进研究室进行学习更是缺少机会。那么这个时候，你就可以试着把机器学习应用到你自己的工作当中。已经有了工作/研究经验的朋友，要试着将自己的工作经历利用起来。举例，不要做机器学习里面最擅长投资的人，而要做金融领域中最擅长机器学习的专家，这才是你的价值主张(valueproposition)。最重要的是，机器学习的基本功没有大家想的那么高不可攀，没有必要放弃自己的本专业全职转行，沉没成本太高。通过跨领域完全可以做到曲线救国，化劣势为优势，你们可能比只懂机器学习的人有更大的行业价值。举几个我身边的例子，我的一个朋友是做传统软件工程研究的，前年他和我商量如何使用机器学习以GitHub上的commit历史来识别bug，这就是一个很好的结合领域的知识。如果你本身是做金融出身，在你补足上面基本功的同时，就可以把机器学习交叉运用于你自己擅长的领域，做策略研究，我已经听说了无数个“宣称”使用机器学习实现了交易策略案例。虽不可尽信，但对特定领域的深刻理解往往就是捅破窗户的那最后一层纸，只理解模型但不了解数据和数据背后的意义，导致很多机器学习模型只停留在好看而不实用的阶段。5. 写在最后虽然人们曾说二十一是生物的世纪，但现在还是人工智能的世纪。欢迎大家来试试机器学习，体验数据分析的魅力。就像我曾在很多回答中提到，机器学习领域应该要敞开大门，让每个人都可以尝试将机器学习知识应用于他们原本的领域，摒弃人为制造的知识壁垒。唯有这样，机器学习技术才能在更多的不同领域落地，从而反哺机器学习研究本身。科技日新月异，追逐热点是好的。但在这个浮躁的时代，不管选择什么方向最重要的就是独立思考的能力，和去伪存真的勇气。因此，看了这么多入门教程和经验分享后，我最希望的是你既不要急着全盘接受，也不要因为不对胃口全盘否定。慢下来，好好想想，制定适合自己的计划，这大概才是做科学工作的正确态度。在思考之后，拒绝外界的噪音，无论是鼓励还是嘲笑。抱着“不撞南山不回头”的信念，继续朝机器学习的高峰攀登。或许，科技领域正因为有了我们这群“书呆子”才显得尤为可爱 ʕ•ᴥ•ʔ注：希望继续在IT行业突破提升自己的各位朋友，欢迎加群384053806，不管你自我感觉牛不牛B。 ", "answer_votes": "116", "answer_comment": "​4 条评论"}
{"answer_author": "刘志军", "answer_id": 191099403, "answer_text": "原文链接：ty4z2008/Qix 机器学习(Machine Learning)&深度学习(Deep Learning)资料(Chapter 1)\n注:机器学习资料篇目一共500条,篇目二开始更新\n希望转载的朋友，你可以不用联系我．但是一定要保留原文链接，因为这个项目还在继续也在不定期更新．希望看到文章的朋友能够学到更多．此外:某些资料在中国访问需要梯子.\n《Brief History of Machine Learning》\n介绍:这是一篇介绍机器学习历史的文章，介绍很全面，从感知机、神经网络、决策树、SVM、Adaboost到随机森林、Deep Learning.\n《Deep Learning in Neural Networks: An Overview》\n介绍:这是瑞士人工智能实验室Jurgen Schmidhuber写的最新版本《神经网络与深度学习综述》本综述的特点是以时间排序，从1940年开始讲起，到60-80年代，80-90年代，一直讲到2000年后及最近几年的进展。涵盖了deep learning里各种tricks，引用非常全面.\n《A Gentle Introduction to Scikit-Learn: A Python Machine Learning Library》\n介绍:这是一份python机器学习库,如果您是一位python工程师而且想深入的学习机器学习.那么这篇文章或许能够帮助到你.\n《How to Layout and Manage Your Machine Learning Project》\n介绍:这一篇介绍如果设计和管理属于你自己的机器学习项目的文章，里面提供了管理模版、数据管理与实践方法.\n《Machine Learning is Fun!》\n介绍:如果你还不知道什么是机器学习，或则是刚刚学习感觉到很枯燥乏味。那么推荐一读。这篇文章已经被翻译成中文,如果有兴趣可以移步http://blog.jobbole.com/67616/ 《R语言参考卡片》\n介绍:R语言是机器学习的主要语言,有很多的朋友想学习R语言，但是总是忘记一些函数与关键字的含义。那么这篇文章或许能够帮助到你\n《Choosing a Machine Learning Classifier》\n介绍:我该如何选择机器学习算法，这篇文章比较直观的比较了Naive Bayes，Logistic Regression，SVM，决策树等方法的优劣，另外讨论了样本大小、Feature与Model权衡等问题。此外还有已经翻译了的版本:http://www.52ml.net/15063.html 《An Introduction to Deep Learning: From Perceptrons to Deep Networks》\n介绍：深度学习概述：从感知机到深度网络，作者对于例子的选择、理论的介绍都很到位，由浅入深。翻译版本：http://www.cnblogs.com/xiaowanyer/p/3701944.html 《The LION Way: Machine Learning plus Intelligent Optimization》\n介绍:<机器学习与优化>这是一本机器学习的小册子, 短短300多页道尽机器学习的方方面面. 图文并茂, 生动易懂, 没有一坨坨公式的烦恼. 适合新手入门打基础, 也适合老手温故而知新. 比起MLAPP/PRML等大部头, 也许这本你更需要!具体内容推荐阅读:http://intelligent-optimization.org/LIONbook/ 《深度学习与统计学习理论》\n介绍:作者是来自百度，不过他本人已经在2014年4月份申请离职了。但是这篇文章很不错如果你不知道深度学习与支持向量机/统计学习理论有什么联系？那么应该立即看看这篇文章.\n《计算机科学中的数学》\n介绍:这本书是由谷歌公司和MIT共同出品的计算机科学中的数学：[Mathematics for Computer Science](Mathematics for Computer Science)，Eric Lehman et al 2013 。分为5大部分：1）证明，归纳。2）结构，数论，图。3）计数，求和，生成函数。4）概率，随机行走。5）递归。等等\n《信息时代的计算机科学理论(Foundations of Data Science)》\n介绍：信息时代的计算机科学理论,目前国内有纸质书购买，iTunes购买 《Data Science with R》\n介绍:这是一本由雪城大学新编的第二版《数据科学入门》教材：偏实用型，浅显易懂，适合想学习R语言的同学选读。\n《Twenty Questions for Donald Knuth》\n介绍:这并不是一篇文档或书籍。这是篇向图灵奖得主Donald Knuth提问记录稿： 近日， Charles Leiserson, Al Aho, Jon Bentley等大神向Knuth提出了20个问题，内容包括TAOCP，P/NP问题，图灵机，逻辑，以及为什么大神不用电邮等等。\n《Automatic Construction and Natural-Language Description of Nonparametric Regression Models》\n介绍：不会统计怎么办？不知道如何选择合适的统计模型怎么办？那这篇文章你的好好读一读了麻省理工Joshua B. Tenenbaum和剑桥Zoubin Ghahramani合作，写了一篇关于automatic statistician的文章。可以自动选择回归模型类别，还能自动写报告...\n《ICLR 2014论文集》\n介绍:对深度学习和representation learning最新进展有兴趣的同学可以了解一下\n《Introduction to Information Retrieval》\n介绍：这是一本信息检索相关的书籍，是由斯坦福Manning与谷歌副总裁Raghavan等合著的Introduction to Information Retrieval一直是北美最受欢迎的信息检索教材之一。最近作者增加了该课程的幻灯片和作业。IR相关资源：http://www-nlp.stanford.edu/IR-book/information-retrieval.html 《Machine learning in 10 pictures》\n介绍:Deniz Yuret用10张漂亮的图来解释机器学习重要概念：1. Bias/Variance Tradeoff 2. Overfitting 3. Bayesian / Occam's razor 4. Feature combination 5. Irrelevant feature 6. Basis function 7. Discriminative / Generative 8. Loss function 9. Least squares 10. Sparsity.很清晰\n《雅虎研究院的数据集汇总》\n介绍：雅虎研究院的数据集汇总： 包括语言类数据，图与社交类数据，评分与分类数据，计算广告学数据，图像数据，竞赛数据，以及系统类的数据。\n《An Introduction to Statistical Learning with Applications in R》\n介绍：这是一本斯坦福统计学著名教授Trevor Hastie和Robert Tibshirani的新书，并且在2014年一月已经开课：https://class.stanford.edu/courses/HumanitiesScience/StatLearning/Winter2014/about Best Machine Learning Resources for Getting Started\n介绍：机器学习最佳入门学习资料汇总是专为机器学习初学者推荐的优质学习资源，帮助初学者快速入门。而且这篇文章的介绍已经被翻译成中文版。如果你不怎么熟悉，那么我建议你先看一看中文的介绍。\nMy deep learning reading list\n介绍:主要是顺着Bengio的PAMI review的文章找出来的。包括几本综述文章，将近100篇论文，各位山头们的Presentation。全部都可以在google上找到。\nCross-Language Information Retrieval\n介绍：这是一本书籍，主要介绍的是跨语言信息检索方面的知识。理论很多\n探索推荐引擎内部的秘密，第 1 部分: 推荐引擎初探\n介绍:本文共有三个系列，作者是来自IBM的工程师。它主要介绍了推荐引擎相关算法，并帮助读者高效的实现这些算法。 探索推荐引擎内部的秘密，第 2 部分: 深度推荐引擎相关算法 - 协同过滤,探索推荐引擎内部的秘密，第 3 部分: 深度推荐引擎相关算法 - 聚类 《Advice for students of machine learning》\n介绍：康奈尔大学信息科学系助理教授David Mimno写的《对机器学习初学者的一点建议》， 写的挺实际，强调实践与理论结合，最后还引用了冯 • 诺依曼的名言: \"Young man, in mathematics you don't understand things. You just get used to them.\"\n分布式并行处理的数据\n介绍：这是一本关于分布式并行处理的数据《Explorations in Parallel Distributed Processing: A Handbook of Models, Programs, and Exercises》,作者是斯坦福的James L. McClelland。着重介绍了各种神级网络算法的分布式实现,做Distributed Deep Learning 的童鞋可以参考下\n《“机器学习”是什么？》\n介绍:【“机器学习”是什么？】John Platt是微软研究院杰出科学家，17年来他一直在机器学习领域耕耘。近年来机器学习变得炙手可热，Platt和同事们遂决定开设博客，向公众介绍机器学习的研究进展。机器学习是什么，被应用在哪里？来看Platt的这篇博文 《2014年国际机器学习大会ICML 2014 论文》\n介绍：2014年国际机器学习大会（ICML）已经于6月21-26日在国家会议中心隆重举办。本次大会由微软亚洲研究院和清华大学联手主办，是这个有着30多年历史并享誉世界的机器学习领域的盛会首次来到中国，已成功吸引海内外1200多位学者的报名参与。干货很多，值得深入学习下\n《Machine Learning for Industry: A Case Study》\n介绍：这篇文章主要是以Learning to Rank为例说明企业界机器学习的具体应用，RankNet对NDCG之类不敏感，加入NDCG因素后变成了LambdaRank，同样的思想从神经网络改为应用到Boosted Tree模型就成就了LambdaMART。Chirs Burges，微软的机器学习大神，Yahoo 2010 Learning to Rank Challenge第一名得主，排序模型方面有RankNet，LambdaRank，LambdaMART，尤其以LambdaMART最为突出，代表论文为： From RankNet to LambdaRank to LambdaMART: An Overview此外，Burges还有很多有名的代表作，比如：A Tutorial on Support Vector Machines for Pattern Recognition Some Notes on Applied Mathematics for Machine Learning 100 Best GitHub: Deep Learning\n介绍:100 Best GitHub: Deep Learning\n《UFLDL-斯坦福大学Andrew Ng教授“Deep Learning”教程》\n介绍:本教程将阐述无监督特征学习和深度学习的主要观点。通过学习，你也将实现多个功能学习/深度学习算法，能看到它们为你工作，并学习如何应用/适应这些想法到新问题上。本教程假定机器学习的基本知识（特别是熟悉的监督学习，逻辑回归，梯度下降的想法），如果你不熟悉这些想法，我们建议你去这里机器学习课程，并先完成第II，III，IV章（到逻辑回归）。此外这关于这套教程的源代码在github上面已经有python版本了 UFLDL Tutorial Code\n*《Deep Learning for Natural Language Processing and Related Applications》\n介绍:这份文档来自微软研究院,精髓很多。如果需要完全理解，需要一定的机器学习基础。不过有些地方会让人眼前一亮,茅塞顿开。\nUnderstanding Convolutions\n介绍:这是一篇介绍图像卷积运算的文章，讲的已经算比较详细的了\n《Machine Learning Summer School》\n介绍：每天请一个大牛来讲座，主要涉及机器学习，大数据分析，并行计算以及人脑研究。https://www.youtube.com/user/smolix （需翻墙）\n《Awesome Machine Learning》\n介绍：一个超级完整的机器学习开源库总结，如果你认为这个碉堡了，那后面这个列表会更让你惊讶：【Awesome Awesomeness】,国内已经有热心的朋友进行了翻译中文介绍，机器学习数据挖掘免费电子书 斯坦福《自然语言处理》课程视频\n介绍:ACL候任主席、斯坦福大学计算机系Chris Manning教授的《自然语言处理》课程所有视频已经可以在斯坦福公开课网站上观看了（如Chrome不行，可用IE观看） 作业与测验也可以下载。\n《Deep Learning and Shallow Learning》\n介绍:对比 Deep Learning 和 Shallow Learning 的好文，来着浙大毕业、MIT 读博的 Chiyuan Zhang 的博客。\n《Recommending music on Spotify with deep learning》\n介绍:利用卷积神经网络做音乐推荐。\n《Neural Networks and Deep Learning》\n介绍：神经网络的免费在线书，已经写了三章了，还有对应的开源代码：https://github.com/mnielsen/neural-networks-and-deep-learning 爱好者的福音。\n《Java Machine Learning》\n介绍：Java机器学习相关平台和开源的机器学习库，按照大数据、NLP、计算机视觉和Deep Learning分类进行了整理。看起来挺全的，Java爱好者值得收藏。\n《Machine Learning Theory: An Introductory Primer》\n介绍：机器学习最基本的入门文章，适合零基础者\n《机器学习常见算法分类汇总》\n介绍：机器学习的算法很多。很多时候困惑人们都是，很多算法是一类算法，而有些算法又是从其他算法中延伸出来的。这里，我们从两个方面来给大家介绍，第一个方面是学习的方式，第二个方面是算法的类似性。\n《机器学习经典论文/survey合集》\n介绍：看题目你已经知道了是什么内容,没错。里面有很多经典的机器学习论文值得仔细与反复的阅读。\n《机器学习视频库》\n介绍：视频由加州理工学院（Caltech）出品。需要英语底子。\n《机器学习经典书籍》\n介绍：总结了机器学习的经典书籍，包括数学基础和算法理论的书籍，可做为入门参考书单。\n《16 Free eBooks On Machine Learning》\n介绍:16本机器学习的电子书，可以下载下来在pad，手机上面任意时刻去阅读。不多我建议你看完一本再下载一本。\n《A Large set of Machine Learning Resources for Beginners to Mavens》\n介绍:标题很大，从新手到专家。不过看完上面所有资料。肯定是专家了\n《机器学习最佳入门学习资料汇总》\n介绍：入门的书真的很多，而且我已经帮你找齐了。\n《Sibyl》\n介绍：Sibyl 是一个监督式机器学习系统，用来解决预测方面的问题，比如 YouTube 的视频推荐。\n《Neural Network &amp;amp; Text Mining》\n介绍:关于(Deep) Neural Networks在 NLP 和 Text Mining 方面一些paper的总结\n《前景目标检测1（总结）》\n介绍:计算机视觉入门之前景目标检测1（总结）\n《行人检测》\n介绍:计算机视觉入门之行人检测\n《Deep Learning – important resources for learning and understanding》\n介绍:Important resources for learning and understanding . Is awesome\n《Machine Learning Theory: An Introductory Primer》\n介绍:这又是一篇机器学习初学者的入门文章。值得一读\n《Neural Networks and Deep Learning》\n介绍:在线Neural Networks and Deep Learning电子书\n《Python 网页爬虫 &amp;amp; 文本处理 &amp;amp; 科学计算 &amp;amp; 机器学习 &amp;amp; 数据挖掘兵器谱》\n介绍:python的17个关于机器学习的工具\n《神奇的伽玛函数(上)》\n介绍:下集在这里神奇的伽玛函数(下) 《分布式机器学习的故事》\n介绍:作者王益目前是腾讯广告算法总监，王益博士毕业后在google任研究。这篇文章王益博士7年来从谷歌到腾讯对于分布机器学习的所见所闻。值得细读\n《机器学习提升之道（Level-Up Your Machine Learning）》\n介绍:把机器学习提升的级别分为0~4级，每级需要学习的教材和掌握的知识。这样，给机器学习者提供一个上进的路线图，以免走弯路。另外，整个网站都是关于机器学习的，资源很丰富。\n《Machine Learning Surveys》\n介绍:机器学习各个方向综述的网站\n《Deep Learning Reading list》\n介绍:深度学习阅资源列表\n《Deep Learning: Methods and Applications》\n介绍：这是一本来自微的研究员 li Peng和Dong Yu所著的关于深度学习的方法和应用的电子书\n《Machine Learning Summer School 2014》\n介绍:2014年七月CMU举办的机器学习夏季课刚刚结束 有近50小时的视频、十多个PDF版幻灯片，覆盖 深度学习，贝叶斯，分布式机器学习，伸缩性 等热点话题。所有13名讲师都是牛人：包括大牛Tom Mitchell （他的［机器学习］是名校的常用教材），还有CMU李沐 .（1080P高清哟）\n《Sibyl: 来自Google的大规模机器学习系统》\n介绍:在今年的IEEE/IFIP可靠系统和网络（DSN）国际会议上，Google软件工程师Tushar Chandra做了一个关于Sibyl系统的主题演讲。 Sibyl是一个监督式机器学习系统，用来解决预测方面的问题，比如YouTube的视频推荐。详情请阅读google sibyl 《Building a deeper understanding of images》\n介绍:谷歌研究院的Christian Szegedy在谷歌研究院的博客上简要地介绍了他们今年参加ImageNet取得好成绩的GoogLeNet系统.是关于图像处理的。\n《Bayesian network 与python概率编程实战入门》\n介绍:贝叶斯学习。如果不是很清可看看概率编程语言与贝叶斯方法实践 《AMA: Michael I Jordan》\n介绍:网友问伯克利机器学习大牛、美国双料院士Michael I. Jordan：\"如果你有10亿美金，你怎么花？Jordan: \"我会用这10亿美金建造一个NASA级别的自然语言处理研究项目。\"\n《机器学习&amp;amp;数据挖掘笔记_16（常见面试之机器学习算法思想简单梳理）》\n介绍:常见面试之机器学习算法思想简单梳理,此外作者还有一些其他的机器学习与数据挖掘文章和深度学习文章,不仅是理论还有源码。\n《文本与数据挖掘视频汇总》\n介绍：Videolectures上最受欢迎的25个文本与数据挖掘视频汇总\n《怎么选择深度学习的GPUs》\n介绍:在Kaggle上经常取得不错成绩的Tim Dettmers介绍了他自己是怎么选择深度学习的GPUs, 以及个人如何构建深度学习的GPU集群: http://t.cn/RhpuD1G 《对话机器学习大神Michael Jordan：深度模型》\n介绍:对话机器学习大神Michael Jordan\n《Deep Learning 和 Knowledge Graph 引爆大数据革命》\n介绍:还有２，３部分。http://blog.sina.com.cn/s/blog_46d0a3930101gs5h.html 《Deep Learning 教程翻译》\n介绍:是Stanford 教授 Andrew Ng 的 Deep Learning 教程，国内的机器学习爱好者很热心的把这个教程翻译成了中文。如果你英语不好，可以看看这个\n《Deep Learning 101》\n介绍:因为近两年来，深度学习在媒体界被炒作很厉害（就像大数据）。其实很多人都还不知道什么是深度学习。这篇文章由浅入深。告诉你深度学究竟是什么！\n《UFLDL Tutorial》\n介绍:这是斯坦福大学做的一免费课程（很勉强），这个可以给你在深度学习的路上给你一个学习的思路。里面提到了一些基本的算法。而且告诉你如何去应用到实际环境中。中文版 《Toronto Deep Learning Demos》\n介绍:这是多伦多大学做的一个深度学习用来识别图片标签／图转文字的demo。是一个实际应用案例。有源码\n《Deep learning from the bottom up》\n介绍:机器学习模型，阅读这个内容需要有一定的基础。\n《R工具包的分类汇总》\n介绍: (CRAN Task Views, 34种常见任务,每个任务又各自分类列举若干常用相关工具包) 例如: 机器学习，自然语言处理，时间序列分析，空间信息分析，多重变量分析，计量经济学，心理统计学，社会学统计，化学计量学，环境科学，药物代谢动力学 等\n《机器学习常见算法分类汇总》\n介绍: 机器学习无疑是当前数据分析领域的一个热点内容。很多人在平时的工作中都或多或少会用到机器学习的算法。本文为您总结一下常见的机器学习算法，以供您在工作和学习中参考.\n《Deep Learning（深度学习）学习笔记整理系列》\n介绍: 很多干货，而且作者还总结了好几个系列。另外还作者还了一个文章导航.非常的感谢作者总结。\nDeep Learning（深度学习）学习笔记整理系列之（二） Deep Learning（深度学习）学习笔记整理系列之（三） Deep Learning（深度学习）学习笔记整理系列之（四） Deep Learning（深度学习）学习笔记整理系列之（五） Deep Learning（深度学习）学习笔记整理系列之（六） Deep Learning（深度学习）学习笔记整理系列之（七） DeepLearning（深度学习）学习笔记整理系列之（八） 《Tutorials Session A - Deep Learning for Computer Vision》\n介绍:传送理由：Rob Fergus的用深度学习做计算机是觉的NIPS 2013教程。有mp4, mp3, pdf各种下载 他是纽约大学教授，目前也在Facebook工作，他2014年的8篇论文 《FudanNLP》\n介绍:FudanNLP，这是一个复旦大学计算机学院开发的开源中文自然语言处理（NLP）工具包 Fudan NLP里包含中文分词、关键词抽取、命名实体识别、词性标注、时间词抽取、语法分析等功能，对搜索引擎 文本分析等极为有价值。\n《Open Sourcing ml-ease》\n介绍:LinkedIn 开源的机器学习工具包,支持单机, Hadoop cluster，和 Spark cluster 重点是 logistic regression 算法\n《机器学习周刊》\n介绍:对于英语不好，但又很想学习机器学习的朋友。是一个大的福利。机器学习周刊目前主要提供中文版，还是面向广大国内爱好者，内容涉及机器学习、数据挖掘、并行系统、图像识别、人工智能、机器人等等。谢谢作者\n《线性代数》\n介绍：《线性代数》是《机器学习》的重要数学先导课程。其实《线代》这门课讲得浅显易懂特别不容易，如果一上来就讲逆序数及罗列行列式性质，很容易让学生失去学习的兴趣。我个人推荐的最佳《线性代数》课程是麻省理工Gilbert Strang教授的课程。 课程主页 《Big-data》\n介绍:大数据数据处理资源、工具不完备列表，从框架、分布式编程、分布式文件系统、键值数据模型、图数据模型、数据可视化、列存储、机器学习等。很赞的资源汇总。\n《machine learning for smart dummies》\n介绍:雅虎邀请了一名来自本古里安大学的访问学者，制作了一套关于机器学习的系列视频课程。本课程共分为7期，详细讲解了有关SVM, boosting, nearest neighbors, decision trees 等常规机器学习算法的理论基础知识。\n《Entanglement-Based Quantum Machine Learning》\n介绍:应对大数据时代，量子机器学习的第一个实验 paper 下载 《How a Math Genius Hacked OkCupid to Find True Love》\n介绍:Wired杂志报道了UCLA数学博士Chris McKinlay （图1）通过大数据手段+机器学习方法破解婚恋网站配对算法找到真爱的故事,通过Python脚本控制着12个账号，下载了婚恋网站2万女用户的600万问题答案，对他们进行了统计抽样及聚类分析（图2，3），最后终于收获了真爱。科技改变命运！\n《Underactuated Robotics》\n介绍:MIT的Underactuated Robotics于 2014年10月1日开课，该课属于MIT研究生级别的课程，对机器人和非线性动力系统感兴趣的朋友不妨可以挑战一下这门课程！\n《mllib实践经验(1)》\n介绍:mllib实践经验分享\n《Google Turns To Deep Learning Classification To Fight Web Spam》\n介绍:Google用Deep Learning做的antispam(反垃圾邮件)\n《NLP常用信息资源》\n介绍:NLP常用信息资源* 《NLP常用信息资源》 《机器学习速查表》\n介绍:机器学习速查表\n《Best Papers vs. Top Cited Papers in Computer Science》\n介绍：从1996年开始在计算机科学的论文中被引用次数最多的论文\n《InfiniTAM: 基于深度图像的体数据集成框架》\n介绍：把今年的一个ACM Trans. on Graphics (TOG)论文中的代码整理为一个开源的算法框架，共享出来了。欢迎大家使用。可以实时的采集3D数据、重建出三维模型。Online learning，GPU Random forest，GPU CRF也会后续公开。\n《Hacker&amp;#x27;s guide to Neural Networks》\n介绍：【神经网络黑客指南】现在，最火莫过于深度学习（Deep Learning），怎样更好学习它？可以让你在浏览器中，跑起深度学习效果的超酷开源项目ConvNetJS作者karpathy告诉你，最佳技巧是，当你开始写代码，一切将变得清晰。他刚发布了一本图书，不断在线更新\n《Building a Production Machine Learning Infrastructure》\n介绍：前Google广告系统工程师Josh Wills 讲述工业界和学术界机器学习的异同,大实话\n《Deep Learning Sentiment Analysis for Movie Reviews using Neo4j》\n介绍：使用Neo4j 做电影评论的情感分析。\n《DeepLearning.University – An Annotated Deep Learning Bibliography》\n介绍：不仅是资料，而且还对有些资料做了注释。\n《A primer on deeping learning》\n介绍：深度学习入门的初级读本\n《Machine learning is teaching us the secret to teaching 》\n介绍：机器学习教会了我们什么？\n《scikit-learn：用于机器学习的Python模块》\n介绍：scikit-learn是在SciPy基础上构建的用于机器学习的Python模块。\n《对话机器学习大神Michael Jordan：解析领域中各类模型》\n介绍：乔丹教授（Michael I. Jordan）教授是机器学习领域神经网络的大牛，他对深度学习、神经网络有着很浓厚的兴趣。因此，很多提问的问题中包含了机器学习领域的各类模型，乔丹教授对此一一做了解释和展望。\n《A*搜索算法的可视化短教程》\n介绍：A*搜索是人工智能基本算法，用于高效地搜索图中两点的最佳路径, 核心是 g(n)+h(n): g(n)是从起点到顶点n的实际代价，h(n)是顶点n到目标顶点的估算代价。合集 《基于云的自然语言处理开源项目FudanNLP》\n介绍：本项目利用了Microsoft Azure，可以在几分种内完成NLP on Azure Website的部署，立即开始对FNLP各种特性的试用，或者以REST API的形式调用FNLP的语言分析功能\n《吴立德《概率主题模型&amp;amp;数据科学基础》\n介绍：现任复旦大学首席教授、计算机软件博士生导师。计算机科学研究所副所长.内部课程\n《机器学习入门资源不完全汇总》\n介绍：好东西的干货真的很多\n《收集从2014年开始深度学习文献》\n介绍：从硬件、图像到健康、生物、大数据、生物信息再到量子计算等，Amund Tveit等维护了一个DeepLearning.University小项目：收集从2014年开始深度学习文献，相信可以作为深度学习的起点,github 《EMNLP上两篇关于股票趋势的应用论文 》\n介绍：EMNLP上两篇关于stock trend 用到了deep model组织特征； Exploiting Social Relations and Sentiment for Stock Prediction用到了stock network。\n《Bengio组（蒙特利尔大学LISA组）深度学习教程 》\n介绍：作者是深度学习一线大牛Bengio组写的教程，算法深入显出，还有实现代码，一步步展开。\n《学习算法的Neural Turing Machine 》\n介绍：许多传统的机器学习任务都是在学习function，不过谷歌目前有开始学习算法的趋势。谷歌另外的这篇学习Python程序的Learning to Execute也有相似之处\n《Learning to Rank for Information Retrieval and Natural Language Processing》\n介绍：作者是华为技术有限公司，诺亚方舟实验室，首席科学家的李航博士写的关于信息检索与自然语言处理的文章\n《Rumor has it: Identifying Misinformation in Microblogs》\n介绍：利用机用器学习在谣言的判别上的应用,此外还有两个。一个是识别垃圾与虚假信息的paper.还有一个是网络舆情及其分析技术 《R机器学习实践》\n介绍：该课程是网易公开课的收费课程，不贵，超级便宜。主要适合于对利用R语言进行机器学习，数据挖掘感兴趣的人。\n《大数据分析：机器学习算法实现的演化》\n介绍：本章中作者总结了三代机器学习算法实现的演化：第一代非分布式的， 第二代工具如Mahout和Rapidminer实现基于Hadoop的扩展，第三代如Spark和Storm实现了实时和迭代数据处理。BIG DATA ANALYTICS BEYOND HADOOP 《图像处理，分析与机器视觉》\n介绍：讲计算机视觉的四部奇书（应该叫经典吧）之一，另外三本是Hartley的《多图几何》、Gonzalez的《数字图像处理》、Rafael C.Gonzalez / Richard E.Woods 的《数字图像处理》 《LinkedIn最新的推荐系统文章Browsemaps》\n介绍：里面基本没涉及到具体算法，但作者介绍了CF在LinkedIn的很多应用，以及他们在做推荐过程中获得的一些经验。最后一条经验是应该监控log数据的质量，因为推荐的质量很依赖数据的质量！\n《初学者如何查阅自然语言处理（NLP）领域学术资料》\n介绍：初学者如何查阅自然语言处理（NLP）领域学术资料\n《树莓派的人脸识别教程》\n介绍：用树莓派和相机模块进行人脸识别\n《利用深度学习与大数据构建对话系统 》\n介绍：如何利用深度学习与大数据构建对话系统\n《经典论文Leo Breiman：Statistical Modeling: The Two Cultures 》\n介绍：Francis Bach合作的有关稀疏建模的新综述(书)：Sparse Modeling for Image and Vision Processing，内容涉及Sparsity, Dictionary Learning, PCA, Matrix Factorization等理论，以及在图像和视觉上的应用，而且第一部分关于Why does the l1-norm induce sparsity的解释也很不错。\n《Reproducing Kernel Hilbert Space》\n介绍：RKHS是机器学习中重要的概念，其在large margin分类器上的应用也是广为熟知的。如果没有较好的数学基础，直接理解RKHS可能会不易。本文从基本运算空间讲到Banach和Hilbert空间，深入浅出，一共才12页。\n《Hacker&amp;#x27;s guide to Neural Networks》\n介绍：许多同学对于机器学习及深度学习的困惑在于，数学方面已经大致理解了，但是动起手来却不知道如何下手写代码。斯坦福深度学习博士Andrej Karpathy写了一篇实战版本的深度学习及机器学习教程，手把手教你用Javascript写神经网络和SVM.\n《【语料库】语料库资源汇总》\n介绍：【语料库】语料库资源汇总\n《机器学习算法之旅》\n介绍：本文会过一遍最流行的机器学习算法，大致了解哪些方法可用，很有帮助。\n《Reproducible Research in Computational Science》\n介绍：这个里面有很多关于机器学习、信号处理、计算机视觉、深入学习、神经网络等领域的大量源代码（或可执行代码）及相关论文。科研写论文的好资源\n《NYU 2014年的深度学习课程资料》\n介绍：NYU 2014年的深度学习课程资料，有视频\n《计算机视觉数据集不完全汇总》\n介绍：计算机视觉数据集不完全汇总\n《Machine Learning Open Source Software》\n介绍：机器学习开源软件\n《LIBSVM》\n介绍：A Library for Support Vector Machines\n《Support Vector Machines》\n介绍：数据挖掘十大经典算法之一\n《100 Best GitHub: Deep Learning》\n介绍：github上面100个非常棒的项目\n《加州大学欧文分校(UCI)机器学习数据集仓库》\n介绍：当前加州大学欧文分校为机器学习社区维护着306个数据集。查询数据集 《Andrej Karpathy个人主页》\n介绍：Andrej Karpathy 是斯坦福大学Li Fei-Fei的博士生，使用机器学习在图像、视频语义分析领域取得了科研和工程上的突破，发的文章不多，但每个都很扎实，在每一个问题上都做到了state-of-art.\n《Andrej Karpathy的深度强化学习演示》\n介绍：Andrej Karpathy的深度强化学习演示，论文在这里 《CIKM数据挖掘竞赛夺冠算法-陈运文》\n介绍：CIKM Cup(或者称为CIKM Competition)是ACM CIKM举办的国际数据挖掘竞赛的名称。\n《Geoffrey E. Hinton》\n介绍：杰弗里·埃弗里斯特·辛顿 FRS是一位英国出生的计算机学家和心理学家，以其在神经网络方面的贡献闻名。辛顿是反向传播算法和对比散度算法的发明人之一，也是深度学习的积极推动者.\n《自然语言处理的深度学习理论与实际》\n介绍：微软研究院深度学习技术中心在CIKM2014 上关于《自然语言处理的深度学习理论与实际》教学讲座的幻灯片\n《用大数据和机器学习做股票价格预测》\n介绍： 本文基于<支持向量机的高频限价订单的动态建模>采用了 Apache Spark和Spark MLLib从纽约股票交易所的订单日志数据构建价格运动预测模型。(股票有风险，投资谨慎)GitHub源代码托管地址.\n《关于机器学习的若干理论问题》\n介绍：徐宗本 院士将于热爱机器学习的小伙伴一起探讨有关于机器学习的几个理论性问题，并给出一些有意义的结论。最后通过一些实例来说明这些理论问题的物理意义和实际应用价值。\n《深度学习在自然语言处理的应用》\n介绍：作者还著有《这就是搜索引擎：核心技术详解》一书，主要是介绍应用层的东西\n《Undergraduate machine learning at UBC》\n介绍：机器学习课程\n《人脸识别必读的N篇文章》\n介绍：人脸识别必读文章推荐\n《推荐系统经典论文文献及业界应用》\n介绍：推荐系统经典论文文献\n《人脸识别必读的N篇文章》\n介绍：人脸识别必读文章推荐\n《第十二届中国&amp;quot;机器学习及其应用&amp;quot;研讨会PPT》\n介绍：第十二届中国\"机器学习及其应用\"研讨会PPT\n《统计机器学习》\n介绍：统计学习是关于计算机基于数据构建的概率统计模型并运用模型对数据进行预测和分析的一门科学，统计学习也成为统计机器学习。课程来自上海交通大学\n《机器学习导论》\n介绍：机器学习的目标是对计算机编程，以便使用样本数据或以往的经验来解决给定的问题.\n《CIKM 2014主题报告的幻灯片》\n介绍：CIKM 2014 Jeff Dean、Qi Lu、Gerhard Weikum的主题报告的幻灯片， Alex Smola、Limsoon Wong、Tong Zhang、Chih-Jen Lin的Industry Track报告的幻灯片\n《人工智能和机器学习领域有趣的开源项目》\n介绍：部分中文列表 《机器学习经典算法详解及Python实现--基于SMO的SVM分类器》\n介绍:此外作者还有一篇元算法、AdaBoost　python实现文章 《Numerical Optimization: Understanding L-BFGS》\n介绍:加州伯克利大学博士Aria Haghighi写了一篇超赞的数值优化博文，从牛顿法讲到拟牛顿法，再讲到BFGS以及L-BFGS, 图文并茂，还有伪代码。强烈推荐。\n《简明深度学习方法概述（一）》\n介绍:还有续集简明深度学习方法概述（二） 《R language for programmers》\n介绍:Ｒ语言程序员私人定制版\n《谷歌地图解密：大数据与机器学习的结合》\n介绍:谷歌地图解密\n《空间数据挖掘常用方法》\n介绍:空间数据挖掘常用方法\n《Use Google&amp;#x27;s Word2Vec for movie reviews》\n介绍:Kaggle新比赛 ”When bag of words meets bags of popcorn“ aka ”边学边用word2vec和deep learning做NLP“ 里面全套教程教一步一步用python和gensim包的word2vec模型，并在实际比赛里面比调参数和清数据。 如果已装过gensim不要忘升级\n《PyNLPIR》\n介绍:PyNLPIR提供了NLPIR/ICTCLAS汉语分词的Python接口,此外Zhon提供了常用汉字常量，如CJK字符和偏旁，中文标点，拼音，和汉字正则表达式（如找到文本中的繁体字）\n《深度卷积神经网络下围棋》\n介绍:这文章说把最近模型识别上的突破应用到围棋软件上，打16万张职业棋谱训练模型识别功能。想法不错。训练后目前能做到不用计算，只看棋盘就给出下一步，大约10级棋力。但这篇文章太过乐观，说什么人类的最后一块堡垒马上就要跨掉了。话说得太早。不过，如果与别的软件结合应该还有潜力可挖。@万精油墨绿\n《NIPS审稿实验》\n介绍:UT Austin教授Eric Price关于今年NIPS审稿实验的详细分析,他表示，根据这次实验的结果，如果今年NIPS重新审稿的话，会有一半的论文被拒。\n《2014年最佳的大数据，数据科学文章》\n介绍:KDNuggets分别总结了2014年14个阅读最多以及分享最多的文章。我们从中可以看到多个主题——深度学习，数据科学家职业，教育和薪酬，学习数据科学的工具比如R和Python以及大众投票的最受欢迎的数据科学和数据挖掘语言\n《机器学习经典算法详解及Python实现--线性回归（Linear Regression）算法》\n介绍:Python实现线性回归,作者还有其他很棒的文章推荐可以看看\n《2014中国大数据技术大会33位核心专家演讲PDF》\n介绍：2014中国大数据技术大会33位核心专家演讲PDF下载\n《使用RNN和Paragraph Vector做情感分析》\n介绍：这是T. Mikolov & Y. Bengio最新论文Ensemble of Generative and Discriminative Techniques for Sentiment Analysis of Movie Reviews ，使用RNN和PV在情感分析效果不错，［项目代码］(https://github.com/mesnilgr/iclr15)公布在github(目前是空的)。这意味着Paragraph Vector终于揭开面纱了嘛。\n《NLPIR/ICTCLAS2015分词系统大会上的技术演讲 》\n介绍:NLPIR/ICTCLAS2015分词系统发布与用户交流大会上的演讲，请更多朋友检阅新版分词吧。 我们实验室同学的演讲包括：孙梦姝-基于评论观点挖掘的商品搜索技术研究 李然-主题模型 《Machine Learning is Fun!》\n介绍:Convex Neural Networks 解决维数灾难\n《CNN的反向求导及练习》\n介绍:介绍CNN参数在使用bp算法时该怎么训练，毕竟CNN中有卷积层和下采样层，虽然和MLP的bp算法本质上相同，但形式上还是有些区别的，很显然在完成CNN反向传播前了解bp算法是必须的。此外作者也做了一个资源集:机器学习，深度学习，视觉，数学等 《正则表达式优化成Trie树 》\n介绍:如果要在一篇文章中匹配十万个关键词怎么办？Aho-Corasick 算法利用添加了返回边的Trie树，能够在线性时间内完成匹配。 但如果匹配十万个正则表达式呢 ？ 这时候可以用到把多个正则优化成Trie树的方法，如日本人写的 Regexp::Trie 《Deep learning Reading List》\n介绍:深度学习阅读清单\n《Caffe》\n介绍:Caffe是一个开源的深度学习框架，作者目前在google工作，作者主页Yangqing Jia (贾扬清) 《GoogLeNet深度学习模型的Caffe复现 》\n介绍:2014 ImageNet冠军GoogLeNet深度学习模型的Caffe复现模型,GoogleNet论文.\n《LambdaNet，Haskell实现的开源人工神经网络库 》\n介绍:LambdaNetLambdaNet是由Haskell实现的一个开源的人工神经网络库，它抽象了网络创建、训练并使用了高阶函数。该库还提供了一组预定义函数，用户可以采取多种方式组合这些函数来操作现实世界数据。\n《百度余凯&amp;amp;张潼机器学习视频》\n介绍:如果你从事互联网搜索，在线广告，用户行为分析，图像识别，自然语言理解，或者生物信息学，智能机器人，金融预测，那么这门核心课程你必须深入了解。\n《杨强在TEDxNanjing谈智能的起源》\n介绍:\"人工智能研究分许多流派。其中之一以IBM为代表，认为只要有高性能计算就可得到智能，他们的‘深蓝’击败了世界象棋冠军；另一流派认为智能来自动物本能；还有个很强的流派认为只要找来专家，把他们的思维用逻辑一条条写下，放到计算机里就行……\" 杨强在TEDxNanjing谈智能的起源\n《深度RNN/LSTM用于结构化学习 0)序列标注Connectionist Temporal ClassificationICML06》\n介绍:1)机器翻译Sequence to Sequence NIPS14 2)成分句法GRAMMAR AS FOREIGN LANGUAGE 《Deep Learning实战之word2vec》\n介绍:网易有道的三位工程师写的word2vec的解析文档，从基本的词向量/统计语言模型->NNLM->Log-Linear/Log-Bilinear->层次化Log-Bilinear，到CBOW和Skip-gram模型，再到word2vec的各种tricks，公式推导与代码，基本上是网上关于word2vec资料的大合集，对word2vec感兴趣的朋友可以看看\n《Machine learning open source software》\n介绍:机器学习开源软件,收录了各种机器学习的各种编程语言学术与商业的开源软件．与此类似的还有很多例如:DMOZ - Computers: Artificial Intelligence: Machine Learning: Software,　LIBSVM -- A Library for Support Vector Machines,　Weka 3: Data Mining Software in Java,　scikit-learn:Machine Learning in Python,　Natural Language Toolkit:NLTK,　MAchine Learning for LanguagE Toolkit,　Data Mining - Fruitful and Fun,　Open Source Computer Vision Library 《机器学习入门者学习指南》\n介绍:作者是计算机研二(写文章的时候，现在是2015年了应该快要毕业了)，专业方向自然语言处理．这是一点他的经验之谈．对于入门的朋友或许会有帮助\n《A Tour of Machine Learning Algorithms》\n介绍:这是一篇关于机器学习算法分类的文章，非常好\n《2014年的《机器学习日报》大合集》\n介绍:机器学习日报里面推荐很多内容，在这里有一部分的优秀内容就是来自机器学习日报．\n《 Image classification with deep learning常用模型》\n介绍:这是一篇关于图像分类在深度学习中的文章\n《自动语音识别：深度学习方法》\n介绍:作者与Bengio的兄弟Samy 09年合编《自动语音识别：核方法》 3）李开复1989年《自动语音识别》专著，其博导、94年图灵奖得主Raj Reddy作序\n《NLP中的中文分词技术》\n介绍: 作者是360电商技术组成员,这是一篇NLP在中文分词中的应用\n《Using convolutional neural nets to detect facial keypoints tutorial》\n介绍: 使用deep learning的人脸关键点检测，此外还有一篇AWS部署教程 《书籍推荐:Advanced Structured Prediction》\n介绍: 由Sebastian Nowozin等人编纂MIT出版的新书《Advanced Structured Prediction》http://t.cn/RZxipKG ，汇集了结构化预测领域诸多牛文，涉及CV、NLP等领域，值得一读。网上公开的几章草稿:一,二,三,四,五 《An Introduction to Matrix Concentration Inequalities》\n介绍: Tropp把数学家用高深装逼的数学语言写的矩阵概率不等式用初等的方法写出来，是非常好的手册，领域内的paper各种证明都在用里面的结果。虽说是初等的，但还是非常的难\n《The free big data sources you should know》\n介绍: 不容错过的免费大数据集，有些已经是耳熟能详，有些可能还是第一次听说，内容跨越文本、数据、多媒体等，让他们伴你开始数据科学之旅吧，具体包括：Data.gov、US Census Bureau、European Union Open Data Portal、Data.gov.uk等\n《A Brief Overview of Deep Learning》\n介绍: 谷歌科学家、Hinton亲传弟子Ilya Sutskever的深度学习综述及实际建议\n《A Deep Dive into Recurrent Neural Nets》\n介绍: 非常好的讨论递归神经网络的文章，覆盖了RNN的概念、原理、训练及优化等各个方面内容，强烈推荐！本文作者Nikhil Buduma还有一篇Deep Learning in a Nutshell值得推荐\n《机器学习：学习资源》\n介绍:里面融合了很多的资源，例如竞赛，在线课程，demo，数据整合等。有分类\n《Statistical foundations of machine learning》\n介绍:《机器学习的统计基础》在线版，该手册希望在理论与实践之间找到平衡点，各主要内容都伴有实际例子及数据，书中的例子程序都是用R语言编写的。\n《A Deep Learning Tutorial: From Perceptrons to Deep Networks》\n介绍:IVAN VASILEV写的深度学习导引：从浅层感知机到深度网络。高可读\n《Research priorities for robust and beneficial artificial intelligence》\n介绍:鲁棒及有益的人工智能优先研究计划：一封公开信,目前已经有Stuart Russell, Tom Dietterich, Eric Horvitz, Yann LeCun, Peter Norvig, Tom Mitchell, Geoffrey Hinton, Elon Musk等人签署The Future of Life Institute (FLI).这封信的背景是最近霍金和Elon Musk提醒人们注意AI的潜在威胁。公开信的内容是AI科学家们站在造福社会的角度，展望人工智能的未来发展方向，提出开发AI系统的Verification，Validity, Security, Control四点要求，以及需要注意的社会问题。毕竟当前AI在经济领域，法律，以及道德领域相关研究较少。其实还有一部美剧《疑犯追踪》,介绍了AI的演进从一开始的自我学习，过滤，图像识别，语音识别等判断危险，到第四季的时候出现了机器通过学习成长之后想控制世界的状态。说到这里推荐收看。\n《metacademy》\n介绍:里面根据词条提供了许多资源，还有相关知识结构，路线图，用时长短等。号称是”机器学习“搜索引擎\n《FAIR open sources deep-learning modules for Torch》\n介绍:Facebook人工智能研究院（FAIR）开源了一系列软件库，以帮助开发者建立更大、更快的深度学习模型。开放的软件库在 Facebook 被称作模块。用它们替代机器学习领域常用的开发环境 Torch 中的默认模块，可以在更短的时间内训练更大规模的神经网络模型。\n《浅析人脸检测之Haar分类器方法》\n介绍:本文虽然是写于2012年，但是这篇文章完全是作者的经验之作。\n《如何成为一位数据科学家》\n介绍:本文是对《机器学习实战》作者Peter Harrington做的一个访谈。包含了书中部分的疑问解答和一点个人学习建议\n《Deep learning from the bottom up》\n介绍:非常好的深度学习概述，对几种流行的深度学习模型都进行了介绍和讨论\n《Hands-On Data Science with R Text Mining》\n介绍:主要是讲述了利用R语言进行数据挖掘\n《Understanding Convolutions》\n介绍:帮你理解卷积神经网络，讲解很清晰，此外还有两篇Conv Nets: A Modular Perspective，Groups &amp;amp; Group Convolutions. 作者的其他的关于神经网络文章也很棒\n《Introduction to Deep Learning Algorithms》\n介绍:Deep Learning算法介绍，里面介绍了06年3篇让deep learning崛起的论文\n《Learning Deep Architectures for AI》\n介绍:一本学习人工智能的书籍，作者是Yoshua Bengio，相关国内报道 《Geoffrey E. Hinton个人主页》\n介绍:Geoffrey Hinton是Deep Learning的大牛，他的主页放了一些介绍性文章和课件值得学习\n《PROBABILITY THEORY: THE LOGIC OF SCIENCE》\n介绍:概率论：数理逻辑书籍\n《H2O》\n介绍:一个用来快速的统计，机器学习并且对于数据量大的数学库\n《ICLR 2015会议的arXiv稿件合集》\n介绍:在这里你可以看到最近深度学习有什么新动向。\n《Introduction to Information Retrieval》\n介绍:此书在信息检索领域家喻户晓， 除提供该书的免费电子版外，还提供一个IR资源列表 ，收录了信息检索、网络信息检索、搜索引擎实现等方面相关的图书、研究中心、相关课程、子领域、会议、期刊等等，堪称全集，值得收藏\n《Information Geometry and its Applications to Machine Learning》\n介绍:信息几何学及其在机器学习中的应用\n《Legal Analytics – Introduction to the Course》\n介绍:课程《法律分析》介绍幻灯片。用机器学习解决法律相关分析和预测问题，相关的法律应用包括预测编码、早期案例评估、案件整体情况的预测，定价和工作人员预测，司法行为预测等。法律领域大家可能都比较陌生，不妨了解下。\n《文本上的算法》\n介绍: 文中提到了最优，模型，最大熵等等理论，此外还有应用篇。推荐系统可以说是一本不错的阅读稿，关于模型还推荐一篇Generative Model 与 Discriminative Model 《NeuralTalk》\n介绍: NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences.NeuralTalk是一个Python的从图像生成自然语言描述的工具。它实现了Google (Vinyals等，卷积神经网络CNN + 长短期记忆LSTM) 和斯坦福 (Karpathy and Fei-Fei， CNN + 递归神经网络RNN)的算法。NeuralTalk自带了一个训练好的动物模型，你可以拿狮子大象的照片来试试看\n《Deep Learning on Hadoop 2.0》\n介绍:本文主要介绍了在Hadoop2.0上使用深度学习,文章来自paypal\n《Practical recommendations for gradient-based training of deep architectures》\n介绍:用基于梯度下降的方法训练深度框架的实践推荐指导,作者是Yoshua Bengio .感谢@xuewei4d 推荐\n《Machine Learning With Statistical And Causal Methods》\n介绍: 用统计和因果方法做机器学习（视频报告）\n《Machine Learning Course 180’》\n介绍: 一个讲机器学习的Youtube视频教程。160集。系统程度跟书可比拟。\n《回归(regression)、梯度下降(gradient descent)》\n介绍: 机器学习中的数学，作者的研究方向是机器学习，并行计算如果你还想了解一点其他的可以看看他博客的其他文章\n《美团推荐算法实践》\n介绍: 美团推荐算法实践，从框架，应用，策略，查询等分析\n《Deep Learning for Answer Sentence Selection》\n介绍: 深度学习用于问答系统答案句的选取\n《Learning Semantic Representations Using Convolutional Neural Networks for Web Search 》\n介绍: CNN用于WEB搜索，深度学习在文本计算中的应用\n《Awesome Public Datasets》\n介绍: Awesome系列中的公开数据集\n《Search Engine &amp;amp; Community》\n介绍: 一个学术搜索引擎\n《spaCy》\n介绍: 用Python和Cython写的工业级自然语言处理库，号称是速度最快的NLP库，快的原因一是用Cython写的，二是用了个很巧妙的hash技术，加速系统的瓶颈，NLP中稀松特征的存取\n《Collaborative Filtering with Spark》\n介绍: Fields是个数学研究中心,上面的这份ppt是来自Fields举办的活动中Russ Salakhutdinov带来的《大规模机器学习》分享\n《Topic modeling 的经典论文》\n介绍: Topic modeling 的经典论文,标注了关键点\n《Move Evaluation in Go Using Deep Convolutional Neural Networks》\n介绍: 多伦多大学与Google合作的新论文，深度学习也可以用来下围棋，据说能达到六段水平\n《机器学习周刊第二期》\n介绍: 新闻，paper,课程，book，system,CES,Roboot，此外还推荐一个深度学习入门与综述资料 《Learning more like a human: 18 free eBooks on Machine Learning》\n介绍: 18 free eBooks on Machine Learning\n《Recommend :Hang Li Home》\n介绍:Chief scientist of Noah's Ark Lab of Huawei Technologies.He worked at the Research Laboratories of NEC Corporation during 1990 and 2001 and Microsoft Research Asia during 2001 and 2012.Paper 《DEEPLEARNING.UNIVERSITY – AN ANNOTATED DEEP LEARNING BIBLIOGRAPHY》\n介绍: DEEPLEARNING.UNIVERSITY的论文库已经收录了963篇经过分类的深度学习论文了，很多经典论文都已经收录\n《MLMU.cz - Radim Řehůřek - Word2vec &amp;amp; friends (7.1.2015)》\n介绍: Radim Řehůřek(Gensim开发者)在一次机器学习聚会上的报告，关于word2vec及其优化、应用和扩展，很实用.国内网盘 《Introducing streaming k-means in Spark 1.2》\n介绍:很多公司都用机器学习来解决问题，提高用户体验。那么怎么可以让机器学习更实时和有效呢？Spark MLlib 1.2里面的Streaming K-means，由斑马鱼脑神经研究的Jeremy Freeman脑神经科学家编写，最初是为了实时处理他们每半小时1TB的研究数据，现在发布给大家用了。\n《LDA入门与Java实现》\n介绍: 这是一篇面向工程师的LDA入门笔记，并且提供一份开箱即用Java实现。本文只记录基本概念与原理，并不涉及公式推导。文中的LDA实现核心部分采用了arbylon的LdaGibbsSampler并力所能及地注解了，在搜狗分类语料库上测试良好，开源在GitHub上。\n《AMiner - Open Science Platform》\n介绍: AMiner是一个学术搜索引擎，从学术网络中挖掘深度知识、面向科技大数据的挖掘。收集近4000万作者信息、8000万论文信息、1亿多引用关系、链接近8百万知识点；支持专家搜索、机构排名、科研成果评价、会议排名。\n《What are some interesting Word2Vec results?》\n介绍: Quora上的主题，讨论Word2Vec的有趣应用，Omer Levy提到了他在CoNLL2014最佳论文里的分析结果和新方法，Daniel Hammack给出了找特异词的小应用并提供了(Python)代码 《机器学习公开课汇总》\n介绍: 机器学习公开课汇总,虽然里面的有些课程已经归档过了，但是还有个别的信息没有。感谢课程图谱的小编\n《A First Course in Linear Algebra》\n介绍: 【A First Course in Linear Algebra】Robert Beezer 有答案 有移动版、打印版 使用GNU自由文档协议 引用了杰弗逊1813年的信\n《libfacedetection》\n介绍:libfacedetection是深圳大学开源的一个人脸图像识别库。包含正面和多视角人脸检测两个算法.优点:速度快(OpenCV haar+adaboost的2-3倍), 准确度高 (FDDB非公开类评测排名第二），能估计人脸角度。\n《Inverting a Steady-State》\n介绍:WSDM2015最佳论文 把马尔可夫链理论用在了图分析上面，比一般的propagation model更加深刻一些。通过全局的平稳分布去求解每个节点影响系数模型。假设合理（转移受到相邻的影响系数影响）。可以用来反求每个节点的影响系数\n《机器学习入门书单》\n介绍:机器学习入门书籍，具体介绍 《The Trouble with SVMs》\n介绍: 非常棒的强调特征选择对分类器重要性的文章。情感分类中，根据互信息对复杂高维特征降维再使用朴素贝叶斯分类器，取得了比SVM更理想的效果，训练和分类时间也大大降低——更重要的是，不必花大量时间在学习和优化SVM上——特征也一样no free lunch\n《Rise of the Machines》\n介绍:CMU的统计系和计算机系知名教授Larry Wasserman 在《机器崛起》,对比了统计和机器学习的差异\n《实例详解机器学习如何解决问题》\n介绍:随着大数据时代的到来，机器学习成为解决问题的一种重要且关键的工具。不管是工业界还是学术界，机器学习都是一个炙手可热的方向，但是学术界和工业界对机器学习的研究各有侧重，学术界侧重于对机器学习理论的研究，工业界侧重于如何用机器学习来解决实际问题。这篇文章是美团的实际环境中的实战篇\n《Gaussian Processes for Machine Learning》\n介绍:面向机器学习的高斯过程，章节概要：回归、分类、协方差函数、模型选择与超参优化、高斯模型与其他模型关系、大数据集的逼近方法等,微盘下载 《FuzzyWuzzy: Fuzzy String Matching in Python》\n介绍:Python下的文本模糊匹配库，老库新推，可计算串间ratio(简单相似系数)、partial_ratio(局部相似系数)、token_sort_ratio(词排序相似系数)、token_set_ratio(词集合相似系数)等 github 《Blocks》\n介绍:Blocks是基于Theano的神经网络搭建框架，集成相关函数、管道和算法，帮你更快地创建和管理NN模块.\n《Introduction to Machine Learning》\n介绍:机器学习大神Alex Smola在CMU新一期的机器学习入门课程”Introduction to Machine Learning“近期刚刚开课，课程4K高清视频同步到Youtube上，目前刚刚更新到 2.4 Exponential Families,课程视频playlist, 感兴趣的同学可以关注，非常适合入门.\n《Collaborative Feature Learning from Social Media》\n介绍:用社交用户行为学习图片的协同特征，可更好地表达图片内容相似性。由于不依赖于人工标签(标注)，可用于大规模图片处理，难在用户行为数据的获取和清洗；利用社会化特征的思路值得借鉴.\n《Introducing practical and robust anomaly detection in a time series》\n介绍:Twitter技术团队对前段时间开源的时间序列异常检测算法(S-H-ESD)R包的介绍，其中对异常的定义和分析很值得参考，文中也提到——异常是强针对性的，某个领域开发的异常检测在其他领域直接用可不行.\n《Empower Your Team to Deal with Data-Quality Issues》\n介绍:聚焦数据质量问题的应对，数据质量对各种规模企业的性能和效率都至关重要，文中总结出(不限于)22种典型数据质量问题显现的信号，以及典型的数据质量解决方案(清洗、去重、统一、匹配、权限清理等)\n《中文分词入门之资源》\n介绍:中文分词入门之资源.\n《Deep Learning Summit, San Francisco, 2015》\n介绍:15年旧金山深度学习峰会视频集萃,国内云盘 《Introduction to Conditional Random Fields》\n介绍:很好的条件随机场(CRF)介绍文章,作者的学习笔记\n《A Fast and Accurate Dependency Parser using Neural Networks》\n介绍: 来自Stanford，用神经网络实现快速准确的依存关系解析器\n《Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning》\n介绍:做深度学习如何选择GPU的建议\n《Sparse Linear Models》\n介绍: Stanford的Trevor Hastie教授在H2O.ai Meet-Up上的报告，讲稀疏线性模型——面向“宽数据”(特征维数超过样本数)的线性模型,13年同主题报告 、讲义.\n《Awesome Computer Vision》\n介绍: 分类整理的机器视觉相关资源列表，秉承Awesome系列风格，有质有量!作者的更新频率也很频繁\n《Adam Szeidl》\n介绍: social networks course\n《Building and deploying large-scale machine learning pipelines》\n介绍: 大规模机器学习流程的构建与部署.\n《人脸识别开发包》\n介绍: 人脸识别二次开发包，免费，可商用，有演示、范例、说明书.\n《Understanding Natural Language with Deep Neural Networks Using Torch》\n介绍: 采用Torch用深度学习网络理解NLP，来自Facebook 人工智能的文章.\n《The NLP Engine: A Universal Turing Machine for NLP》\n介绍: 来自CMU的Ed Hovy和Stanford的Jiwei Li一篇有意思的Arxiv文章,作者用Shannon Entropy来刻画NLP中各项任务的难度.\n《TThe Probabilistic Relevance Framework: BM25 and Beyond》\n介绍: 信息检索排序模型BM25(Besting Matching)。1）从经典概率模型演变而来 2）捕捉了向量空间模型中三个影响索引项权重的因子：IDF逆文档频率；TF索引项频率；文档长度归一化。3）并且含有集成学习的思想：组合了BM11和BM15两个模型。4）作者是BM25的提出者和Okapi实现者Robertson.\n《Introduction to ARMA Time Series Models – simplified》\n介绍: 自回归滑动平均(ARMA)时间序列的简单介绍，ARMA是研究时间序列的重要方法，由自回归模型（AR模型）与滑动平均模型（MA模型）为基础“混合”构成.\n《Encoding Source Language with Convolutional Neural Network for Machine Translation》\n介绍: 把来自target的attention signal加入source encoding CNN的输入，得到了比BBN的模型好的多neural network joint model\n《Spices form the basis of food pairing in Indian cuisine》\n介绍: 揭开印度菜的美味秘诀——通过对大量食谱原料关系的挖掘，发现印度菜美味的原因之一是其中的味道互相冲突，很有趣的文本挖掘研究\n《HMM相关文章索引》\n介绍: HMM相关文章,此外推荐中文分词之HMM模型详解 《Zipf&amp;#x27;s and Heap&amp;#x27;s law》\n介绍: 1)词频与其降序排序的关系,最著名的是语言学家齐夫(Zipf,1902-1950)1949年提出的Zipf‘s law,即二者成反比关系. 曼德勃罗(Mandelbrot,1924- 2010)引入参数修正了对甚高频和甚低频词的刻画 2)Heaps' law: 词汇表与语料规模的平方根(这是一个参数,英语0.4-0.6)成正比\n《I am Jürgen Schmidhuber, AMA》\n介绍: Jürgen Schmidhuber在Reddit上的AMA(Ask Me Anything)主题，有不少RNN和AI、ML的干货内容，关于开源&思想&方法&建议……耐心阅读，相信你也会受益匪浅.\n《学术种子网站：AcademicTorrents》\n介绍: 成G上T的学术数据，HN近期热议话题,主题涉及机器学习、NLP、SNA等。下载最简单的方法，通过BT软件，RSS订阅各集合即可\n《机器学习交互速查表》\n介绍: Scikit-Learn官网提供，在原有的Cheat Sheet基础上加上了Scikit-Learn相关文档的链接，方便浏览\n《A Full Hardware Guide to Deep Learning》\n介绍: 深度学习的全面硬件指南，从GPU到RAM、CPU、SSD、PCIe\n《行人检测(Pedestrian Detection)资源》\n介绍:Pedestrian Detection paper & data\n《A specialized face-processing network consistent with the representational geometry of monkey face patches》\n介绍: 【神经科学碰撞人工智能】在脸部识别上你我都是专家，即使细微的差别也能辨认。研究已证明人类和灵长类动物在面部加工上不同于其他物种，人类使用梭状回面孔区（FFA）。Khaligh-Razavi等通过计算机模拟出人脸识别的FFA活动，堪称神经科学与人工智能的完美结合。\n《Neural Net in C++ Tutorial》\n介绍: 神经网络C++教程,本文介绍了用可调节梯度下降和可调节动量法设计和编码经典BP神经网络，网络经过训练可以做出惊人和美妙的东西出来。此外作者博客的其他文章也很不错。\n《How to Choose a Neural Network》\n介绍:deeplearning4j官网提供的实际应用场景NN选择参考表，列举了一些典型问题建议使用的神经网络\n《Deep Learning (Python, C/C++, Java, Scala, Go)》\n介绍:一个深度学习项目,提供了Python, C/C++, Java, Scala, Go多个版本的代码\n《Deep Learning Tutorials》\n介绍:深度学习教程,github 《自然语言处理的发展趋势——访卡内基梅隆大学爱德华·霍威教授》\n介绍:自然语言处理的发展趋势——访卡内基梅隆大学爱德华·霍威教授.\n《FaceNet: A Unified Embedding for Face Recognition and Clustering》\n介绍:Google对Facebook DeepFace的有力回击—— FaceNet，在LFW(Labeled Faces in the Wild)上达到99.63%准确率(新纪录)，FaceNet embeddings可用于人脸识别、鉴别和聚类.\n《MLlib中的Random Forests和Boosting》\n介绍:本文来自Databricks公司网站的一篇博客文章，由Joseph Bradley和Manish Amde撰写，文章主要介绍了Random Forests和Gradient-Boosted Trees（GBTs）算法和他们在MLlib中的分布式实现，以及展示一些简单的例子并建议该从何处上手.中文版.\n《Sum-Product Networks(SPN) 》\n介绍:华盛顿大学Pedro Domingos团队的DNN，提供论文和实现代码.\n《Neural Network Dependency Parser》\n介绍:基于神经网络的自然语言依存关系解析器(已集成至Stanford CoreNLP)，特点是超快、准确，目前可处理中英文语料，基于《A Fast and Accurate Dependency Parser Using Neural Networks》 思路实现.\n《神经网络语言模型》\n介绍:本文根据神经网络的发展历程，详细讲解神经网络语言模型在各个阶段的形式，其中的模型包含NNLM[Bengio,2003]、Hierarchical NNLM[Bengio, 2005], Log-Bilinear[Hinton, 2007],SENNA等重要变形，总结的特别好.\n《Classifying Spam Emails using Text and Readability Features》\n介绍:经典问题的新研究：利用文本和可读性特征分类垃圾邮件。\n《BCI Challenge @ NER 2015》\n介绍:Kaggle脑控计算机交互(BCI)竞赛优胜方案源码及文档，包括完整的数据处理流程，是学习Python数据处理和Kaggle经典参赛框架的绝佳实例\n《IPOL Journal · Image Processing On Line》\n介绍:IPOL（在线图像处理）是图像处理和图像分析的研究期刊，每篇文章都包含一个算法及相应的代码、Demo和实验文档。文本和源码是经过了同行评审的。IPOL是开放的科学和可重复的研究期刊。我一直想做点类似的工作，拉近产品和技术之间的距离.\n《Machine learning classification over encrypted data》\n介绍:出自MIT，研究加密数据高效分类问题.\n《purine2》\n介绍:新加坡LV实验室的神经网络并行框架Purine: A bi-graph based deep learning framework,支持构建各种并行的架构，在多机多卡，同步更新参数的情况下基本达到线性加速。12块Titan 20小时可以完成Googlenet的训练。\n《Machine Learning Resources》\n介绍:这是一个机器学习资源库,虽然比较少.但蚊子再小也是肉.有突出部分.此外还有一个由zheng Rui整理的机器学习资源.\n《Hands-on with machine learning》\n介绍:Chase Davis在NICAR15上的主题报告材料，用Scikit-Learn做监督学习的入门例子.\n《The Natural Language Processing Dictionary》\n介绍:这是一本自然语言处理的词典,从1998年开始到目前积累了成千上万的专业词语解释,如果你是一位刚入门的朋友.可以借这本词典让自己成长更快.\n《PageRank Approach to Ranking National Football Teams》\n介绍:通过分析1930年至今的比赛数据，用PageRank计算世界杯参赛球队排行榜.\n《R Tutorial》\n介绍:R语言教程,此外还推荐一个R语言教程An Introduction to R.\n《Fast unfolding of communities in large networks》\n介绍:经典老文，复杂网络社区发现的高效算法，Gephi中的[Community detection](The Louvain method for community detection in large networks)即基于此.\n《NUML》\n介绍: 一个面向 .net 的开源机器学习库,github地址 《synaptic.Js》\n介绍: 支持node.js的JS神经网络库，可在客户端浏览器中运行，支持LSTM等 github地址 《Machine learning for package users with R (1): Decision Tree》\n介绍: 决策树\n《Deep Learning, The Curse of Dimensionality, and Autoencoders》\n介绍: 讨论深度学习自动编码器如何有效应对维数灾难,国内翻译 《Advanced Optimization and Randomized Methods》\n介绍: CMU的优化与随机方法课程，由A. Smola和S. Sra主讲，优化理论是机器学习的基石，值得深入学习 国内云(视频) 《CS231n: Convolutional Neural Networks for Visual Recognition》\n介绍: \"面向视觉识别的CNN\"课程设计报告集锦.近百篇，内容涉及图像识别应用的各个方面\n《Topic modeling with LDA: MLlib meets GraphX》\n介绍:用Spark的MLlib+GraphX做大规模LDA主题抽取.\n《Deep Learning for Multi-label Classification》\n介绍: 基于深度学习的多标签分类,用基于RBM的DBN解决多标签分类(特征)问题\n《Google DeepMind publications》\n介绍: DeepMind论文集锦\n《kaldi》\n介绍: 一个开源语音识别工具包,它目前托管在sourceforge上面\n《Data Journalism Handbook》\n介绍: 免费电子书《数据新闻手册》, 国内有热心的朋友翻译了中文版,大家也可以在线阅读 《Data Mining Problems in Retail》\n介绍: 零售领域的数据挖掘文章.\n《Understanding Convolution in Deep Learning》\n介绍: 深度学习卷积概念详解,深入浅出.\n《pandas: powerful Python data analysis toolkit》\n介绍: 非常强大的Python的数据分析工具包.\n《Text Analytics 2015》\n介绍: 2015文本分析(商业)应用综述.\n《Deep Learning libraries and ﬁrst experiments with Theano》\n介绍: 深度学习框架、库调研及Theano的初步测试体会报告.\n《DEEP learning》\n介绍: MIT的Yoshua Bengio, Ian Goodfellow, Aaron Courville著等人讲深度学习的新书，还未定稿，线上提供Draft chapters收集反馈，超赞！强烈推荐.\n《simplebayes》\n介绍: Python下开源可持久化朴素贝叶斯分类库.\n《Paracel》\n介绍:Paracel is a distributed computational framework designed for machine learning problems, graph algorithms and scientific computing in C++.\n《HanLP:Han Language processing》\n介绍: 开源汉语言处理包.\n《Simple Neural Network implementation in Ruby》\n介绍: 使用Ruby实现简单的神经网络例子.\n《Hacker&amp;#x27;s guide to Neural Networks》\n介绍:神经网络黑客入门.\n《The Open-Source Data Science Masters》\n介绍:好多数据科学家名人推荐,还有资料.\n《Text Understanding from Scratch》\n介绍:实现项目已经开源在github上面Crepe 《 Improving Distributional Similarity with Lessons Learned from Word Embeddings》\n介绍:作者发现，经过调参，传统的方法也能和word2vec取得差不多的效果。另外，无论作者怎么试，GloVe都比不过word2vec.\n《CS224d: Deep Learning for Natural Language Processing》\n介绍:Stanford深度学习与自然语言处理课程,Richard Socher主讲.\n《Math Essentials in Machine Learning》\n介绍:机器学习中的重要数学概念.\n《Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks》\n介绍:用于改进语义表示的树型LSTM递归神经网络,句子级相关性判断和情感分类效果很好.实现代码.\n《Statistical Machine Learning》\n介绍:卡耐基梅隆Ryan Tibshirani和Larry Wasserman开设的机器学习课程，先修课程为机器学习(10-715)和中级统计学(36-705)，聚焦统计理论和方法在机器学习领域应用.\n《AM207: Monte Carlo Methods, Stochastic Optimization》\n介绍:《哈佛大学蒙特卡洛方法与随机优化课程》是哈佛应用数学研究生课程，由V Kaynig-Fittkau、P Protopapas主讲，Python程序示例，对贝叶斯推理感兴趣的朋友一定要看看，提供授课视频及课上IPN讲义.\n《生物医学的SPARK大数据应用》\n介绍:生物医学的SPARK大数据应用.并且伯克利开源了他们的big data genomics系统ADAM，其他的内容可以关注一下官方主页.\n《ACL Anthology》\n介绍:对自然语言处理技术或者机器翻译技术感兴趣的亲们，请在提出自己牛逼到无以伦比的idea（自动归纳翻译规律、自动理解语境、自动识别语义等等）之前，请通过谷歌学术简单搜一下，如果谷歌不可用，这个网址有这个领域几大顶会的论文列表,切不可断章取义,胡乱假设.\n《Twitter Sentiment Detection via Ensemble Classification Using Averaged Confidence Scores》\n介绍:论文+代码:基于集成方法的Twitter情感分类,实现代码.\n《NIPS 2014 CIML workshop》\n介绍:NIPS CiML 2014的PPT,NIPS是神经信息处理系统进展大会的英文简称.\n《CS231n: Convolutional Neural Networks for Visual Recognition》\n介绍:斯坦福的深度学习课程的Projects 每个人都要写一个论文级别的报告 里面有一些很有意思的应用 大家可以看看 .\n《A Speed Comparison Between Flexible Linear Regression Alternatives in R》\n介绍:R语言线性回归多方案速度比较具体方案包括lm()、nls()、glm()、bayesglm()、nls()、mle2()、optim()和Stan’s optimizing()等.\n《Back-to-Basics Weekend Reading - Machine Learning》\n介绍:文中提到的三篇论文（机器学习那些事、无监督聚类综述、监督分类综述）都很经典，Domnigos的机器学习课也很精彩\n《A Probabilistic Theory of Deep Learning》\n介绍:莱斯大学（Rice University）的深度学习的概率理论.\n《Nonsensical beer reviews via Markov chains》\n介绍:基于马尔可夫链自动生成啤酒评论的开源Twitter机器人,github地址.\n《Deep Learning for Natural Language Processing (without Magic)》\n介绍:视频+讲义:深度学习用于自然语言处理教程(NAACL13).\n《Introduction to Data Analysis using Machine Learning》\n介绍:用机器学习做数据分析,David Taylor最近在McGill University研讨会上的报告，还提供了一系列讲机器学习方法的ipn，很有价值 GitHub.国内 《Beyond Short Snippets: Deep Networks for Video Classification》\n介绍:基于CNN+LSTM的视频分类,google演示.\n《How does Quora use machine learning in 2015?》\n介绍:Quora怎么用机器学习.\n《Amazon Machine Learning – Make Data-Driven Decisions at Scale》\n介绍:亚马逊在机器学习上面的一些应用,代码示例.\n《Parallel Machine Learning with scikit-learn and IPython》\n介绍:并行机器学习指南(基于scikit-learn和IPython).notebook 《Intro to machine learning with scikit-learn》\n介绍:DataSchool的机器学习基本概念教学.\n《DeepCLn》\n介绍:一个基于OpenGL实现的卷积神经网络，支持Linux及Windows系.\n《An Inside Look at the Components of a Recommendation Engine》\n介绍:基于Mahout和Elasticsearch的推荐系统.\n《Forecasting in Economics, Business, Finance and Beyond》\n介绍:Francis X. Diebold的《(经济|商业|金融等领域)预测方法.\n《Time Series Econometrics - A Concise Course》\n介绍:Francis X. Diebold的《时序计量经济学》.\n《A comparison of open source tools for sentiment analysis》\n介绍:基于Yelp数据集的开源情感分析工具比较,评测覆盖Naive Bayes、SentiWordNet、CoreNLP等 .\n《Pattern Recognition And Machine Learning》\n介绍:国内Pattern Recognition And Machine Learning读书会资源汇总,各章pdf讲稿,博客.\n《Probabilistic Data Structures for Web Analytics and Data Mining 》\n介绍:用于Web分析和数据挖掘的概率数据结构.\n《Machine learning in navigation devices: detect maneuvers using accelerometer and gyroscope》\n介绍:机器学习在导航上面的应用.\n《Neural Networks Demystified 》\n介绍:Neural Networks Demystified系列视频，Stephen Welch制作，纯手绘风格，浅显易懂,国内云.\n《swirl + DataCamp 》\n介绍:{swirl}数据训练营:R&数据科学在线交互教程.\n《Learning to Read with Recurrent Neural Networks 》\n介绍:关于深度学习和RNN的讨论 Sequence to Sequence Learning with Neural Networks.\n《深度强化学习（Deep Reinforcement Learning）的资源》\n介绍:Deep Reinforcement Learning.\n《Machine Learning with Scikit-Learn》\n介绍:(PyCon2015)Scikit-Learn机器学习教程,Parallel Machine Learning with scikit-learn and IPython.\n《PDNN》\n介绍:PDNN: A Python Toolkit for Deep Learning.\n《Introduction to Machine Learning》\n介绍:15年春季学期CMU的机器学习课程，由Alex Smola主讲，提供讲义及授课视频，很不错.国内镜像.\n《Big Data Processing》\n介绍:大数据处理课.内容覆盖流处理、MapReduce、图算法等.\n《Spark MLlib: Making Practical Machine Learning Easy and Scalable》\n介绍:用Spark MLlib实现易用可扩展的机器学习,国内镜像.\n《Picture: A Probabilistic Programming Language for Scene Perception》\n介绍:以往上千行代码概率编程(语言)实现只需50行.\n《Beautiful plotting in R: A ggplot2 cheatsheet》\n介绍:ggplot2速查小册子,另外一个,此外还推荐《A new data processing workflow for R: dplyr, magrittr, tidyr, ggplot2》.\n《Using Structured Events to Predict Stock Price Movement: An Empirical Investigation》\n介绍:用结构化模型来预测实时股票行情.\n《International Joint Conference on Artificial Intelligence Accepted paper》\n介绍:国际人工智能联合会议录取论文列表,大部分论文可使用Google找到.\n《Why GEMM is at the heart of deep learning》\n介绍:一般矩阵乘法(GEMM)对深度学习的重要性.\n《Distributed (Deep) Machine Learning Common》\n介绍:A Community of awesome Distributed Machine Learning C++ projects.\n《Reinforcement Learning: An Introduction》\n介绍:免费电子书<强化学习介绍>,第一版(1998),第二版(2015草稿),相关课程资料,Reinforcement Learning.\n《Free ebook: Microsoft Azure Essentials: Azure Machine Learning》\n介绍:免费书:Azure ML使用精要.\n《A Deep Learning Tutorial: From Perceptrons to Deep Networks》\n介绍:A Deep Learning Tutorial: From Perceptrons to Deep Networks.\n《Machine Learning is Fun! - The world’s easiest introduction to Machine Learning》\n介绍:有趣的机器学习：最简明入门指南,中文版.\n《A Brief Overview of Deep Learning》\n介绍:深度学习简明介绍,中文版.\n《Wormhole》\n介绍:Portable, scalable and reliable distributed machine learning.\n《convnet-benchmarks》\n介绍:CNN开源实现横向评测,参评框架包括Caffe 、Torch-7、CuDNN 、cudaconvnet2 、fbfft、Nervana Systems等，NervanaSys表现突出.\n《This catalogue lists resources developed by faculty and students of the Language Technologies Institute.》\n介绍:卡耐基梅隆大学计算机学院语言技术系的资源大全,包括大量的NLP开源软件工具包，基础数据集，论文集，数据挖掘教程，机器学习资源.\n《Sentiment Analysis on Twitter》\n介绍:Twitter情感分析工具SentiTweet,视频+讲义.\n《Machine Learning Repository @ Wash U》\n介绍:华盛顿大学的Machine Learning Paper Repository.\n《Machine learning cheat sheet》\n介绍:机器学习速查表.\n《Spark summit east 2015 agenda》\n介绍:最新的Spark summit会议资料.\n《Spark summit east 2015 agenda》\n介绍:最新的Spark summit会议资料.\n《Learning Spark》\n介绍:Ebook Learning Spark.\n《Advanced Analytics with Spark, Early Release Edition》\n介绍:Ebook Advanced Analytics with Spark, Early Release Edition.\n《国内机器学习算法及应用领域人物篇:唐杰》\n介绍:清华大学副教授，是图挖掘方面的专家。他主持设计和实现的Arnetminer是国内领先的图挖掘系统，该系统也是多个会议的支持商.\n《国内机器学习算法及应用领域人物篇:杨强》\n介绍:迁移学习的国际领军人物.\n《国内机器学习算法及应用领域人物篇:周志华》\n介绍:在半监督学习，multi-label学习和集成学习方面在国际上有一定的影响力.\n《国内机器学习算法及应用领域人物篇:王海峰》\n介绍:信息检索，自然语言处理，机器翻译方面的专家.\n《国内机器学习算法及应用领域人物篇:吴军》\n介绍:吴军博士是当前Google中日韩文搜索算法的主要设计者。在Google其间，他领导了许多研发项目，包括许多与中文相关的产品和自然语言处理的项目,他的新个人主页.\n《Cat Paper Collection》\n介绍:喵星人相关论文集.\n《How to Evaluate Machine Learning Models, Part 1: Orientation》\n介绍:如何评价机器学习模型系列文章,How to Evaluate Machine Learning Models, Part 2a: Classification Metrics,How to Evaluate Machine Learning Models, Part 2b: Ranking and Regression Metrics.\n《Building a new trends experience》\n介绍:Twitter新trends的基本实现框架.\n《Storm Blueprints: Patterns for Distributed Real-time Computation》\n介绍:Storm手册，国内有中文翻译版本,谢谢作者.\n《SmileMiner》\n介绍:Java机器学习算法库SmileMiner.\n《机器翻译学术论文写作方法和技巧》\n介绍:机器翻译学术论文写作方法和技巧，Simon Peyton Jones的How to write a good research paper同类视频How to Write a Great Research Paper,how to paper talk.\n《神经网络训练中的Tricks之高效BP（反向传播算法）》\n介绍:神经网络训练中的Tricks之高效BP,博主的其他博客也挺精彩的.\n《我和NLP的故事》\n介绍:作者是NLP方向的硕士，短短几年内研究成果颇丰,推荐新入门的朋友阅读.\n《The h Index for Computer Science 》\n介绍:UCLA的Jens Palsberg根据Google Scholar建立了一个计算机领域的H-index牛人列表,我们熟悉的各个领域的大牛绝大多数都在榜上，包括1位诺贝尔奖得主，35位图灵奖得主，近百位美国工程院/科学院院士，300多位ACM Fellow,在这里推荐的原因是大家可以在google通过搜索牛人的名字来获取更多的资源,这份资料很宝贵.\n《Structured Learning for Taxonomy Induction with Belief Propagation》\n介绍:用大型语料库学习概念的层次关系，如鸟是鹦鹉的上级，鹦鹉是虎皮鹦鹉的上级。创新性在于模型构造，用因子图刻画概念之间依存关系，因引入兄弟关系，图有环，所以用有环扩散（loopy propagation）迭代计算边际概率（marginal probability）.\n《Bayesian analysis》\n介绍: 这是一款贝叶斯分析的商业软件,官方写的贝叶斯分析的手册有250多页,虽然R语言 已经有类似的项目,但毕竟可以增加一个可选项.\n《deep net highlights from 2014》\n介绍:deep net highlights from 2014.\n《Fast R-CNN》\n介绍:This paper proposes Fast R-CNN, a clean and fast framework for object detection.\n《Fingerprinting Images for Near-Duplicate Detection》\n介绍:图像指纹的重复识别,作者源码,国内翻译版本.\n《The Computer Vision Industry 》\n介绍:提供计算机视觉、机器视觉应用的公司信息汇总.应用领域包括：自动辅助驾驶和交通管理、眼球和头部跟踪、影视运动分析、影视业、手势识别、通用视觉系统、各种工业自动化和检验、医药和生物、移动设备目标识别和AR、人群跟踪、摄像、安全监控、生物监控、三维建模、web和云应用.\n《Seaborn: statistical data visualization》\n介绍:Python版可视化数据统计开源库.\n《IPython lecture notes for OCW MIT 18.06》\n介绍:麻省理工Gilbert Strang线性代数课程笔记,Gilbert Strang《Linear Algebra》课程主页视频+讲义.\n《Canova: A Vectorization Lib for ML》\n介绍:面向机器学习/深度学习的数据向量化工具Canova,github, 支持CSV文件、MNIST数据、TF-IDF/Bag of Words/word2vec文本向量化.\n《DZone Refcardz: Distributed Machine Learning with Apache Mahout》\n介绍:快速入门：基于Apache Mahout的分布式机器学习.\n《Learning scikit-learn: Machine Learning in Python》\n介绍:基于scikit-learn讲解了一些机器学习技术，如SVM，NB，PCA，DT，以及特征工程、特征选择和模型选择问题.\n《Lightning fast Machine Learning with Spark》\n介绍:基于Spark的高效机器学习,视频地址.\n《How we’re using machine learning to fight shell selling》\n介绍:WePay用机器学习对抗信用卡\"shell selling\"诈骗.\n《Data Scientists Thoughts that Inspired Me》\n介绍:16位数据科学家语录精选.\n《Deep learning applications and challenges in big data analytics》\n介绍:深度学习在大数据分析领域的应用和挑战.\n《Free book:Machine Learning,Mathematics》\n介绍:免费的机器学习与数学书籍,除此之外还有其他的免费编程书籍,编程语言,设计,操作系统等.\n《Object detection via a multi-region &amp;amp; semantic segmentation-aware CNN model》\n介绍:一篇关于CNN模型对象识别Paper.\n《A Statistical View of Deep Learning (V): Generalisation and Regularisation》\n介绍:深度学习的统计分析V:泛化和正则化.\n《Highway Networks》\n介绍:用SGD能高效完成训练的大规模(多层)深度网络HN.\n《What I Read For Deep-Learning》\n介绍:深度学习解读文章.\n《An Introduction to Recommendation Engines》\n介绍:Coursera上的推荐系统导论（Introduction to Recommender Systems）公开课.\n《Stanford Machine Learning》\n介绍:Andrew Ng经典机器学习课程笔记.\n《ICLR 2015》\n介绍:ICLR 2015见闻录,博客的其他机器学习文章也不错.\n《Stanford Machine Learning》\n介绍:推荐系统\"个性化语义排序\"模型.\n《The More Excited We Are, The Shorter We Tweet》\n介绍:激情时分更惜字——MIT的最新Twitter研究结果.\n《苏州大学人类语言技术研究论文主页》\n介绍:苏州大学人类语言技术研究相关论文.\n《Neural Turing Machines implementation》\n介绍:实现神经图灵机(NTM),项目地址,此外推荐相关神经图灵机算法.\n《Computer Vision - CSE 559A, Spring 2015》\n介绍:华盛顿大学的机器视觉(2015),参考资料Computer Vision: Algorithms and Applications.\n《Mining of Massive Datasets》\n介绍:\"Mining of Massive Datasets\"发布第二版,Jure Leskovec, Anand Rajaraman, Jeff Ullman 新版增加Jure Leskovec作为合作作者，新增社交网络图数据挖掘、降维和大规模机器学习三章,电子版依旧免费.\n《Learning Deep Learning》\n介绍:一个深度学习资源页,资料很丰富.\n《Learning Deep Learning》\n介绍:免费电子书\"Learning Deep Learning\".\n《Tutorial: Machine Learning for Astronomy with Scikit-learn》\n介绍:Machine Learning for Astronomy with scikit-learn.\n《An Introduction to Random Forests for Beginners》\n介绍:免费电子书\"随机森林入门指南\".\n《Top 10 data mining algorithms in plain English》\n介绍:白话数据挖掘十大算法.\n《An Inside Look at the Components of a Recommendation Engine》\n介绍:基于Mahout和Elasticsearch的推荐系统,国内译版.\n《Advances in Extreme Learning Machines》\n介绍:博士学位论文:ELM研究进展.\n《10-minute tour of pandas》\n介绍:Pandas十分钟速览,ipn.\n《Data doesn&amp;#x27;t grow in tables: harvesting journalistic insight from documents》\n介绍:面向数据新闻的文本挖掘.\n《Time-lapse Mining from Internet Photos》\n介绍:用网络图片合成延时视频(SIGGRAPH 2015).\n《The Curse of Dimensionality in classification》\n介绍:分类系统的维数灾难.\n《Deep Learning vs Big Data: Who owns what?》\n介绍:深度学习vs.大数据——从数据到知识：版权的思考,[翻译版](http://www.csdn.net/article/2015-05-19/2824707 《A Primer on Predictive Models》\n介绍:预测模型入门.\n《Demistifying LSTM Neural Networks》\n介绍:深入浅出LSTM.\n《ICLR 2015》\n介绍:2015年ICLR会议视频与讲义.\n《On Visualizing Data Well》\n介绍:Ben Jones的数据可视化建议.\n《Decoding Dimensionality Reduction, PCA and SVD》\n介绍:解读数据降维/PCA/SVD.\n《Supervised learning superstitions cheat sheet》\n介绍:IPN:监督学习方法示例/对比参考表,覆盖logistic回归, 决策树, SVM, KNN, Naive Bayes等方法.\n《DopeLearning: A Computational Approach to Rap Lyrics Generation》\n介绍:基于RankSVM和DNN自动(重组)生成Rap歌词.\n《An Introduction to Random Indexing》\n介绍:随机索引RI词空间模型专题.\n《VDiscover》\n介绍:基于机器学习的漏洞检测工具VDiscover.\n《Minerva》\n介绍:深度学习系统minerva。拥有python编程接口。多GPU几乎达到线性加速。在4块GPU上能在4天内将GoogLeNet训练到68.7%的top-1以及89.0%的top-5准确率。和同为dmlc项目的cxxnet相比，采用动态数据流引擎，提供更多灵活性。未来将和cxxnet一起整合为mxnet项目，互取优势.\n《CVPR 2015 paper》\n介绍:2015年国际计算机视觉与模式识别会议paper.\n《What are the advantages of different classification algorithms?》\n介绍:Netflix工程总监眼中的分类算法：深度学习优先级最低,中文版.\n《Results for Microsoft COCO Image Captioning Challenge》\n介绍:Codalab图像标注竞赛排行+各家论文,Reddit上flukeskywalker整理了各家技术相关论文.\n《Caffe con Troll: Shallow Ideas to Speed Up Deep Learning》\n介绍:基于Caffe的加速深度学习系统CcT.\n《Low precision storage for deep learning》\n介绍:深度学习(模型)低精度(训练与)存储.\n《Model-Based Machine Learning (Early Access)》\n介绍:新书预览:模型机器学习.\n《Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems》\n介绍:免费电子书多臂老虎机,此外推荐Introduction to Bandits: Algorithms and Theory.\n《Kaggle R Tutorial on Machine Learing》\n介绍:基于Kaggle's Titanic Competition的交互式R机器学习教程,介绍《Interactive R Tutorial: Machine Learning for the Titanic Competition》.\n《Deep Learning（深度学习）学习笔记整理系列》\n介绍:Deep Learning（深度学习）学习笔记整理系列.\n《Introduction to Neural Machine Translation with GPUs 》\n介绍:神经(感知)机器翻译介绍.\n《Andrew Ng: Deep Learning, Self-Taught Learning and Unsupervised Feature Learning》\n介绍:Andrew Ng关于深度学习/自学习/无监督特征学习的报告,国内云.\n《Recurrent Neural Network Training with Dark Knowledge Transfer》\n介绍:论文:通过潜在知识迁移训练RNN.\n《Show Me The Money》\n介绍:面向金融数据的情感分析工具.\n《pyLDAvis》\n介绍:(Python)主题模型交互可视化库pyLDAvis.\n《Logistic Regression and Gradient Descent》\n介绍:Logistic回归与优化实例教程.\n《贾扬清微信讲座记录》\n介绍:贾扬清（谷歌大脑科学家、caffe缔造者）微信讲座记录.\n《sketch》\n介绍:Theano/Blocks实现RNN手写字符串生成sketch.\n《Web Scale Document Clustering: Clustering 733 Million Web Pages》\n介绍:基于TopSig的海量(7亿+)网页聚类.\n《NAACL 2015 Proceedings on ACL Anthology》\n介绍:NAACL 2015 论文papers.\n《Stock Forecasting With Machine Learning - Seven Possible Errors》\n介绍:机器学习预测股市的七个问题.\n《Are there any good resources for learning about neural networks?》\n介绍:神经网络学习资料推荐.\n《A Critical Review of Recurrent Neural Networks for Sequence Learning》\n介绍:面向序列学习的RNN综述.\n《Handling and Processing Strings in R》\n介绍:R文本处理手册.\n《Must-watch videos about Python》\n介绍:“必看”的Python视频集锦.\n《The Google Stack》\n介绍:Google(基础结构)栈.\n《Randomized Algorithms for Matrices and Data》\n介绍:矩阵和数据的随机算法(UC Berkeley 2013).\n《Intermediate R》\n介绍:DataCamp中级R语言教程.\n《Topology Without Tears》\n介绍:免费电子书:轻松掌握拓扑学,中文版.\n《Information Theory, Pattern Recognition, and Neural Networks》\n介绍:Book,video.\n《Scikit-learn》\n介绍:Scikit-learn 是基于Scipy为机器学习建造的的一个Python模块，他的特色就是多样化的分类，回归和聚类的算法包括支持向量机，逻辑回归，朴素贝叶斯分类器，随机森林，Gradient Boosting，聚类算法和DBSCAN。而且也设计出了Python numerical和scientific libraries Numpy and Scipy\n《Pylearn2》\n介绍:Pylearn是一个让机器学习研究简单化的基于Theano的库程序。\n《NuPIC》\n介绍:NuPIC是一个以HTM学习算法为工具的机器智能平台。HTM是皮层的精确计算方法。HTM的核心是基于时间的持续学习算法和储存和撤销的时空模式。NuPIC适合于各种各样的问题,尤其是检测异常和预测的流数据来源。\n《Nilearn》\n介绍:Nilearn 是一个能够快速统计学习神经影像数据的Python模块。它利用Python语言中的scikit-learn 工具箱和一些进行预测建模，分类，解码，连通性分析的应用程序来进行多元的统计。\n《PyBrain》\n介绍:Pybrain是基于Python语言强化学习，人工智能，神经网络库的简称。 它的目标是提供灵活、容易使用并且强大的机器学习算法和进行各种各样的预定义的环境中测试来比较你的算法。\n《Pattern》\n介绍:Pattern 是Python语言下的一个网络挖掘模块。它为数据挖掘，自然语言处理，网络分析和机器学习提供工具。它支持向量空间模型、聚类、支持向量机和感知机并且用KNN分类法进行分类。\n《Fuel》\n介绍:Fuel为你的机器学习模型提供数据。他有一个共享如MNIST, CIFAR-10 (图片数据集), Google’s One Billion Words (文字)这类数据集的接口。你使用他来通过很多种的方式来替代自己的数据。", "answer_votes": "101", "answer_comment": "​13 条评论"}
{"answer_author": "知乎用户", "answer_id": 57739892, "answer_text": "什么是机器学习，请参考这里，什么是机器学习？----------------------------------------------------------------------------------建议视频、书和编程实践结合起来学习。视频：coursera 林轩田 《機器學習基石 (Machine Learning Foundations)》                网易公开课 Andrew Ng 《 斯坦福大学公开课 ：机器学习课程》书籍：李航 《统计学习方法 (豆瓣)》                 Christopher M. Bishop 《Pattern Recognition And Machine Learning (豆瓣)》编程实践：《Peter Harrington机器学习实战 (豆瓣)》                       《TOBY SEGARAN集体智慧编程 (豆瓣)》从头入门的话，可以先看李航的《统计学习方法》和《机器学习实战》，Coursera上有吴恩达的ML的课程，最近才开你可以去跟着看看。我其实更推荐A站上的台大林老师的课，虽然第一部分结课了，但是现在还可以看，课后题认真做收获很大的。等这些都看完以后，补充点数学知识，就可以去看PRML或者MLAPP或者ESL，然后就要看你的方向了。&lt;img src=\"https://pic4.zhimg.com/50/e649e1433fab12c3c601b136b751286f_hd.jpg\" data-rawwidth=\"370\" data-rawheight=\"229\" class=\"content_image\" width=\"370\"&gt;碰到不明白的数学理论，直接谷歌百度就可以了。这些消化了，机器学习基本算入门了。", "answer_votes": "34", "answer_comment": "​12 条评论"}
{"answer_author": "Spirit_Dongdong", "answer_id": 15909488, "answer_text": "尝试跟一下斯坦福的机器学期公开课吧已经全部翻译完整了http://v.163.com/special/opencourse/machinelearning.html", "answer_votes": "15", "answer_comment": "​添加评论"}
{"answer_author": "徐亦达", "answer_id": 68441652, "answer_text": "可以道优酷看下徐亦达老师的机器学习视频：优酷网-中国第一视频网,提供视频播放,视频发布,视频搜索", "answer_votes": "29", "answer_comment": "​5 条评论"}
{"answer_author": "面包君", "answer_id": 81498421, "answer_text": "转行干机器学习也一年半载了，从之前一直接触算法建模的工作到现在撘机器学习的平台，也走了不少弯路，幸好的是交流比较多，资源比较多，所以上手也比较快。还有一个就是应用的场景也有很多，所以实践的机会不少。从最初的LR模型实现，每天和运营穿一条裤子，要去理解哪些是我们的目标用户，什么情况算是bad case；和产品撕逼，怎么我们这个数据埋点没有啊，我们的数据口径怎么都一样啊；跪在技术哥身边，早点把营销平台和推荐平台打通哈，什么时候能把online学习做进去啊，action rules什么时候实现啊，怎么把strategy ID和marketing content对应起来啊。这些早期的坑也是踩了一个又一个，好了，推荐的基础框架搭起来了，开始接数据，找数仓的同学帮忙搞特征工程features，每天要看看数据有没有产出。开始操model，接了很多业务case，写MR、python处理离散缺失这些情况。offline这块每天有result后去评估AUC、F1这些。然后又遇到瓶颈了，发现lift%已经不能再上涨了，又开始折腾feature和online learning这块，把FTRL这些东西折腾上去之后发现conversion rate提升了3~4倍，果然还是online大法好呀。那现在效果又不行了，怎么办呢？又在从人性、scene这些角度去思考，业务scene做交叉，接入更多的LBS、weather、mobile、frequency、like这些数据。折腾吧，骚年。", "answer_votes": "11", "answer_comment": "​4 条评论"}
{"answer_author": "第四范式", "answer_id": 157741810, "answer_text": "相信看到这篇文章的朋友，几乎都想成为机器学习科学家。\n\n怎么做呢？读个博士需要 5 年，以及几十到上百万元的花费。读个线下培训班，不仅教学质量参差不齐，而且价格也动辄需要好几万。\n\n事实上，绝大多数的付费课程，基本上都有完全免费的课程放在另一个地方。我们只是把这些信息整理好，告诉你在哪儿可以找到他们，以及通过什么样的顺序进行学习。\n\n这样，哪怕你是还没毕业的大学生，或者是初入职场的工程师，都可以通过自学的方式掌握机器学习科学家的基础技能，并在论文、工作甚至日常生活中快速应用。\n\n在这里我们推荐一份用户友好型的机器学习教程，你可以通过几个月的学习成为机器学习科学家，完全免费。\n\n一份用户友好型的机器学习教程\n\n当你学习机器学习课程时，有没有被信息过载所淹没？\n\n大部分的学习者都遇到了这个问题，这不是他们的错，因为绝大多数的机器学习课程都过于关注个别算法了。 \n\n没错，虽然算法很重要，但他们还是把太多时间花在了算法上。 \n\n以至于......你几乎很难在短时间内走完一遍机器学习的流程，从而感受到通过它解决具体数据问题的巨大兴奋。\n\n这些机器学习课程关注于算法是因为它容易教。相比之下，如果机器学习老师要带你走一遍机器学习的流程，那么他需要搭建计算环境，完成数据采集、清洗、拆分，特征处理，模型调参和模型预测，甚至他还需要一个面向学习者的交互界面。老师哪有这么多的工具，与其手把手带着学生走一遭，还不如学习机器学习算法。 \n\n但这样的问题是，很难有人能坚持通过自学，成为一个卓越的机器学习科学家。哪怕他是数学博士，或者技术高超的程序员，都很容易陷在细节中而难以有具体项目实现的成就感。 \n\n这份教程将会带来完全不同的思路。它非常适合自学者，即便完全没有编程的基础，也能通过恰当的工具快速实现机器学习模型，解决工作、生活中遇到的具体问题。\n\n值得注意的是，我们享用了世界顶级的机器学习资源，而不需要花费 1 分钱。 \n\n自我学习的方式 \n\n我们推荐通过 Doing Shit（不是技术术语）完成你的学习。\n\n在这之前你也许已经学习过机器学习了，但从我和朋友们的经验来看，往往会被各种神秘的符号、公式、大量的教科书和论文整的晕头转向，然后再也不想碰这恼人的玩意了。\n\n我们的方法会更加友好，它的学习过程就像小朋友学习一样，你会了解一些基础的知识（但不一定要完全弄懂），然后通过好用的工具快速实现出来就好了。而当你被建模出来的结果吸引，那时候我们才谈算法背后的数学逻辑和计算逻辑。\n\n所以我们会在学习中做很多机器学习项目，这样的好处是当你面对一个工作机会时，你就是一个经验丰富的机器学习科学家了！\n\n当然自学本身是需要自律的，这本教程将一直陪伴着你，以下是 4 个步骤。\n\n1.前提条件 （不需要完全弄懂）\n统计学、编程和数学（也可以不需要编程） \n\n2.海绵模式 \n把自己浸泡在机器学习的各种理论中 \n\n3.目标实践 \n通过机器学习包实践 9 个有意思的题目 \n\n4.机器学习项目 \n深度参与到感兴趣的项目和领域中\n\n步骤 1：前提条件 \n\n机器学习之所以看起来很吓人，是因为总伴随着那些晦涩难懂的术语。实际上，即便你是中文系毕业的，也可以学好机器学习。不过，我们需要你在一些领域有基础的理解。\n\n好消息是，一旦你满足了前提条件，其余的将会非常容易。事实上，几乎所有的机器学习都是把统计学和计算机科学的概念应用于数据领域。 \n\n任务：确保你了解基础的统计学、编程和数学 \n\n统计学：理解统计学、特别是贝叶斯概率对许多机器学习算法来说都是至关重要的。 \n免费的指南：How to Learn Statistics for Data Science, The Self-Starter Way \nhttps://elitedatascience.com/learn-statistics-for-data-science\n\n编程：懂得编程将会更灵活的应用机器学习。 \n免费的指南：How to Learn Python for Data Science, The Self-Starter Way \nhttps://elitedatascience.com/learn-python-for-data-science\n\n数学：对原始算法的研究需要线性代数、多变量计算的基础。 \n免费的指南：How to Learn Math for Data Science, The Self-Starter Way \nhttps://elitedatascience.com/learn-math-for-data-science\n\n你可以先看看这些教程，给你的机器学习道路打下知识基础。 \n\n步骤 2：海绵模式 \n\n海绵模式是尽可能吸收足够多的机器学习理论知识。 \n\n现在有些人可能会想：“如果我不打算进行原创性研究，为什么在可以使用现有机器学习包的时候，还需要学习理论？” \n\n这是一个合理的问题！ \n\n然而，如果你想把机器学习更灵活的应用于日常工作，学习一些基础理论还是很有好处的，而且你并不需要完全弄懂。下面我们会剧透学习机器学习理论的 5 个理由。\n\n（1）规划和数据采集\n数据采集真是一个昂贵和耗时的过程！那么我需要采集哪些类型的数据？根据模型的不同，我需要多少数据？这个挑战是否可行？ \n\n（2）数据假设和预处理 \n不同的算法对数据输入有不同的假设，那我应该如何预处理我的数据？我应该正则化吗？假如我的模型缺少一些数据，它还稳定吗？离群值怎么处理？ \n\n（3）解释模型结果 \n简单的认为机器学习是一个“黑盒子”的概念是错误的。是的，并不是所有的结果都直接可以解释，但你需要诊断自己的模型然后改善它们。我要怎么评估模型是过拟合还是欠拟合？我要向业务利益相关者怎么解释这些结果？以及模型还有多少的改善空间？ \n\n（4）改进和调整模型 \n你的第一次训练很少会达到最佳模式，你需要了解不同的调参和正则化方法的细微差别。如果我的模型是过拟合了，我该如何补救？我应该花更多时间在特征工程上，还是数据采集上？我可以组合我的模型吗？ \n\n（5）驱动商业价值 \n机器学习从来不会在真空中完成。如果你不了解武器库中的工具，就无法最大化发挥它们的效能。在这么多结果指标中，哪些是优化的参考指标？哪个更为重要？或者还有其他的算法会表现更好吗？ \n\n好消息是，你不需要一开始就知道所有问题的答案。所以我们推荐你从学习足够的理论开始，然后快速进入到实践。这样的话，你比较能够坚持下来，并在一段时间后真正精通机器学习。\n\n以下是一些免费的机器学习资料。\n\n2.1 机器学习视频课程 \n\n这是来自哈佛大学和耶鲁大学的世界级课程。\n\n任务：完成至少一门课程 \n\n哈佛大学数据科学课程 \n\n端到端的数据科学课程。相比吴恩达的课程，它对机器学习的重视程度较低，但是从数据收集到分析，你可以在这里学到整个数据科学的工作流程。 \n\n课程主页：http://cs109.github.io/2015/\n斯坦福大学机器学习课程 \n\n这是吴恩达的著名课程，这些视频说清楚了机器学习背后的核心理念。如果你的时间只能上一节课，我们建议这个。 \n\n课程主页：https://www.youtube.com/watch?v=qeHZOdmJvFU&list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW&index=1\n2.2 机器学习参考资料 \n\n接下来我们推荐行业中两本经典的教材。 \n\n任务：看这些 PDF 作为教科书 \n\nAn Introduction to Statistical Learning \nGentler 在书里介绍了统计学习的基本要素，适合所有机器学习的学习者。 \nPDF 地址：http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf\n\nElements of Statistical Learning \n严格的介绍了机器学习理论和数学，推荐给机器学习的研究员。 \nPDF 地址：http://statweb.stanford.edu/~tibs/ElemStatLearn/\n2.3 成功的关键 \n\n以下是每个步骤成功的关键。 \n\nA：注重大局，总是问为什么 \n\n每当你被介绍一个新概念时，问一句“为什么”。为什么在某些情况下要使用决策树而不是回归？为什么要规范参数？为什么要拆分数据集？当你了解为什么使用每个工具时，你将成为真正的机器学习从业者。 \n\nB：接受你不会记得所有学过的东西 \n\n不要疯狂的做笔记，也不要每个课程都复习 3 次。在自己的实际工作中，你会经常需要回过头查看。\n\nC：继续前进，不要气馁 \n\n尽量避免在一个话题上拖太久的时间。即便是对于机器学习教授来说，有些概念也很不好解释。但是当你在实践中开始应用时，你会很快就懂得概念的真实含义。 \n\nD：视频比教科书更有效 \n\n从我们的经验来看，教科书是很好的参考工具，但它很难坚持。我们强烈推荐视频讲座的形式。 \n\n步骤 3：有目的实践 \n\n在海绵模式之后，我们会通过刻意练习的方式磨练技能，把机器学习能力提高到一个新水平。目标包括三个方面：\n\n1.实践完整的机器学习流程：包括数据收集、清洗、预处理，建立模型，调整参数和模型评估。 \n\n2.在真实的数据集中练习，逐渐建立哪种模型适合哪种挑战的直觉。\n\n3.深入到一个具体主题中，例如在数据集中应用不同类型的聚类算法，看哪些效果最好。 \n\n在完成这些步骤后，当你开始解决大型项目时就不会不知所措了。\n\n3.1 机器学习的工具 \n\n为了快速实现机器学习模型，我们推荐使用现成的建模工具。这样的话，你会在短时间内练习整个机器学习的工作流程，而无需在任何一个步骤花费太多时间。这会给你非常有价值的“大局直觉”（Big Picture Intuition）。\n\nPython：Scikit-Learn \n\nScikit-learn 和 Sklearn 是通用机器学习中 Python 的黄金标准库，它具有常规算法的实现。 \n\nR：Caret \n\nCaret 为 R 语言中的模型包提供一个统一的界面。它还包括了预处理、数据拆分、模型评估的功能，使其成为一个完整的端到端解决方案。 \n\n3.2 实践数据集 \n\n学习了工具后，你还需要一些数据集。数据科学和机器学习的艺术，很多都在于解决问题时的几十个微观决定。我们会在不同的数据集中看到建模的结果。\n\n任务：从以下选项中选择 5 到 10 个数据集。我们建议从 UCI 的机器学习库开始，例如你可以选择 3 个数据集，分别用于回归、分类和聚类。 \n\n在进行机器学习工程的时候，想想以下问题： \n你需要为每个数据集执行哪些类型的预处理？\n你需要进行降维操作吗？你可以使用什么方法？ \n你可以如何拆分数据集？ \n你怎么知道模型是否出现“过拟合”？ \n你应该使用哪些类型的性能指标？ \n不同的参数调整会如何影响模型的结果？ \n你能够进行模型组合以得到更好的结果吗？ \n你的聚类结果和直观的相符么？ \n\nUCI 机器学习报告 \nUCI 机器学习报告采集了超过 350 个不同的数据集，专门为机器学习提供训练数据。你可以按照任务搜索（回归、分类或聚类），也可以按照行业、数据集大小搜索。 \n地址：http://archive.ics.uci.edu/ml/\nKaggle \nhttp://Kaggle.com 以举办数据科学比赛闻名，但是该网站还拥有超过 180 个社区数据集，它们包含了有趣的话题，从用户宠物小精灵到欧洲足球比赛的数据应有尽有。 \nhttps://www.kaggle.com/datasets\nhttp://Data.gov\n如果你正在寻找社会科学或者与政府有关的数据集，请查看 http://Data.gov。这是美国政府开放数据集合，你可以搜索超过 190,000 个数据集。 \nhttps://www.data.gov/\n步骤 4：机器学习项目 \n\n好了，现在到了真正有趣的部分了。到目前为止，我们已经涵盖了前提条件、基本理论和有目的实践。现在我们准备好进入更大的项目。 \n\n这一步骤的目标是将机器学习技术整合到完整的、端到端的分析中。 \n\n4.1 完成一个机器学习项目\n\n任务：完成泰坦尼克幸存者挑战。\n\n泰坦尼克号幸存者预测挑战是一个非常受欢迎的机器学习实践项目，事实上，这是 http://Kaggle.com 上最受欢迎的比赛。 \n\n我们喜欢以这个项目作为起点，因为它有很多伟大的教程。你可以从中了解到这些有经验的数据科学家们是怎么处理数据探索、特征工程和模型调参的。 \n\nPython 教程 \n我们真的非常喜欢这个教程，因为它教会你如何进行数据预处理和纠正数据。教程由 Pycon UK 提供。 \n教程地址：https://github.com/savarin/pyconuk-introtutorial\nR 教程\n在 R 中使用 Caret 包来处理几个不同的模型。本教程很好总结了端到端的预测建模过程。 \n教程地址：http://amunategui.github.io/binary-outcome-modeling/\n\n这是一个“不负责任”的快速教程：仅仅是个教程，跳过了理论讲解。不过这也很有用，而且它显示了如何进行随机森林操作。 \n教程地址：http://will-stanton.com/machine-learning-with-r-an-irresponsibly-fast-tutorial/\n4.2 从头写个算法 \n\n为了对机器学习有更深的理解，没有什么比从头写个算法有帮助了，因为魔鬼总是在细节里。\n\n我们建议从一些简单的开始，例如逻辑回归、决策树或者 KNN 算法。 \n\n这个项目也为你提供了一个将数据语言翻译成程序语言的实践。当你想把最新的学术界研究应用于工作时，这个技能将会十分方便。 \n\n而如果你卡住了，这里有一些提示： 维基百科有很多好资源，它有很多常见算法的伪代码。\n为了培养你的灵感，请尝试查看现有机器学习软件包的源代码。\n将你的算法分解，为采样、梯度下降等编写单独的功能 \n从简单开始，在尝试编写随机森林前，先执行一个决策树。\n\n4.3 选择一个有趣的项目或领域 \n\n如果你没有好奇心，你是很难学好的。但目前为止，也许你已经找到了想坚持下去的领域，那么开始建模吧！\n\n老实说这是机器学习最好的部分了。这是一个强大的工具，而一旦你开始理解，很多想法都会主动找上门。 \n\n好消息是，如果你一直在跟踪，也准备好从事这份工作，那么你的收获会远超你的想象！ \n\n我们也推荐了 6 个有趣的机器学习项目。 \n地址：https://elitedatascience.com/machine-learning-projects-for-beginners\n恭喜你到达了自学指南的终点\n\n这里有一个好消息，如果你已经遵循并完成了所有任务，那么你在应用机器学习上将会比 90% 自称是数据科学家的人更好。 \n\n而更好的消息是，你还有很多东西要学习。例如深度学习、强化学习、迁移学习、对抗生成模型等等。 \n\n成为最好的机器学习科学家的关键是永远不要停止学习。在这个充满活力、激动人心的领域，开始你的旅程吧!\n\n该教程由 EliteDataScience 提供，我们翻译了这份教程，略有改动。这是原文链接：https://elitedatascience.com/learn-machine-learning", "answer_votes": "154", "answer_comment": "​12 条评论"}
{"answer_author": "景略集智", "answer_id": 254023169, "answer_text": "<img src=\"https://pic2.zhimg.com/50/v2-ca629e3baa8a45f800c24f7a65c39e76_hd.jpg\" data-caption=\"\" data-rawwidth=\"2929\" data-rawheight=\"1072\" class=\"origin_image zh-lightbox-thumb\" width=\"2929\" data-original=\"https://pic2.zhimg.com/v2-ca629e3baa8a45f800c24f7a65c39e76_r.jpg\">下文中所出现的所有代码均可在原帖中运行，希望读者朋友们除了阅读和运行代码之外，能够自由地修改、调试甚至调戏代码，尝试不同的训练数据、模型参数下输出结果的差异。传送门：说3分钟好像太狂了，5分钟帮你开启机器学习的大门吧！ - 集智专栏<img src=\"https://pic3.zhimg.com/50/v2-fc947602803d1bdd5aa21ef1f2f17e7a_hd.jpg\" data-caption=\"\" data-rawwidth=\"1069\" data-rawheight=\"660\" class=\"origin_image zh-lightbox-thumb\" width=\"1069\" data-original=\"https://pic3.zhimg.com/v2-fc947602803d1bdd5aa21ef1f2f17e7a_r.jpg\">机器学习的时代已经来临，它能带来怎样非凡的成就，现在还不好说，但是说它将改变软件工程师解决问题的方式，却是毋庸置疑的。现在机器学习已经被不少公司广泛应用于各个领域，比如苹果的 Apple ARKit 用来创造更丰富更有层次感的用户体验，亚马逊的 Amazon Echo 用来回答复杂的用户问题，惠普将机器学习技术用于解决3D打印问题。机器学习是个非常强大的技术，编程人员应该学习如何利用机器学习去解决技术，最好不要在将来才开始，现在就行动。<img src=\"https://pic1.zhimg.com/50/v2-69e1c602f8de4f6a2063f4021f55107a_hd.jpg\" data-rawwidth=\"1000\" data-rawheight=\"288\" class=\"origin_image zh-lightbox-thumb\" width=\"1000\" data-original=\"https://pic1.zhimg.com/v2-69e1c602f8de4f6a2063f4021f55107a_r.jpg\">美剧《硅谷》里的Jing Yang也知道怎么用机器学习开发APP应用机器学习机器学习有很多运转部件。在本文，我会先通过帮你写一些代码来解释机器学习，然后再讨论开始下一步工作前可以做哪些准备工作。首先我们想想在机器学习出现之前，软件都是怎么编出来的。软件工程师会通过给电脑逐步操作的指令解决具体的问题。<img src=\"https://pic3.zhimg.com/50/v2-eaf29c29d944c97a979111af299f0544_hd.gif\" data-caption=\"\" data-rawwidth=\"325\" data-rawheight=\"195\" data-thumbnail=\"https://pic3.zhimg.com/50/v2-eaf29c29d944c97a979111af299f0544_hd.jpg\" class=\"content_image\" width=\"325\">我们举一个银行业的例子。比如说，我们想写一个程序能预测贷款人会不会还他们的借款。我们可以写一个程序分析他们的用户资料，为关键变量设置参数：信用评分（credit score）贷款数目（loan amount）贷款种类（type of loan）成为银行用户的时间（Length of membership）程序逻辑会如下所示：<img src=\"https://pic3.zhimg.com/50/v2-945c6b9737eabea23bcfe5d9a58e55e7_hd.jpg\" data-rawwidth=\"1568\" data-rawheight=\"398\" class=\"origin_image zh-lightbox-thumb\" width=\"1568\" data-original=\"https://pic3.zhimg.com/v2-945c6b9737eabea23bcfe5d9a58e55e7_r.jpg\">简明银行贷款审批程序逻辑如果问题复杂程度很高，那么手动调整参数和写指令的难度也会相应很高，甚至有时无法实现。想象一下给物体识别系统编程的难度吧。但是机器看一下范例，就能学习怎么解决这些问题。有了机器学习技术，编程人员就能训练一个机器学习模型，从数千个贷款人的数据中学习。模型还能随着时间推移不断更新，响应新趋势和更多的数据。例如，2017年国际信用界巨头艾可飞爆发安全漏洞后，那么来自艾可飞的信用评分就没有其它信用报告机构的数据那么有价值了。如果这要反映在真实的贷款结果上，机器学习模型可以调整相应的参数，减少艾可飞提供的信用评分的权重。有了足够的数据，机器学习模型会训练自己找到最优的参数。这种技术称为监督式学习，在后面的教程中会用到它。（另外两种较为通用的技术是非监督式学习和增强学习）<img src=\"https://pic4.zhimg.com/50/v2-6c9cbb7771e147d4b43c59a42d058597_hd.jpg\" data-rawwidth=\"800\" data-rawheight=\"602\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic4.zhimg.com/v2-6c9cbb7771e147d4b43c59a42d058597_r.jpg\">简明银行贷款审批机器学习逻辑搭建房价预测模型教程学习机器学习技术的最快途径就是自己尝试去搭建一个机器学习模型，那么我们就来建一个自己的房价预测模型。先假定每套房子的基值为24万美元，每多一间卧室就增加15000美元（为了方便表达数字，以下用K代表1000）。如下：<img src=\"https://pic4.zhimg.com/50/v2-6744b1c7b70f5fa0c71b52c0ca6aa6a8_hd.jpg\" data-caption=\"\" data-rawwidth=\"1072\" data-rawheight=\"297\" class=\"origin_image zh-lightbox-thumb\" width=\"1072\" data-original=\"https://pic4.zhimg.com/v2-6744b1c7b70f5fa0c71b52c0ca6aa6a8_r.jpg\">预测房价需要一个简单的线性模型：(y = mx + b)。我们可以用这个公式：<img src=\"https://pic2.zhimg.com/50/v2-2fac2de1ef338b096bbdfe299cccb50e_hd.jpg\" data-caption=\"\" data-rawwidth=\"1099\" data-rawheight=\"109\" class=\"origin_image zh-lightbox-thumb\" width=\"1099\" data-original=\"https://pic2.zhimg.com/v2-2fac2de1ef338b096bbdfe299cccb50e_r.jpg\">现在我们建一个机器学习模型去做这件事。通过使用训练数据，我想让模型找出m和b的值，这个我们知道分别是15和240。我们用 Python 编写程序。用下面的代码新建一个 Python 文件，命名为 home_price.py。在代码中，我们先导入资料和数据，设置好一些初始变量，线性模型和损失函数。如果你的环境设置不允许，可以考虑安装 Docker，使用下面的 Docker 命令：<img src=\"https://pic1.zhimg.com/50/v2-77832cd8d055260d0b0abfbb881c4c06_hd.jpg\" data-caption=\"\" data-rawwidth=\"1103\" data-rawheight=\"115\" class=\"origin_image zh-lightbox-thumb\" width=\"1103\" data-original=\"https://pic1.zhimg.com/v2-77832cd8d055260d0b0abfbb881c4c06_r.jpg\">没错，不用打印报表和注释，就是15行代码 ！1. 数据建模请点击运行按钮，导入TensorFlow并定义相应变量和模型。（可运行代码原贴：说3分钟好像太狂了，5分钟帮你开启机器学习的大门吧！ - 集智专栏）<img src=\"https://pic4.zhimg.com/50/v2-6fcc5aecd1e97252f688bbd61094d02c_hd.jpg\" data-caption=\"\" data-rawwidth=\"1056\" data-rawheight=\"980\" class=\"origin_image zh-lightbox-thumb\" width=\"1056\" data-original=\"https://pic4.zhimg.com/v2-6fcc5aecd1e97252f688bbd61094d02c_r.jpg\">2. 模型训练请点击运行按钮，启动TensorFlow的计算图。注：如刷新了页面，请先重新运行上一段代码<img src=\"https://pic3.zhimg.com/50/v2-fc947602803d1bdd5aa21ef1f2f17e7a_hd.jpg\" data-caption=\"\" data-rawwidth=\"1069\" data-rawheight=\"660\" class=\"origin_image zh-lightbox-thumb\" width=\"1069\" data-original=\"https://pic3.zhimg.com/v2-fc947602803d1bdd5aa21ef1f2f17e7a_r.jpg\">希望读者朋友们除了阅读和运行代码之外，能够自由地修改、调试甚至调戏代码，尝试不同的训练数据、模型参数下输出结果的差异。在代码中，我们设置了一些基本的在训练中会用到的占位符和变量。然后我们写一个损失函数，通过减去预测值中的y （给定值或者真实数值）进行计算。接着把得到的数值传给优化程序。每迭代一次，优化程序就会通过更新变量m和b的值尽可能地得到y的值和预测值。接下来，我们就用训练数据把模型训练上1000次。最后，你应该会得到这样一个输出：<img src=\"https://pic1.zhimg.com/50/v2-df792567a73a9c5e307cccd2b4061380_hd.jpg\" data-caption=\"\" data-rawwidth=\"1084\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb\" width=\"1084\" data-original=\"https://pic1.zhimg.com/v2-df792567a73a9c5e307cccd2b4061380_r.jpg\">m的值为[ 15.00007153]，b的值为[239.99978638]。你觉得得到的m和b的值怎么样？和我们预测的值很接近对吧？<img src=\"https://pic1.zhimg.com/50/v2-40f59ec05eb521d98b946c819520924e_hd.jpg\" data-caption=\"\" data-rawwidth=\"600\" data-rawheight=\"391\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic1.zhimg.com/v2-40f59ec05eb521d98b946c819520924e_r.jpg\">下面是每次迭代中模型如何被优化的直观图。最初m和b的值从1.0开始（我们在代码中指定了），但是随着时间推移，它们会慢慢接近正确的值。我们也可以看到损失值（预测— y）慢慢降低至0。<img src=\"https://pic1.zhimg.com/50/v2-e1d65f34b3387a6f7da0cfabb2e926e5_hd.jpg\" data-rawwidth=\"800\" data-rawheight=\"552\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic1.zhimg.com/v2-e1d65f34b3387a6f7da0cfabb2e926e5_r.jpg\">迭代100次后m，b的值和损失值（loss）希望上面的教程能帮你理解机器学习的基础知识。不远的将来，每个编程人员都会在实际工作中用到机器学习技术，我们离npm install object-detect并不遥远。<img src=\"https://pic2.zhimg.com/50/v2-d8aa19acea3b5a8cdbb6468f5e6e0b0f_hd.gif\" data-rawwidth=\"498\" data-rawheight=\"203\" data-thumbnail=\"https://pic2.zhimg.com/50/v2-d8aa19acea3b5a8cdbb6468f5e6e0b0f_hd.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"498\" data-original=\"https://pic2.zhimg.com/v2-d8aa19acea3b5a8cdbb6468f5e6e0b0f_r.gif\">祝你身体健康！资料来源：Getting started with Machine Learning in 5 minutes 作者：Arjun Patel  翻译：小马哥拓展阅读：世上最大的不可描述网站也向AI和机器学习势力低头了！以彼之道，还施彼身——使用机器学习来揪出作弊的玩家不是人工智能，是智能机器官方微博：@景略集智微信公众号：jizhi-im商务合作： @军师投稿转载：kexiyang@jizhi.im集智QQ群：557373801<img src=\"https://pic3.zhimg.com/50/v2-ef1332d6a6bbde0fef67ea51c94cafa7_hd.jpg\" data-caption=\"\" data-rawwidth=\"1024\" data-rawheight=\"831\" class=\"origin_image zh-lightbox-thumb\" width=\"1024\" data-original=\"https://pic3.zhimg.com/v2-ef1332d6a6bbde0fef67ea51c94cafa7_r.jpg\">", "answer_votes": "97", "answer_comment": "​5 条评论"}
{"answer_author": "知乎用户", "answer_id": 152908179, "answer_text": "题主如果是中国人，我建议，从周志华《机器学习》开始，其他的书，不是不好。周志华额书出版之前，我看过很多资料《introduction to data mining》,《machine learning》等，但感觉都没有周的书好，仔细想来，个人觉得，周的书是按照中国人的思维写的。所以，我建议从周的书开始看。看周的书的时候，边看边补数学的基础知识，比如概率论，数理统计，信息论，线性代数。", "answer_votes": "6", "answer_comment": "​1 条评论"}
{"answer_author": "知乎用户", "answer_id": 38360049, "answer_text": "如果是刚开始入门，我觉得最功利的方法大概是get hands dirty。因为机器学习是很多学科的交叉，不仅涉及统计学，数学，各种算法等理论，这些理论方面的很难几个月内搞的很清楚，如果过分关注这些（是应该关注）的话，会很容易把握不准方向。关于用什么语言，这应该是个人习惯的问题，目前用的多的是R, Matlab，Python， 还有JAVA, C++等。在没有特殊需要的时候，会一个就差不多了，毕竟这些是工具。综上，我目前觉得最好的入门方法是用Weka开始处理一些数据。（What is the Weka Machine Learning Workbench）。并结合这本书：Data Mining: Practical Machine Learning Tools and Techniques, Third Edition，I. Witten你可以选择不编程，直接调用weka各种程序，先感觉下machine learning。随着自己project需要，在深入地了解各种理论，并自己写代码。另外，软件可以看各种视频tutorial，例如Weka的：Rushdi Shams，这样子效率更高。想到了再补充。", "answer_votes": "5", "answer_comment": "​2 条评论"}
{"answer_author": "谢辛", "answer_id": 156451101, "answer_text": "这个问题已经好久没有更新了，作为机器学习入门小白来更新点关于计算机，数学，机器学习相关的mooc，不局限于coursera。由于我是英语渣，所以暂时看的全是有中文字幕的。所以英语不行的也可以放心往下阅读。以后慢慢补英语。。。。。。。首先是数学线性代数麻省理工大学的线性代数   麻省理工公开课：线性代数_全35集_网易公开课配合上线性代数及其应用 (豆瓣)，好用到爆。这本书颠覆了我对线性变换的认识，各种变换原来都有几何意义，这本书还介绍了奇异值的用法，对机器学习很有用。关键是这本书全书没有太多证明，全是图，入门很棒。线性代数应该这样学 (豆瓣),这本书观点很独特，看着很high。数学分析高等微積分 - 臺大開放式課程 (NTU OpenCourseWare)。台湾大学的课程超级赞，一看就停不下来。这门数学分析教程比较入门，很容易看懂，关键是老先生讲得很有趣。视频清晰度也超赞。<img src=\"https://pic1.zhimg.com/50/v2-0d938cf0394d36f4fa458c8c6f8e6e7c_hd.jpg\" data-rawwidth=\"414\" data-rawheight=\"223\" class=\"content_image\" width=\"414\">看看这个课程目录，颇有武侠意味。2.配合着数学分析原理 (豆瓣)，很爽。3.还要加深的话，可以看看陶哲轩实分析 (豆瓣)概率论与数理统计概率论与数理统计 (豆瓣)，听说这个不错，准备看一看coursera上台湾大学的概率课程又开课了，以前没看的赶紧去看看。这个适合入门，老师很幽默，作业题很不错。机器学习与深度学习coursera吴恩达的机器学习就不提了，必看的。台湾大学林轩田的，cs231也不说了，同理。前几天逛了逛coursera，又在coursera发现一门台湾大学的mooc，人工智慧，看了第一章后，发现原来人工智能不只包含机器学习，深度学习.....还有好多种，这个mooc介绍了各种搜索树，很不错，准备继续刷。他的配套教材人工智能 (豆瓣)我觉得最适合入门的课程应该是udacity上的课程，因为比较简单，教你使用sklearn,tensorflow库。google的工程师也在，很不错.机器学习入门（中/英）.深度学习（中/英）.统计学习方法 (豆瓣),机器学习 (豆瓣)当教材不错。算法首推coursera上普林斯顿的算法课，全部java实现。我的java语法知识都是在这课程学的。配合着算法 (豆瓣).  应该能入门。这mooc的作业真的非常有意思，非常棒，非常棒，非常棒！國立交通大學開放式課程(OpenCourseWare, OCW),国立交通大学的算法课讲的也很好，适合深入，但是又比算法导论浅显。教材是算法设计 (豆瓣)。cuda课程现在的神经网络都在GPU上跑，学学英伟达的框架还是很有用的。并行编程入门 等我发现新的好课程继续更。", "answer_votes": "4", "answer_comment": "​3 条评论"}
{"answer_author": "地球的外星人君", "answer_id": 214760348, "answer_text": "分享一下资源，27个机器学习的资源，正好今天专栏发了。今天分享一篇机器学习的文章。翻了一半，发现Linux中国已经翻译过了。。。干脆搬过来，还有一个姊妹篇《My Curated List of AI and Machine Learning Resources from Around the Web》，明天准备发这个。原文地址是：Cheat Sheet of Machine Learning and Python (and Math) Cheat Sheets译文地址是：值得收藏的 27 个机器学习的小抄机器学习Machine Learning有很多方面，当我开始研究学习它时，我发现了各种各样的“小抄”，它们简明地列出了给定主题的关键知识点。最终，我汇集了超过 20 篇的机器学习相关的小抄，其中一些我经常会翻阅，而另一些我也获益匪浅。这篇文章里面包含了我在网上找到的 27 个小抄，如果你发现我有所遗漏的话，请告诉我。机器学习领域的变化是日新月异的，我想这些可能很快就会过时，但是至少在 2017 年 6 月 1 日时，它们还是很潮的。如果你想要这些图表，你无需向我一样一张张下载，只需要从这里点击下载就可以了。如果你喜欢这篇文章，那就分享给更多人，如果你想感谢我，就到原帖地址点个赞吧。机器学习这里有一些有用的流程图和机器学习算法表，我只包括了我所发现的最全面的几个。神经网络架构来源： http://www.asimovinstitute.org/neural-network-zoo/<img src=\"https://pic4.zhimg.com/50/v2-d6a26b41e5f4b980e57ae61434dbfc1e_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"2400\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic4.zhimg.com/v2-d6a26b41e5f4b980e57ae61434dbfc1e_r.jpg\">微软 Azure 算法流程图来源： https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-algorithm-cheat-sheet用于微软 Azure 机器学习工作室的机器学习算法：<img src=\"https://pic3.zhimg.com/50/v2-91f3525fb999dab8372b9d720d569697_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1035\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic3.zhimg.com/v2-91f3525fb999dab8372b9d720d569697_r.jpg\">SAS 算法流程图来源： http://blogs.sas.com/content/subconsciousmusings/2017/04/12/machine-learning-algorithm-use/SAS：我应该使用哪个机器学习算法？：<img src=\"https://pic1.zhimg.com/50/v2-a294c10effecc494735850ccb8c8ba16_hd.jpg\" data-rawwidth=\"1152\" data-rawheight=\"648\" class=\"origin_image zh-lightbox-thumb\" width=\"1152\" data-original=\"https://pic1.zhimg.com/v2-a294c10effecc494735850ccb8c8ba16_r.jpg\">算法总结来源： http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/机器学习算法指引：<img src=\"https://pic2.zhimg.com/50/v2-d93eec3173586733121b778eec57dd67_hd.jpg\" data-rawwidth=\"1166\" data-rawheight=\"745\" class=\"origin_image zh-lightbox-thumb\" width=\"1166\" data-original=\"https://pic2.zhimg.com/v2-d93eec3173586733121b778eec57dd67_r.jpg\">来源： http://thinkbigdata.in/best-known-machine-learning-algorithms-infographic/已知的机器学习算法哪个最好？：<img src=\"https://pic3.zhimg.com/50/v2-9bedfc4dd0e15468e4350b8d86ab0d0f_hd.jpg\" data-rawwidth=\"564\" data-rawheight=\"1002\" class=\"origin_image zh-lightbox-thumb\" width=\"564\" data-original=\"https://pic3.zhimg.com/v2-9bedfc4dd0e15468e4350b8d86ab0d0f_r.jpg\">算法优劣来源： https://blog.dataiku.com/machine-learning-explained-algorithms-are-your-friend<img src=\"https://pic1.zhimg.com/50/v2-b9cd1b919991f94e6e4fee018d64f406_hd.jpg\" data-rawwidth=\"1240\" data-rawheight=\"1753\" class=\"origin_image zh-lightbox-thumb\" width=\"1240\" data-original=\"https://pic1.zhimg.com/v2-b9cd1b919991f94e6e4fee018d64f406_r.jpg\">Python自然而然，也有许多在线资源是针对 Python 的，这一节中，我仅包括了我所见过的最好的那些小抄。算法来源： https://www.analyticsvidhya.com/blog/2015/09/full-cheatsheet-machine-learning-algorithms/<img src=\"https://pic4.zhimg.com/50/v2-3cf81de0802fdf1e25126a1995e6f85e_hd.jpg\" data-rawwidth=\"1118\" data-rawheight=\"1432\" class=\"origin_image zh-lightbox-thumb\" width=\"1118\" data-original=\"https://pic4.zhimg.com/v2-3cf81de0802fdf1e25126a1995e6f85e_r.jpg\">Python 基础来源： http://datasciencefree.com/python.pdf<img src=\"https://pic4.zhimg.com/50/v2-3c27dca38318cc6f9b35f629c4d0cdf5_hd.jpg\" data-rawwidth=\"1100\" data-rawheight=\"850\" class=\"origin_image zh-lightbox-thumb\" width=\"1100\" data-original=\"https://pic4.zhimg.com/v2-3c27dca38318cc6f9b35f629c4d0cdf5_r.jpg\">来源： https://www.datacamp.com/community/tutorials/python-data-science-cheat-sheet-basics#gs.0x1rxEA<img src=\"https://pic4.zhimg.com/50/v2-b31d8c3df7f530cf8db646e87a499b94_hd.jpg\" data-rawwidth=\"800\" data-rawheight=\"566\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic4.zhimg.com/v2-b31d8c3df7f530cf8db646e87a499b94_r.jpg\">Numpy来源： https://www.dataquest.io/blog/numpy-cheat-sheet/<img src=\"https://pic2.zhimg.com/50/v2-442881e01990abe0206e588b6a6ebcfc_hd.jpg\" data-rawwidth=\"850\" data-rawheight=\"1100\" class=\"origin_image zh-lightbox-thumb\" width=\"850\" data-original=\"https://pic2.zhimg.com/v2-442881e01990abe0206e588b6a6ebcfc_r.jpg\">来源： http://datasciencefree.com/numpy.pdf<img src=\"https://pic2.zhimg.com/50/v2-fb577f69085892d1eff6833565f6bac0_hd.jpg\" data-rawwidth=\"1100\" data-rawheight=\"850\" class=\"origin_image zh-lightbox-thumb\" width=\"1100\" data-original=\"https://pic2.zhimg.com/v2-fb577f69085892d1eff6833565f6bac0_r.jpg\">来源： https://www.datacamp.com/community/blog/python-numpy-cheat-sheet#gs.Nw3V6CE<img src=\"https://pic3.zhimg.com/50/v2-47001e7331173217be7a6fe454b4d983_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1131\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic3.zhimg.com/v2-47001e7331173217be7a6fe454b4d983_r.jpg\">来源： https://github.com/donnemartin/data-science-ipython-notebooks/blob/master/numpy/numpy.ipynb<img src=\"https://pic1.zhimg.com/50/v2-03573b92f37b0d32b44194d2eca2f4bc_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1016\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic1.zhimg.com/v2-03573b92f37b0d32b44194d2eca2f4bc_r.jpg\">Pandas来源： http://datasciencefree.com/pandas.pdf<img src=\"https://pic1.zhimg.com/50/v2-25d1f359bf7c8aa1e4d662776fd57a9a_hd.jpg\" data-rawwidth=\"1100\" data-rawheight=\"850\" class=\"origin_image zh-lightbox-thumb\" width=\"1100\" data-original=\"https://pic1.zhimg.com/v2-25d1f359bf7c8aa1e4d662776fd57a9a_r.jpg\">来源： https://www.datacamp.com/community/blog/python-pandas-cheat-sheet#gs.S4P4T=U<img src=\"https://pic1.zhimg.com/50/v2-c92d7fd090979610ba3d457e886412b6_hd.jpg\" data-rawwidth=\"602\" data-rawheight=\"427\" class=\"origin_image zh-lightbox-thumb\" width=\"602\" data-original=\"https://pic1.zhimg.com/v2-c92d7fd090979610ba3d457e886412b6_r.jpg\">来源： https://github.com/donnemartin/data-science-ipython-notebooks/blob/master/pandas/pandas.ipynb<img src=\"https://pic4.zhimg.com/50/v2-1620b69eab74a809633a2b5b852776be_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1135\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic4.zhimg.com/v2-1620b69eab74a809633a2b5b852776be_r.jpg\">Matplotlib来源： https://www.datacamp.com/community/blog/python-matplotlib-cheat-sheet<img src=\"https://pic3.zhimg.com/50/v2-d5300d81fa97694c7a6bb5c09b7ec967_hd.jpg\" data-rawwidth=\"1169\" data-rawheight=\"826\" class=\"origin_image zh-lightbox-thumb\" width=\"1169\" data-original=\"https://pic3.zhimg.com/v2-d5300d81fa97694c7a6bb5c09b7ec967_r.jpg\">来源： https://github.com/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib.ipynb<img src=\"https://pic4.zhimg.com/50/v2-a64e7b8fbc51852c9dc74f78da609bfb_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1104\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic4.zhimg.com/v2-a64e7b8fbc51852c9dc74f78da609bfb_r.jpg\">Scikit Learn来源： https://www.datacamp.com/community/blog/scikit-learn-cheat-sheet#gs.fZ2A1Jk<img src=\"https://pic2.zhimg.com/50/v2-1605daa296f58f7cb85c6de45365edcc_hd.jpg\" data-rawwidth=\"1169\" data-rawheight=\"826\" class=\"origin_image zh-lightbox-thumb\" width=\"1169\" data-original=\"https://pic2.zhimg.com/v2-1605daa296f58f7cb85c6de45365edcc_r.jpg\">来源： http://peekaboo-vision.blogspot.de/2013/01/machine-learning-cheat-sheet-for-scikit.html<img src=\"https://pic3.zhimg.com/50/v2-9af0a879f6c40bc37f0c7fd067d81508_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"888\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic3.zhimg.com/v2-9af0a879f6c40bc37f0c7fd067d81508_r.jpg\">来源： https://github.com/rcompton/ml_cheat_sheet/blob/master/supervised_learning.ipynb<img src=\"https://pic3.zhimg.com/50/v2-67113df7f92d6ac802413182c7321431_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1146\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic3.zhimg.com/v2-67113df7f92d6ac802413182c7321431_r.jpg\">Tensorflow来源： https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/1_Introduction/basic_operations.ipynb<img src=\"https://pic2.zhimg.com/50/v2-99651f5d22432fc0c24dbc7d975725db_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1048\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic2.zhimg.com/v2-99651f5d22432fc0c24dbc7d975725db_r.jpg\">Pytorch来源： https://github.com/bfortuner/pytorch-cheatsheet<img src=\"https://pic1.zhimg.com/50/v2-7f800d2962489dbe22776a3247f60c8e_hd.jpg\" data-rawwidth=\"1278\" data-rawheight=\"1334\" class=\"origin_image zh-lightbox-thumb\" width=\"1278\" data-original=\"https://pic1.zhimg.com/v2-7f800d2962489dbe22776a3247f60c8e_r.jpg\">数学如果你希望了解机器学习，那你就需要彻底地理解统计学（特别是概率）、线性代数和一些微积分。我在本科时辅修了数学，但是我确实需要复习一下了。这些小抄提供了机器学习算法背后你所需要了解的大部分数学知识。概率来源： http://www.wzchen.com/s/probability_cheatsheet.pdf<img src=\"https://pic2.zhimg.com/50/v2-1e71165845dcfcdc9e57679207e7a7b9_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1075\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic2.zhimg.com/v2-1e71165845dcfcdc9e57679207e7a7b9_r.jpg\">线性代数来源： https://minireference.com/static/tutorials/linear_algebra_in_4_pages.pdf<img src=\"https://pic3.zhimg.com/50/v2-a020bee96349e9ae9a95b43500184a7c_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1158\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic3.zhimg.com/v2-a020bee96349e9ae9a95b43500184a7c_r.jpg\">统计学来源： http://web.mit.edu/~csvoss/Public/usabo/stats_handout.pdf<img src=\"https://pic2.zhimg.com/50/v2-53962a0c3f20cedbfbe08b281866dc26_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"1015\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic2.zhimg.com/v2-53962a0c3f20cedbfbe08b281866dc26_r.jpg\">微积分来源： http://tutorial.math.lamar.edu/getfile.aspx?file=B,41,N<img src=\"https://pic3.zhimg.com/50/v2-aa96d21cda418b31ad085723b440608c_hd.jpg\" data-rawwidth=\"1600\" data-rawheight=\"935\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic3.zhimg.com/v2-aa96d21cda418b31ad085723b440608c_r.jpg\">", "answer_votes": "104", "answer_comment": "​3 条评论"}
{"answer_author": "dontbeatmycat", "answer_id": 39833491, "answer_text": "台大林轩田的《机器学习基石》和《机器学习技法》公开课，很适合入门，采用频率学派观点，作业的理论题有一定难度。", "answer_votes": "9", "answer_comment": "​1 条评论"}
