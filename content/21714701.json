{"question_id": "21714701", "question_text": "机器学习，数据挖掘在研究生阶段大概要学些什么？能给一个梗概或者方向么？ 最好可以列出主要的课程或者相关资源，谢谢", "question_title": "机器学习，数据挖掘在研究生阶段大概要学些什么？", "question_commet": "​3 条评论", "answer_number": "33 个回答", "question_followers": "6,660", "brower_number": "402,319"}
{"answer_author": "知乎用户", "answer_id": 49112656, "answer_text": "三个字：勤动手~~其实机器学习和数据挖掘是两个相差的比较多的领域，机器学习比较偏向数学问题的推导， 所以在顶会上的很多paper更看重idea，不是很看重实验是否来源于真实数据（有一些实验数据会自己构造，比如Andrew Ng的谱聚类自己构造了一个图，图里面的点组成了四个英文字母NIPS，他证明他的谱聚类比之前的聚类方法好）     来让我们感受一下这个飘逸的图&lt;img src=\"https://pic4.zhimg.com/50/b8c137ce1fe9c8febb51946af7e561b7_hd.jpg\" data-rawwidth=\"210\" data-rawheight=\"242\" class=\"content_image\" width=\"210\"&gt;而数据挖掘说土点就是老子就是会抽feature~的领域，比如Kaggle上的入门题Titanic，我们都知道善良的美帝人民喜爱拯救小孩子（快！让小孩先走），所以年龄对于生还人员预测很重要，可是有些人的Age缺失了在给定的数据中。咱们这种土人只会给缺失的人扔个年龄平均数，然而那些有洞察力的人，认为他的姓名中暗示了年龄，Mrs与Miss，Mr与Master分别对应了年龄的某个区间，然后他们刁刁的可以用逻辑斯蒂回归模型就拿到很好的分数。对于找工作解决实际问题而言~数据（代表着分布式系统领域）>特征（数据挖掘与自然语言处理与图像）>模型（机器学习）。这并不是说模型不重要，而是一定要对具体问题做模型的Adaptation，你直接把图像领域的CNN拍到自然领域处理领域可能效果还不如一些传统方法，然而你把模型改吧改吧改成了DCNN，你就超越了Baseline，所以一定要能看懂模型，然后结合你的具体问题，把问题给解决了！所以，对于你的问题，大家推荐了那么多理论学习资料，我觉得肯定够了，我的忠告是不要沉迷于数学公式的推导，一定要理解他是如何运用数据的，比如SVM他的分类决策是根据和分类面最接近的那些点的支持向量决定的，贝叶斯的分类决策是根据大量先验知识决定的。所以在解决实际问题时候，贝叶斯会特别特别对先验和后验的同分布特别敏感，而SVM的鲁棒性会好很多。千万不要最后只知道SVM利用了拉格朗日乘子，对偶问题，极小极大与极大极小的转换做的分类器，而忽略了他怎么利用数据的特征~最后想说的是：学好Python，掌握好开源的Tool。在工作解决实际问题的过程中，往往是这个逻辑：这个问题我们需要这个数据我们去crawl吧！！！（爬虫能力）-> 这些数据应该抽取ABCD这些特征（对数据的感觉）->这种数据特征的拟合用这个模型好！！！我记得这个开源Tool实现了（对开源机器学习模型的了解）-> 还是不work，我们写Rule吧（有多少人工就有多少智能的步骤）。当然最后一步十分重要，尤其对于自然语言处理问题（摊手脸）", "answer_votes": "321", "answer_comment": "​20 条评论"}
{"answer_author": "知乎用户", "answer_id": 49084558, "answer_text": "这是一个很难回答的问题，每个人的基础不同起点也不同，需要学的东西也完全不一样。先说我的观点：不要想一下子吃成一个胖子；很多时候，想吃的越多反而什么也消化不了。让我们先看一道面试题（非原创）：一条路上有N棵树，每棵树都有两个指标，一个是位置a_i（是整数），一个是体积w_i（是整数），现在要把这些树砍下来，运到K个仓库，我该如何选择这些仓库的位置（也是整数），使得搬运的成本尽量小呢？假设理想情况下，每棵树的搬运成本为树的体积 x 搬运的位移^2。如果你看完这个题目，不能条件反射的告诉我你的思路，你其实并没有真正懂什么是聚类算法（K-means）。每个机器学习算法，犹如这道题一样具有两面性，一面是算法，也就是怎么算；一面是优化目标，为什么这么算。不能区分的看待机器学习的两面性，就不能明白为什么一群号称做机器学习研究的人整天却在玩数学。先挖个坑，以下是《理论篇》，《实践篇》以后在写了 = =我自己是本科数学出身，本科毕业的时候，我并不知道什么是机器学习，也没有写过大型程序，更不要说去搞一个机器学习的算法和实践了。但是回头看，真是因为本科时代打下的坚实数学基础，让我毕业后学习这些相关知识变得轻车熟路。这些本科时代就应该熟练掌握的东西包括线性代数（线性空间，矩阵计算，张量）数值数学（数值代数，数值分析，线性规划，二次规划，凸优化理论，常见的数值优化算法）\n概率论和统计（没有这个基础，后面学概率图模型，统计计算都无从谈起）实分析和泛函的基础（这块内容有助于提升抽线思维的能力，一些经典结论对之后一些理论的理解很有帮助，比如RKHS）有了这个基础，我们再来看机器学习都有哪些东西，其实真心不多，看我用一个知乎回答就告诉你，最简单的当然是从分类器（classification）谈起了。总结一下，学习这些东西要先知道哪些数学内容呢？Naive Bayes：真的只需要懂一点概率论就行了。Linear Discriminant Analysis：这个你只需要知道什么是多变量Gaussian分布。Logistic Regression：如果知道线性回归和广义线性回归，LR也不是什么特别的东西。如果知道最大熵原理，并能从它推导出LR那说明你对LR的理解又更深入了。Linear SVM：这个稍微复杂一点，因为问题的formulation需要先理解max-margin原理。而具体的算法实际上就只是经典的二次规划和凸优化内容。Kernel SVM：要真正理解这个或许需要先明白什么是RKHS。然后其他算法部分只是仿照Linear SVM的简单推广。RKHS相关内容可以参照http://www.umiacs.umd.edu/~hal/docs/daume04rkhs.pdfAdaboost：这个东西如果只需要知道算法过程，是很简单的东西。但是如果你能明白为什么这么做，在什么假设下这么做会收敛到最优解，那你的理解也非常不错了。Decision Tree：有两个需要了解CART 和 c4.5。这个很简单，没什么好说的，但是你能不能高效的实现它们呢？Neural network：这个是我见过最傻的模型，你要知道怎么做优化，乃至怎么做随机优化，结果看天吃饭。再来看一些非监督模型，比如经典的有数据处理与可视化：PCA，LDA，MDS，以及其他“高大上”但不一定work的manifold learning算法聚类算法，以及如何评价聚类结果稀疏编码：如何把一个带LASSO的问题转化成线性约束？有哪些别的更快的方法求解LASSO。以上这些东西，算是入门性质的。本科毕业后大概一年左右，这些东西我就基本熟悉了。要学习这些东西，看一些教材自然是好的，但是书里废话比较多呢，而且一本书的作者知道的东西毕竟有限，我都是倾向直接从维基出发找资料看的。说实话，现在很少会自己去实现这些算法了，这些经典算法都有现成的开源工具。事实上要写一个高效的Linear SVM也不是很容易的事情。我主要讲讲学完这些，应该怎么学更高级的内容，当然还是结合我自己的经历。授人以鱼不如授人以渔，要学习前沿的内容就要掌握基础的工具。书分为两种，一种书看完了就是看完了，你学到了一堆技能，但却不能用这些技能产生新的知识，面对问题也不能因地制宜，如果是这样学估计只能用来应付找工作面试吧；另一种书看完了才是学习新东西的开始，你学到了如何读懂别人的论文，如何开发新的知识，如何根据情况选择和调整算法。实战分类模型（Advanced classification）：在掌握了Decision Tree和Adaboost后可以进阶了解Random Forest 和 Gradient Boosting两个模型，和他们的调参策略。推荐参加一些机器学习的比赛来强化这方面的使用熟练度。概率图模型（Probabilistic graphical model）：我是在Coursera上学习概率图模型这门课的，讲得真的非常好，正打算过二周目。学完这个课，掌握了图模型的设计，推断，和采样方法之后，就可以开始学习两个核心的机器学习模型，一个是Latent Dirichlet Allocation（LDA），常用于文本处理；一个是Probabilistic Matrix Factorization（PMF），常用于推荐系统。这类图模型都在研究两个基本的问题：如何采样；如何inference隐含变量，是用EM、MCMC、还是Variational Bayes，从而用来估算参数。为了搞清楚这些，学习下面这门课就非常必要了。统计计算（Statistical computing）：这个课系统的介绍了数值积分方法，Monte Carlo方法（importance sampling, MCMC，Sequential/Particle  MCMC，bootstrap），EM/MM。学完这门课，你能对这个领域的工具有个全局性的了解，明白每个工具的利弊，它们产生的历史来源，从而在具体问题中正确的选择使用它们。有了这些工具，你会发现大部分research的工作都是在这些细分领域做一些简单的扩展。比如Bayesian PMF（ICML'08）这篇文章几乎就完全是MCMC在PMF的应用。话说回来，Research大部分时候就是以这样一种循序渐进的方式进行的，把一些现成的idea排列组合。深度学习（Deep learning）：说实话我刚开始接触这块内容发现，这尼玛就是传说中的黑科技啊。你不知道模型里面发生了什么，好坏都是看天吃饭的感觉。为了搞清楚这个，我决定重头开始实现神经网络。（代码在bobye/neuron · GitHub ）前前后后花了近半年的时间，在实现的过程中，我学习了构造和训练神经网络的各个细节。我是从Stanford这个Tutorial开始学习的UFLDL Tutorial 课程资料里提供了Matlab的源码，不过我喜欢重新造轮子，那个时候恰好在学习Scala，就用Scala重写了一个神经网络的库（这个语言的特性非常适合写神经网络的算法）。\n近几年深度学习的主流被深度卷积网络代替，这种监督学习的算法虽然对某些问题十分有效，但是数学上并不是特别神奇的东西，我还是比较关注那些非监督的神经网络。优化（optimization）：没有优化算法，任何机器学习模型都是空中楼阁，如何用更高效的优化算法，如何trade-off 计算时间和准确度，如何把已有问题scale到更高规模的数据上一直都是“优化大师们”做不完的工作。这也是一个非常大的分支，我觉得现在比较流行的两个大类是随机梯度优化和ADMM。前者用来解决大规模非约束优化问题，现实情景用的很多，但我们对它知道的很少；后者用来解决带约束问题，有很多变体。此外，优化大家庭也又有很多别的成员，这时候我要推荐的资料包括J Nocedal的numerical optimization这本书，讲的内容非常充实。此外ADMM的内容当然看Boyd巨牛11年的Tutorial paper。话说“概率图模型画圈，神经网络调参数，优化问题加正则”，不会科研也会胡诌了。。。最后说说答主最近在看的东西PAC学习理论（PAC Learning）：这个理论已经相对古老了，它的历史价值很大，应用价值很有争议，但是一直有人在继续这个方向的工作，并试图用它来构造新的模型，所以还是有必要知道的。推荐一下最近的新书：Understanding Machine Learning： From Theory To Algorithms.非参数贝叶斯统计（Non-parametric Bayesian statistics）：这个方向还非常年轻，有很多需要挖掘的东西，（划去）也是我PhD的一个重要课题（划去）。我觉得如果你开始看这些东西了，我已经没资格给你指路了，哈哈", "answer_votes": "1.4K", "answer_comment": "​97 条评论"}
{"answer_author": "TonyOuyang", "answer_id": 20193411, "answer_text": "有一次我听了Eric Xing的一个报告，讲machine learning综述和展望的，非常引人入胜，事后我邮件他要slides，他说\"sure\" & 等他回去以后给我，然后...就没有然后了...--------------------- 正经回答分割线 ---------------------------machine learning综述的话，推荐这篇：A Few Useful Things to Know about Machine Learning中文版在这里：机器学习那些事还有好心人做了图片版：&lt;img src=\"https://pic1.zhimg.com/50/b7b42f946c501c6b48ad7710b2363357_hd.jpg\" class=\"content_image\"&gt;数据挖掘方面，有好心人写了一篇：大数据工程人员知识图谱ps 楼上说到的Andrew Ng在Coursera上的课，我觉得最好的一点是讲了怎么去科学地\"debugging a learning algorithm\"，以及要设计一个machine learning system的时候，你该怎么判断哪些事情需要花时间哪些事情暂时还不重要（而不是没头苍蝇到处乱来）X. Advice for Applying Machine Learning (Week 6)XI. Machine Learning System Design (Week 6)这是太多的其他课程／教学资料里没有讲或者一笔带过的东西，但却是最基本需要掌握的地方，I wish I knew ....=========看到评论有求图的，见@祝铭嘉 的回答", "answer_votes": "274", "answer_comment": "​11 条评论"}
{"answer_author": "陈然", "answer_id": 24217696, "answer_text": "The Open Source Data Science Masters by datasciencemasters看到一个不错的网站，是一个Stanford的CS学生维护的，上面列出了这个方向相关的课程和相应的资源，我觉得很不错。", "answer_votes": "118", "answer_comment": "​添加评论"}
{"answer_author": "Frank Chu", "answer_id": 128695306, "answer_text": "机器学习是一门集计算机、统计和优化于一体的学科，也是数据挖掘、自然语言处理和计算机视觉等学科的基础。机器学习同时也是算法工程师 (数据挖掘、自然语言处理、图像等) 面试必问的题目。因此在研究生阶段学好机器学习，既可以打好基础，又可以为将来找工作做好准备。首先，学好机器学习需要一定的优化和统计基础，你可以参考以下这几本书：线性代数 ： 这个是最低的要求了，理工科本科的时候应该都学过。矩阵分析 ：研究生的矩阵分析课一般就用这本书。Optimization by Stephen Boyd  ：由凸优化大神Stephen Boyd所写，绝对经典。你也可以参考Stanford CS229课上的notes：Linear AlgebraReview of Probability TheoryOptimization Overview1Optimization Overview2  然后，你可以开始学习机器学习的内容，我觉得你可以分为以下几个部分来看：Introduction :  了解下 What‘s machine learning and why machine learning.Statics and Optimization in Machine Learning : 机器学习中常用到的统计和优化方法：SVD分解，矩阵求导，优化和 Dirichlet prior等。Model Selection and Evaluation ： 如何划分数据集，如何evaluate模型的好坏。Linear Models for Regression ： 线性回归，Gradient Descent， Newton Method， BFGS，L-BFGS, Ridge Regression and Lasso.Linear Models for Classification :  Logistic Regression, Softmax Regression.Exercises : you need an exercise here to exam what you have learned:  坐标下降法 (Coordinate Descent), 迭代软阈值算法(IST),  Stochastic Gradient Descent.Support Vector Machines : SVM,  Dual Problem of SVM,  Kernel Function, Soft-margin SVM.Clustering :  K-means, Mixtures of Gaussians, Expectation Maximization (EM), Spectral Clustering, Normalized Cut, Hierarchical Clustering (层次聚类),  Density-based Clustering, Learning Vector Quantization (LVQ).Ensemble Learning : Boosting, Bagging, Random Forest, KNN, Decision Tree.Reinforcement LearningProbabilistic Graphical Model: Bayesian Network, Markov Network, CRF, HMM, LDAPrinciple Component Analysis (PCA)Machine Learning Theory: VC Dimension, Learning Principles.Neural Network and Deep Learning: AutoEncoder, CNN, RNN, LSTM, Restricted Boltzmann Machine.以上带链接的部分为答主总结在博客中的内容，可以作为参考。未带链接的部分是答主接下来准备写在博客中的内容。博客内容持续更新，欢迎关注和交流：Frank Chu 。 关于机器学习的书籍，你可以参考以下几本书：机器学习 by 周志华: 周志华老师的这本书非常适合作为机器学习入门的书籍，书中的例子十分形象且简单易懂。统计机器学习 by 李航：李航老师的这本书偏优化和推倒，推倒相应算法的时候可以参考这本书。PRML by Christopher Bishop: PRML这本书有点偏Bayesian了，初学者看起来可能有些困难，可以和前两本结合起来看。Machine Learning A Probabilistic Perspective Learning by Kevin P. Murphy: MLAPP这本书也是一本比较经典的机器学习书，可以和PRML互相补充着来看。关于机器学习的资料，可以参考的有：CS 229: Machine Learning (Course handouts) : Stanford Machine Learning 课程， 里面的notes很不错。ML by Andrew Ng in coursera  :  这个比较适入门的时候看。Machine Learning Notes in cousera ： 如果没有时间看2中的视频的话，可以直接看这个博客，作者将2中所有内容都记录了下来。台大机器学习基石Frank Chu  ： 当然你也可以参考我的博客 ^_^机器学习是需要动手去推倒和实现的，如果你只是看看书和资料，不会理解得很好。如果你不仅推倒、实现了，还把它写成了博客，那么你就理解得比较透彻了。关于数据挖掘，在有了一定的机器学习基础之后，可以去参加阿里天池，kaggle等数据挖掘比赛来提高数据挖掘水平。", "answer_votes": "226", "answer_comment": "​6 条评论"}
{"answer_author": "知乎用户", "answer_id": 24218108, "answer_text": "楼主问的其实是两个相关（很多人分不清）但其实差不少的领域。现在排名第一的 @安岩 在推荐阅读上回答非常详尽，就不在这个方面多废话了，只是简单按照自己的经验说一下这两个的区别和联系：机器学习的终极目标是让计算机完成一些被我们认为是“智能”的工作，一开始的研究是从逻辑学方向入手的，之后几十年一直是统计机器学习的天下（说是“统计”，但其实更多是概率方向的知识），而近几年沉睡很久的神经网络也在得到更多甚至说是狂热的重视（神经网络可以认为是统计模型，但相比传统统计机器学习（statistical/probabilistic）而言，它更多时候更接近一个确定性（deterministic）模型）。另一方面，数据挖掘更侧重于实际应用，而且也和统计学（注意，这和概率有很大的区别）的关联更加显著。传统的应用包括购物篮分析（常购买商品、常共同购买商品），和比较新的一些社交网络、UGC分析（User Generated Contents, 用户生成的内容）等等。一个简单的数据挖掘和机器学习的区分就是，数据挖掘并不那么关心算法的细节，而相对更重视结果的解释及其统计意义；而相反，机器学习似乎更在乎算法的设计、优化，在分类、聚类、或者一些既定问题上的效果，而较少关心统计意义方面的考量。具体来说，一个数据挖掘专家可能会用线性回归甚至关联分析，这些被机器学习学者认为是上世纪初产物的模型完成一些非常有趣的实际工作，并得到确定的统计意义（比如95%置信区间、某个事件是否具有“突发”统计意义等），也就是说这些结果最终还是服务于人，需要人去理解；而机器学习学者会尽量设计模型来自动别难过完成相对“智能、复杂”的任务，比如图像识别、语音识别、自然语言理解等，提高算法在这些问题上的准确性，但通常会被统计学家吐槽很多模型的效果提升其实统计意义不明。最后简单总结一些两者分别（有些其实界限不是很清晰了，我只是列在了被研究得更多的那边）和公共的搜索词：数据挖掘（不熟，轻拍）：Data Analysis, (Social) Network Analysis, UGC Analysis, Market Segmentation, Recommendation/Ads Systems机器学习：Computer Vision, Speech Recognition, Natural Language Processing/Understanding, Pattern Recognition, Statistical Learning Theory (Convergence, Error Analysis), Probabilistic Graphical Models, Neural Networks公共：Linear Algebra, Parallelization/Large-Scale/Distributed Computation, Optimization, Probability/Statistics", "answer_votes": "47", "answer_comment": "​2 条评论"}
{"answer_author": "眉大侠", "answer_id": 19081322, "answer_text": "这个方面数学要求较高。建议，概率论统计学，代数好好学学，以及探讨各种优化问题。是数学，你都读读吧，没有坏处的。基础是数学，这是真的，没有扎实的基本功，这方面的东西看起来会很费劲。给你推荐一个系列的课程？只推荐个机器学习的课程吧，其他很多相关的学科大多都要用到机器学习的思想。stanford的机器学习课程，很有名了。斯坦福大学公开课 ：机器学习课程Coursera.org以及这方面的笔记Coursera公开课笔记: 斯坦福大学机器学习第一课“引言(Introduction)”JerryLead的很牛翻译过来的笔记（全套，可以研读下）Machine Learning一些博客推荐Free Mind（pluskid写的一系列很厉害）Free Mind机器学习 - 标签(leftnoeasy)Rachel Zhang的专栏http://dahuasky.wordpress.com/page/2/Tutorials by Avi KakStatistical Data Mining Tutorials这本书很有名，忘了说Pattern Recognition and Machine Learning/Christopher M. Bishop-图书与这方面相关的其他课程模式识别数据挖掘机器视觉自然语言推荐系统神经网络概率图论人工智能等等有相通的内容，很多都在用机器学习的方法，都可以看看。。。随便搜索就知道，这方面大多都是在搞统计学习方法之类。。。所以，就一句话，数学在这个方向很重要。", "answer_votes": "418", "answer_comment": "​17 条评论"}
{"answer_author": "李映真", "answer_id": 22990866, "answer_text": "给你推荐我们用的课本，把其中一本仔细读完都会有很大的收获。Kevin P. Murphy Machine Learning: a Probabilistic Perspective, the MIT Press (2012)David Barber Bayesian Reasoning and Machine Learning, Cambridge University Press (2012)Christopher M. Bishop Pattern Recognition and Machine Learning. Springer (2006)David J.C. MacKay Information Theory, Inference, and Learning Algorithms, Cambridge University Press (2003)第二和第四本在作者主页有 pdf 版本，个人比较喜欢 MacKay 的书，不过比较老了。", "answer_votes": "22", "answer_comment": "​2 条评论"}
{"answer_author": "Han Hsiao", "answer_id": 24367832, "answer_text": "刚回答过这个问题，如有兴趣建议抽出时间看一看。如何系统地学习数据挖掘？研究生的重点是做学术研究发论文，建议前期多看一些核心会议和期刊近三年来的发表和获奖论文（会议和期刊推荐在上面的介绍里有）找到自己感兴趣的方向，然后开始找数据做实验（数据来源可参考：数据分析和挖掘有哪些公开的数据来源？）发paper。祝多发paper，挖掘快乐：）", "answer_votes": "9", "answer_comment": "​添加评论"}
{"answer_author": "李文哲", "answer_id": 19096464, "answer_text": "想学所有的知识永远也学不完， 最重要的是专一。 与其翻阅不同的教材，我觉得还不如去尝试去解决实际问题，在这个过程当中根据需要适当的补充知识（假设你已经大概了解了机器学习的领域） 去kaggle尝试一下实际的问题吧， 之后你自己就会有方向感了,   http://www.kaggle.com/competitions", "answer_votes": "24", "answer_comment": "​1 条评论"}
{"answer_author": "张戎", "answer_id": 244179258, "answer_text": "以下内容都是进入公司之后才开始学习的，其实后来觉得可以在读书期间就学一下相关的内容，也方便自己找工作。知乎专栏写过一篇文章：《转行到数据挖掘与机器学习（三）》。原文来自微信公众号“数学人生”，链接是：转行到数据挖掘与机器学习（三）回头看一下，目前已经从纯数学专业转行到数据挖掘和机器学习领域有一年半了，又到了该总结转行经验的时候。还是那句老话，大牛们请主动忽视以下内容，初学者可以用作参考。［1］编程语言目前工业界的机器学习编程语言很多，基于个人的一些浅显的工作经验，发现目前比较常用的编程语言是 Python 和 SQL。通常来说，SQL 是为了从数据库中提取数据，然后进行必要的数据过滤，数据分析，数据提取。对于 SQL，需要掌握的内容有以下几点：聚合函数，数学函数，字符串函数，表格的连接函数，条件语句等。SQL 与 HIVE 的经典教材有两本，分别是：《HIVE编程指南》，作者 Edward Capriolo《SQL基础教程》，作者 MickPS：个人特别喜欢《SQL基础教程》，极易上手，易学易通。之前写过一篇文章总结 HIVE 的使用细节，提供给大家做参考：《HIVE基础介绍》对于编程语言 Python 来说，目前深度学习的框架 Tensorflow 等，都可以使用 Python 进行编程。除此之外，Python 还有各种各样的数值计算库和机器学习库等着大家去使用，例如 Numpy，Scipy，ScikitLearn，matplotlib 等。其中，Scikitlearn 的文档是非常详细的，特别适合初学者入门学习。至于 Python 教材的话，其实有很多，例如：《Python基础教程》，作者是 Magnus Lie Hetland，这本书特别适合初学者看。如果是网络教材的话，推荐参考 廖雪峰 的官方网站，地址是：Home - 廖雪峰的官方网站至于开发环境的话，一般来说公司都会使用Linux，有一本书可以提供给大家做参考：《Linux命令行与Shell脚本编程大全》，作者 Richard Blum／ Christine Bresnahan既然是处理大数据，那么 MapReduce，Hadoop，Spark 等内容需要了解。参考文章：《一文看懂大数据的生态技术圈，Hadoop，Hive，Spark都有了》［2］机器学习既然是做数据挖掘和机器学习的工作，那每个人都需要了解这方面的内容。在这里笔者推荐教材《机器学习实战》，作者是 Peter Harrington。阅读这本书需要读者掌握 Python 语言，加上 Numpy，Scipy，matplotlib 函数库的一些基础内容。源代码的话可以在网上找到，然后根据书本的章节逐步学习即可。除了《机器学习实战》之外，周志华老师所写的《机器学习》西瓜书也是不错的选择。建议初学者结合这两本书一起学习，周志华老师的《机器学习》介绍了多种机器学习算法，并有简单的例子和数学原理进行描述。既然提到了机器学习，那就简单地总结一下里面的一些算法吧。如果是做推荐业务的团队，那么使用地最多的还是逻辑回归算法（Logistic Regression），ItemCF 和 UserCF，物质扩散和热传导算法（Heat Spreading） 算法。由于 LR 是使用线性的方法来处理非线性的问题，并且实际的环境中会有物品的特征和用户的特征，因此会导致特征工程比较复杂，交叉项多（二维或者三维的交叉）。因此，在实际的工作中，特征工程的作用就显得十分重要。工程师和业务人员要根据物品和用户进行必要的特征构造，形成物品特征，用户特征，交叉特征等。之前也写过一篇文章《特征工程简介》，供大家参考。除此之外，涉及到在线优化的问题，Google 在几年前提出了一个 FTRL 算法。论文是 Ad Click Prediction a View from the Trenches，里面会涉及 SGD 算法，Truncated Gradient 算法，RDA 算法，FOBOS 算法，以及最终的 FTRL 算法等。比逻辑回归算法还要简单的那就是线性回归算法了，目的都是针对连续型的数据进行预测，结果都十分容易解释。除了直接的线性回归之外，还有局部加权线性回归，岭回归，Lasso 和前向逐步线性回归等算法。这些细节可以参考文章《线性回归》。如果是针对转行的同学的话，那么大家肯定关心的是如何把之前的技能平滑地切入到新的领域中。如果学过数理统计的话，那么《最大似然估计》就是一个不错的切入点。除了上面所说的算法，支持向量机算法（Support Vector Machine），GBDT 算法，随机森林算法，XgBoost 算法都是在工业界比较常见的算法。目前个人还没有对这类算法进行过总结，不过还是强烈建议大家去学习一下。2017年笔者应该会对这些算法进行一些个人的总结。无监督学习算法也是整个机器学习领域的一大方向。提到无监督学习算法，就不得不提到聚类算法，其中最经典的还是 Kmeans 算法。这个可以参见文章《聚类算法（一）》。聚类算法的反面就是异常点检测算法，之前在异常点检测算法上面研究过一阵，也写过不少的文章。例如：《异常点检测算法（一）》，《异常点检测算法（二）》，《异常点检测算法（三）》，《异常点检测算法综述》。除此之外，强化学习也是机器学习的一个研究方向。随着 DeepMind 公司的 AlphaGo 打败围棋顶尖选手，能够自动玩游戏的智能 AI，强化学习已经成为了一个比较热门的研究方向。之前写过一篇关于强化学习和泛函分析的小文章《当强化学习遇见泛函分析》，供大家参考。目前深度学习已经成为了机器学习的热门研究方向，无论是卷积神经网络 CNN 还是循环神经网络 RNN，都是研究的主流。之前在学习反向传播算法的时候，写过一篇如何基于 BP 算法训练 RNN 网络的文章《循环神经网络－Reccurent Neural Networks》。［3］数理统计数理统计方面还是有一些东西是蛮常用的。例如时间序列模型 ARMA 模型等。一些数据的指标，例如均值，方差，标准差，变异系数，相关系数，ROC曲线和AUC，召回率和正确率，交叉验证等。［4］业务场景在实际的工作中，最重要的一个因素就是理解业务，只有理解了业务的需求，才能够更好的完成领导所布置的任务。在做事情的时候，一定要形成闭环。那就是：了解业务需求－》调研业界方案－》查看是否适用－》上线效果。通过最终的效果和我们要做成的目标，来反推当前需要做的事情。一些学生时代的思维方式需要逐渐抛弃，参考文章：《开公众号之后的一些感想》。", "answer_votes": "121", "answer_comment": "​6 条评论"}
{"answer_author": "知乎用户", "answer_id": 76753878, "answer_text": "学习挑一个合适的导师以及逼格够高, 但是不至于难到你的项目.....", "answer_votes": "1", "answer_comment": "​添加评论"}
{"answer_author": "孔秋强", "answer_id": 49225297, "answer_text": "高票答案说的都很好。数学真的很重要！如果你还是研一阶段，推荐你去听一听数学学院的课程。楼上关于机器学习方面的资料推荐已经很详细了，我就补充一些推荐的数学资料吧。有些数学课程真的不适合自学，有老师讲一下就马上不一样了。有用的数学知识有：最优化。推荐《Numerical Optimization 2ed - Nocedal》，机器学习里到处都是优化，如神经网络权值的计算等。学最优化的好处是学的时候顺便也能把矩阵给复习一下。泛函分析。推荐《泛函分析》张恭庆著。这门课能极大扩宽视野，有些数学上的证明，比如三层神经网络能逼近任意函数，就是需要有泛函的知识才能看懂的。再往深有Soblev空间和调和分析，就更加数学一些，对做信号处理方向会有很大帮助。概率论。暂无推荐。机器学习实际上就是统计学习，PRML的书几乎把每种模型都贝叶斯化了。入了机器学习的坑，就离不开概率。测度论。推荐《测度论》严加安著。测度论是概率论的基础，能够让你对概率有更深入的了解。随机过程。暂无推荐。在数学院里，随机过程是在测度论之后开的，涉及了大量的测度论知识。没学测度论也没关系，可以看针对工科写的应用随机过程。多元统计分析。推荐《实用多元统计分析_第四版》Richard A. Johnson等著。机器学习统计学习不分家，也是大量的数据矩阵表达，矩阵运算，这门课最大的好处就是把眼花缭乱的积分号矩阵化，更加简洁。抽象代数。这门课对机器学习的直接作用不大，有时间学一学也能够扩宽视野。比如知道矩阵及矩阵乘法实际是一个非阿贝尔群（乘法不可交换）。表示论。我对表示论了解不多，只是零星学过一点群表示论。表示论也是数学一个重要部分。在机器学习中的应用不详。===================================至于机器学习的书籍，上面高票答得都很好！", "answer_votes": "21", "answer_comment": "​4 条评论"}
{"answer_author": "肖智博", "answer_id": 19082436, "answer_text": "研究生阶段都是跟着导师做课题，从中抽出来一个题目做。即使不是这样，论文的题目也会非常具体到一个很细小的问题，所涉及的方法也不会很多。课程看学校安排了，如果学校安排课程也是一门大课，讲述各种方法，不过这样光说不练是掌握不了的。研究生阶段有的是时间，找你想学的方法自己动手实现一下才好。我觉得课程和书都是带你入门的，结合题目细致研究一个领域才是正道。手机上写的，比较简略。", "answer_votes": "9", "answer_comment": "​5 条评论"}
{"answer_author": "道道", "answer_id": 49219946, "answer_text": "Coursera上有个5门UIUIC的课拿一个certificate的data mining program，我觉得课程的选择和渐进都是非常接近实际的data mining硕士program的（实际研究生program可能会多一些基础统计和CS课程，和一些辅助理论和算法课程，另外多一些选修方向）。这个program的几位教授都是data mining学术界的大牛 （有位是我研究生时期data mining教授读书时期的博士导师，还有位连我这样的门外汉也听说过他的大名）。附上链接：Coursera - Specializations课程组成：1. Pattern Discovery in Data Mining2. Text Retrieval and Search Engines3. Cluster Analysis in Data Mining4. Text Mining and Analytics5. Data Visualization如果非要让我选的话，Data Visualization可能不是必须的，但是非常有趣而且实用，是很有益处的“bonus”。另外如果统计的基础知识不太记得清楚的话很推荐去上一门基础统计科或者refresh一下统计知识…因为对理解这些课程的帮助很大。", "answer_votes": "16", "answer_comment": "​2 条评论"}
{"answer_author": "湿人彭", "answer_id": 113158720, "answer_text": "额……已经结课的北航大数据在职生来答一个。首先这个问题应该分为两个视角来回答：教务视角和学生视角。对于学校来说，学生的基础不一，跨专业的比比皆是。所以会分为专业课和选修课，一般来说会上一些通识课程如：数据库、统计原理、各种数学、算法、还有必修的英语和政治。另外一部分是各种语言、工具类课程，比如C++、Java、python、R、SAS、SPSS等，然后是一些实用课程，比如社交网络分析、web分析、高级数据挖掘神马的。在学生角度，需要根据自身实力好好确定需要提升的点，可以参考数科学家技能树，挨个点亮。从最基础的微积分、线性代数、数据库、各种开发语言（一个专长就够），到各种机器学习算法原理、使用、调优，再到整个数据挖掘全流程的数据处理、分析、挖掘等。", "answer_votes": "2", "answer_comment": "​1 条评论"}
{"answer_author": "知乎用户", "answer_id": 109644200, "answer_text": "我贴一下具体的课程吧，怎么学，我的经验是用到什么学什么。用以致学。这样就不会学到后面忘记前面。&lt;img data-rawwidth=\"750\" data-rawheight=\"769\" src=\"https://pic4.zhimg.com/50/9e659a09024436c50d29b5b70ab885aa_hd.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"750\" data-original=\"https://pic4.zhimg.com/9e659a09024436c50d29b5b70ab885aa_r.jpg\"&gt;&lt;img data-rawwidth=\"750\" data-rawheight=\"720\" src=\"https://pic4.zhimg.com/50/cbdee976949778ebb8f92ee4d83725a7_hd.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"750\" data-original=\"https://pic4.zhimg.com/cbdee976949778ebb8f92ee4d83725a7_r.jpg\"&gt;", "answer_votes": "2", "answer_comment": "​4 条评论"}
{"answer_author": "许靖", "answer_id": 49188761, "answer_text": "KDD的论文及各种reference，KDD的比赛及各种参赛算法，当然，最优化理论是必学的。", "answer_votes": "0", "answer_comment": "​2 条评论"}
{"answer_author": "杨超", "answer_id": 41774724, "answer_text": "不知道题主说的硕士还是博士。就以自己的经历说下吧。西北某军工类院校，计算机，实验室做语音的。学院没什么机器学习的积累，也没有高质量的课，英语烂，网上的视频看不下去，就自己看书，纯粹自学。书籍：大四导师就推荐了本prml，整个研究生阶段就反复看，做题，跟同学分享讨论，给同学讲解。模式分类，图模型(jordan的未发行版)，模式分析，统计学习基础等等这些经典也都刷过。那些集体智慧,机器学习实战也都看过。\"数学\"方面:线性代数应该这样学，学校的矩阵论和数理统计课。这是指我学的觉得有用的，其他我还看了一大堆数学书的第一章或者前两章，什么实复泛函分析啦，拓扑学啦，测度论啦。可是因为自己的脑力毅力加之没人逼我学，实在没能读下去。优化我没学过，虽然也翻过不少优化书的前两章，但学习过程中确实没用到啥复杂的优化算法，没需求，而且那东西我觉得一点都不有趣，就没去学。2011年.学nlp的东西，刷了一本jur啥写的特厚的nlp的书，写的特别好，把里面的算法实现了一遍。看prml。这时看不懂LDA。2012年论文方向是深度学习，那时候也没找到现成的工具包，自己写了一个支持cuda的深度神经网络的工具包。（其实代码很简单，就花了几个晚上而已）。看prml。可以看懂了LDA。2013年.实在觉得深度学习没意思，论文换了题目，开始研究狄利克雷过程。中间去实习，实习完了继续看，加起来看了有半年。反复看prml。纯粹应为太闲，这时重新看LDA论文，就非常清晰了。论文精读了百篇以上，除了当时花心思研究的深度学习和DP看了一大堆论文外，其他方面只精读各种经典论文，也就是各个模型的第一篇，如果论文太多，先看nips,icml之类的。另外，survey也是值读的。虽然好的survey并不多。其实大论文比较容易看懂，因为更详细，学DP时研读neal,sudderth和eb fox的博士论文，感觉收获很大，也很佩服这些牛人phd做的工作，不管有没有用，至少做的特别认真，特别严谨。另外，有一套Foundations and Trends 系列的introduction也是蛮不错的。每天拿来学习的时间也就3-4小时。其他时间都在玩。最后结果：自己连机器学习应用的门槛还没进，不过感觉跟很多同领域的小硕比起来，还算不差。感想：我时间都花在概率模型上，或者说贝叶斯模型，对于真的去训练模型，我不擅长。我尤其厌烦那种把机器学习当个黑盒子，什么问题非要去套这个黑盒子，更讨厌那些明知其理还在鼓吹的人。研究问题，不静下来从物理的角度（事物的原理）出发，反而一上来就倒过来，期望靠统计来发现一些表象的规律。由一些基本的原理不断组合产生出的世界，才体现出美感，而拟合输入输出对实在太丑陋。贝叶斯方法相比某些方法还算有点物理意义，所以自己还感点兴趣。这些年，记忆最深的当属一篇cvpr的best paper。讲的一个去雾算法，我觉得这篇论文比拟合来拟合去的强上无数倍。对于phd：phd就不是这节奏了，我的phd师兄就比我学的多多的了，但是要折腾的杂事也比我多。phd的基础要很扎实，不能像我这样糊弄了事，而且phd要发论文，必须得时刻了解动向，发现机会，熬夜折腾论文实验，不像小硕，玩玩混过去即可。远离学术圈，尽可能少的发表论文留下污点。", "answer_votes": "53", "answer_comment": "​19 条评论"}
{"answer_author": "yuke", "answer_id": 213503189, "answer_text": "这是个很好的问题，我下面说的一部分可能是大众已经了解的点，但另外一大部分，我相信是很多人未必重视但我认为对于学好机器学习很重要的点，这些也是我结合个人经历总结出来的：首先，机器学习的根本是数理统计，这是大家都知道的概率论：相当于是理解randomness（随机性）是如何工作并对世界当中的events产生作用的；统计学概论：和概率论正好想法，是通过观察到世界当中的events的结果而反推randomness中的概率性规律。如果有可能的话可以尽量先学概率论再学统计学，意思大致等同于应该先学密码生成，再学密码破译；线性代数：线性代数的基础是肯定需要的，当然主要就是矩阵计算这部分比较重要，后续的线性代数中有关于正定性、半正定性等等很深的内容，大多数人可能不必学。除非你是需要对机器学习的凸优化机制进行研究。之所以说大多数人不必学是因为如今Tensorflow等等机器学习框架已经把优化过程这部分以黑箱的形式做的很完善了，所以即便我们不了解其中的细节也差别不大；实分析/实变函数：学一部分实分析/实变函数我觉得是有帮助的，因为通过这个学习过程，就能够对“小量”这个概念有一个非常深刻的理解。后续的机器学习中涉及到的数学基础知识很多是建立在“小量”这个基础上的；测度论：我个人认为其实不用学测度论，除非你的目的是要去大学担任教职工作或从事学术研究；随机过程：有些同学会奇怪为什么做机器学习要学习随机过程，其实这点是我结合自己的亲身经历总结出来的。 我在经过一段时间后发现要理解和熟练掌握机器学习最大的重点是要理解数理统计理论在实践中是如何应用的。简单来说，机器学习中的back-propogation这种机制本身只是一个微积分结合凸优化的一个机械化的参数估计过程而已。而要想真正学好机器学习，back-prop具体如何实现并不重要，重要的是你是如何理解samples（样本）/observations（数据观测）和基于其总结出的数理统计规律之间的关系的；从另一个层面讲，就是你是否能够很好地理解randomness（随机性）是如何在数据中显现的，更重要的是发现随机性这层外衣里面裹挟的这个概率性的规律。       举例来说，比如你看到股票市场上的股票近一年来的波动态势，最重要的是你是否能通过大数  据分析的方法找到其中的几个为主的驱动因素，和这几个驱动因素互相之间是如何影响的，而在发现这些因素后具体去估计每个因素的相关参数只不过是一个标准化的流程也已。而在实践中你能看到随机性的最好的应用情景就是在随机过程和马尔科夫过程中了；就拿天气预报来说，现在11点是阴天，你预测下午2点的天气是晴天或者阴天的概率其实就应用到了马尔科夫过程       马尔科夫过程：大家都看到了在例如NLP（自然语言处理）的n-gram语言模型中普遍会使用到Markov Property（马氏性）这个基本假设，所以能够从根本上理解马氏性对这类应用的深层理解是很有帮助的。如果说随机过程是一个广义的概念，其中包含连续的随机过程和离散的随机过程，那么马尔科夫过程基本就是随机过程中离散随机过程的一个最经典的一类。希望以后可以有机会再聊聊神经网络吧，我也先挖个坑，希望有以后有机会可以细聊。", "answer_votes": "5", "answer_comment": "​添加评论"}
{"answer_author": "知乎用户", "answer_id": 49183607, "answer_text": "为了了解svm，看了一沓论文然后实现了简单模型。", "answer_votes": "1", "answer_comment": "​添加评论"}
{"answer_author": "匿名用户", "answer_id": 68065053, "answer_text": "不知道是不是问题被修改过了？看到一堆答复，都是针对机器学习里的内容做介绍的，还有涉及到的相关的数学介绍。Ng的斯坦福公开课，都是本科生的吧！coursera上的很多课程，都是入门性质，不要以为拿了满分就是不错了，据我所知，很多人拿到满分，很多人翻译过课件。我也是。这种问题，最好的就是去看看各个学校的培养计划，系统性的培养。。对于数据挖掘，比如看看人大的数据挖掘培养计划，绝对不是说看完一本书就可以了，或者说学习一门数据挖掘课程。更不是一堆数学学科的堆砌。很多人的学习是一堆知识的堆砌，没办法系统化，还是停留在本科的水平。另外，研究生的主要任务是确定研究方向。很多机器学习院系，都是提供基础课程而已。如果你没有选择合适的方向，比如自然语言处理或者图像之类，单就机器学习而言，可以参考CMU的机器学习，有研一的机器学习课程，也有面向研二的机器学习，也有面向PhD的。ML Classes for Fall 2015-Machine Learning Department不要觉得看完一门课的视频就算过了研究生的培养了。总之，多数人都是：下载过很多书（视频），可依旧学不好这门课。听过很多道理，可依旧过不好这辈子。", "answer_votes": "12", "answer_comment": "​添加评论"}
{"answer_author": "某翔", "answer_id": 133272317, "answer_text": "&lt;img data-rawwidth=\"750\" data-rawheight=\"1334\" src=\"https://pic3.zhimg.com/50/v2-ef052dc4f3ffebd0af2ca9e1afd3909f_hd.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"750\" data-original=\"https://pic3.zhimg.com/v2-ef052dc4f3ffebd0af2ca9e1afd3909f_r.jpg\"&gt;更深层次的概率论貌似是CMU的重点，严格来说10-702 10-725 10-708都算是统计课，所以我也可能觉得机器学习的master不止是对于编程的研究，同样还要了解从概率论的角度，为什么这一个个算法可以用来逼近最后的答案。据我所知10-702和36-705可以看Larry Wasserman的All of Statistics来解决，10-701应该可以google到课程网站，网上一般有讲义10-725是肯定有网站和讲义的，而且还很贴心的给了准备材料，有兴趣可以看看", "answer_votes": "3", "answer_comment": "​添加评论"}
{"answer_author": "赵熙", "answer_id": 198183350, "answer_text": "机器学习的概念范畴很广，从大的方面说，包括理论和实践两方面。理论方面：高数、线代、概率论、数据结构、机器学习算法、最优化、运筹学、随机过程等。实践方面：分析工具（Matlab、Python、R、SAS等）、分析范式、数据理解、可视化等。前者看一本经典教材即可，推荐《机器学习》或《数据挖掘概念与技术》，后者就需要多练习多实践，熟能生巧，如果用Python的话推荐《机器学习实战》边学边练。数据分析就像做饭一样，做的次数多了自然就有经验了，是一门工程性很强的实践活动，分享读博士期间收集的一些数据集，可用来练习实践。各领域公开数据集下载 - 知乎专栏", "answer_votes": "2", "answer_comment": "​添加评论"}
{"answer_author": "大器不早成", "answer_id": 262246458, "answer_text": "回答里都是在讲一些学习资源，这里安利一个学习资源，入门机器学习的科研神器——数据超市,里面封装了常见的机器学习算法，可以让你在无需编程的前提下，快速上手机器学习，辅助你学习算法，当然你还可以搭建科研流程帮助你写论文", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "赵耀", "answer_id": 245671259, "answer_text": "因人而异，但是说点个人经验之谈首先算法方面，Ng的cs229，李航的统计学习，周老师的西瓜树，总得学一个吧，个人认为学一个就可以，剩下的当工具书就可以，在学习完之后希望你可以理解的更深入一些，比如把gradient descent和newtons method理解到Taylor series 的层面，把regularization理解到prior probability的层面其次code方面，现在工业界的趋势摆在那里python，scala，java怎么都得会一个吧，再次是一个基本技能，做业务经常要自己提数据，hiveql，pig总得会一个吧，linux用要用的6吧综上所述，如果可以去大公司实习一下，那是再好不过了", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "咩咩咩沁沁", "answer_id": 24274157, "answer_text": "数学专业 一定要学这个吗 走统计方向", "answer_votes": "0", "answer_comment": "​4 条评论"}
{"answer_author": "刘浩辉", "answer_id": 134931008, "answer_text": "对数据敏感，数学抽象能力及数学工具等，强大的编程能力，就这些吧", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "杨格蒙", "answer_id": 112892057, "answer_text": "虽然一年里我们有11门课之多 但个人觉得六门课非常重要 ProbabilityStatistical inference Regression modelBig dataMachine learning Information retrieval 弊校在IR领域一直很强 感觉bd和ml两门课学校的发展都是建立的ir的基础上 三者相辅相成 缺一不可", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "有熊出没", "answer_id": 46480590, "answer_text": "我喜欢题主这个问题，知友们对具体知识的回答很详细了，我换个角度切入下。首先，数据挖掘不一定要有后期的machine learning, SQL会了以后，很多基础的，有实际意义的东西就会通过数据整合显示出来，而机器学习对于数据量并没有太大的要求，对于数据的质的要求会更高，一旦training data biased， 整个model会被严重影响。很多情况下（实际商业）big data会止于浅层挖掘，只有部分有意义的数据会最终被用来learn. 其次，如果题主读的是统计硕士，大部分学校的focus是expand你对机器学习的认识，介绍很多已经成熟的模型以及应用。但个人觉得machine learning 是一个非常 programming intensive的方向，所以应该学校会叫你学两三门编程语言。如果题主读的是博士，那你的研究方向可能最终会落脚于某个算法的提升或开发，而且对于成熟的算法，要有比较深刻的理解和认识，deep learning貌似是目前统计方面比较热的一个方向，当然，至于语言，R基本是必备的。书籍的话，Berkeley和Stanford都会用the elements of statistical learning，这本书连同其完整的数据练习相当有意思，可深可浅，值得用心去读。", "answer_votes": "2", "answer_comment": "​1 条评论"}
{"answer_author": "刘世超", "answer_id": 119315544, "answer_text": "很好", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "匿名用户", "answer_id": 49526704, "answer_text": "想请教下～在某网站上看到关于机器学习～数据挖掘的招聘很少～学习了机器学习～数据挖掘 可以去哪些公司啊？除了bat～", "answer_votes": "0", "answer_comment": "​添加评论"}
{"answer_author": "张洛阳", "answer_id": 129552705, "answer_text": "我觉得应该先看机器学习方面的书籍，再去阅读有具体研究方向的相关论文。我的老师就是把一大堆论文扔给我(关键是我也看不懂)，结果等我研究生毕业了都没有太深入的了解什么是机器学习，楼上的很多参考资料都是不错的选择。", "answer_votes": "1", "answer_comment": "​添加评论"}
